{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "B20AI058.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "VCyfe2g9H3ek",
        "wYz4X2A1IBdc",
        "WIZgzAgbIEL4",
        "jR3EmTvJ49MJ",
        "uXp56jGp5BOE",
        "xKPbVb495EqZ",
        "SQgRlRUl5J7a"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Data Preprocessing"
      ],
      "metadata": {
        "id": "VvF9W7YFHFTy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importing the Libraries"
      ],
      "metadata": {
        "id": "GTBKVqMr44AH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "kvFoS8DreLgQ"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install flaml"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "605_GeydpZ-v",
        "outputId": "0139e81d-4533-4ec0-86ab-bf93c7971ebe"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting flaml\n",
            "  Downloading FLAML-1.0.1-py3-none-any.whl (157 kB)\n",
            "\u001b[?25l\r\u001b[K     |██                              | 10 kB 22.7 MB/s eta 0:00:01\r\u001b[K     |████▏                           | 20 kB 29.4 MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 30 kB 34.4 MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 40 kB 21.1 MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 51 kB 9.0 MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 61 kB 10.4 MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 71 kB 9.6 MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 81 kB 10.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 92 kB 11.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 102 kB 10.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 112 kB 10.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 122 kB 10.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 133 kB 10.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 143 kB 10.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 153 kB 10.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 157 kB 10.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.7/dist-packages (from flaml) (1.3.5)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from flaml) (1.4.1)\n",
            "Collecting lightgbm>=2.3.1\n",
            "  Downloading lightgbm-3.3.2-py3-none-manylinux1_x86_64.whl (2.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.0 MB 28.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scikit-learn>=0.24 in /usr/local/lib/python3.7/dist-packages (from flaml) (1.0.2)\n",
            "Requirement already satisfied: xgboost<=1.3.3,>=0.90 in /usr/local/lib/python3.7/dist-packages (from flaml) (0.90)\n",
            "Requirement already satisfied: NumPy>=1.16.2 in /usr/local/lib/python3.7/dist-packages (from flaml) (1.21.6)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.7/dist-packages (from lightgbm>=2.3.1->flaml) (0.37.1)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.1.4->flaml) (2022.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.1.4->flaml) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=1.1.4->flaml) (1.15.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.24->flaml) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.24->flaml) (1.1.0)\n",
            "Installing collected packages: lightgbm, flaml\n",
            "  Attempting uninstall: lightgbm\n",
            "    Found existing installation: lightgbm 2.2.3\n",
            "    Uninstalling lightgbm-2.2.3:\n",
            "      Successfully uninstalled lightgbm-2.2.3\n",
            "Successfully installed flaml-1.0.1 lightgbm-3.3.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install scikit-learn-intelex"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fmzqtv1NAHf6",
        "outputId": "9e7589d1-c955-4d13-98a3-6cd500129c09"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting scikit-learn-intelex\n",
            "  Downloading scikit_learn_intelex-2021.5.3-py37-none-manylinux1_x86_64.whl (69 kB)\n",
            "\u001b[K     |████████████████████████████████| 69 kB 4.1 MB/s \n",
            "\u001b[?25hCollecting daal4py==2021.5.3\n",
            "  Downloading daal4py-2021.5.3-py37-none-manylinux1_x86_64.whl (22.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 22.5 MB 1.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scikit-learn>=0.22 in /usr/local/lib/python3.7/dist-packages (from scikit-learn-intelex) (1.0.2)\n",
            "Collecting daal==2021.5.3\n",
            "  Downloading daal-2021.5.3-py2.py3-none-manylinux1_x86_64.whl (284.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 284.3 MB 1.4 kB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.7/dist-packages (from daal4py==2021.5.3->scikit-learn-intelex) (1.21.6)\n",
            "Collecting tbb==2021.*\n",
            "  Downloading tbb-2021.6.0-py2.py3-none-manylinux1_x86_64.whl (4.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.0 MB 38.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.22->scikit-learn-intelex) (1.4.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.22->scikit-learn-intelex) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.22->scikit-learn-intelex) (3.1.0)\n",
            "Installing collected packages: tbb, daal, daal4py, scikit-learn-intelex\n",
            "Successfully installed daal-2021.5.3 daal4py-2021.5.3 scikit-learn-intelex-2021.5.3 tbb-2021.6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Accelerating Scikit-learn\n",
        "from sklearnex import patch_sklearn\n",
        "patch_sklearn()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5FqbwlxFAD6C",
        "outputId": "e23ea2c6-f822-49e4-b163-27cfa0426470"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Intel(R) Extension for Scikit-learn* enabled (https://github.com/intel/scikit-learn-intelex)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import plotly \n",
        "import plotly.express as px\n",
        "import plotly.graph_objs as go\n",
        "import plotly.offline as py\n",
        "from plotly.offline import iplot\n",
        "from plotly.subplots import make_subplots\n",
        "import plotly.figure_factory as ff\n",
        "\n",
        "import missingno as msno"
      ],
      "metadata": {
        "id": "GcMUFddi0hhK"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importing the dataset"
      ],
      "metadata": {
        "id": "n8RZg1iyHKZV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data=pd.read_csv(\"healthcare-dataset-stroke-data.csv\")"
      ],
      "metadata": {
        "id": "SfdHsxUfejNr"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 537
        },
        "id": "9Pbo0nHWeo1J",
        "outputId": "c779516c-70d5-4321-af87-d0c4be32a902"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         id  gender   age  hypertension  heart_disease ever_married  \\\n",
              "0      9046    Male  67.0             0              1          Yes   \n",
              "1     51676  Female  61.0             0              0          Yes   \n",
              "2     31112    Male  80.0             0              1          Yes   \n",
              "3     60182  Female  49.0             0              0          Yes   \n",
              "4      1665  Female  79.0             1              0          Yes   \n",
              "...     ...     ...   ...           ...            ...          ...   \n",
              "5105  18234  Female  80.0             1              0          Yes   \n",
              "5106  44873  Female  81.0             0              0          Yes   \n",
              "5107  19723  Female  35.0             0              0          Yes   \n",
              "5108  37544    Male  51.0             0              0          Yes   \n",
              "5109  44679  Female  44.0             0              0          Yes   \n",
              "\n",
              "          work_type Residence_type  avg_glucose_level   bmi   smoking_status  \\\n",
              "0           Private          Urban             228.69  36.6  formerly smoked   \n",
              "1     Self-employed          Rural             202.21   NaN     never smoked   \n",
              "2           Private          Rural             105.92  32.5     never smoked   \n",
              "3           Private          Urban             171.23  34.4           smokes   \n",
              "4     Self-employed          Rural             174.12  24.0     never smoked   \n",
              "...             ...            ...                ...   ...              ...   \n",
              "5105        Private          Urban              83.75   NaN     never smoked   \n",
              "5106  Self-employed          Urban             125.20  40.0     never smoked   \n",
              "5107  Self-employed          Rural              82.99  30.6     never smoked   \n",
              "5108        Private          Rural             166.29  25.6  formerly smoked   \n",
              "5109       Govt_job          Urban              85.28  26.2          Unknown   \n",
              "\n",
              "      stroke  \n",
              "0          1  \n",
              "1          1  \n",
              "2          1  \n",
              "3          1  \n",
              "4          1  \n",
              "...      ...  \n",
              "5105       0  \n",
              "5106       0  \n",
              "5107       0  \n",
              "5108       0  \n",
              "5109       0  \n",
              "\n",
              "[5110 rows x 12 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-fedd6207-0d57-45bf-a474-f86055a3879e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>gender</th>\n",
              "      <th>age</th>\n",
              "      <th>hypertension</th>\n",
              "      <th>heart_disease</th>\n",
              "      <th>ever_married</th>\n",
              "      <th>work_type</th>\n",
              "      <th>Residence_type</th>\n",
              "      <th>avg_glucose_level</th>\n",
              "      <th>bmi</th>\n",
              "      <th>smoking_status</th>\n",
              "      <th>stroke</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>9046</td>\n",
              "      <td>Male</td>\n",
              "      <td>67.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Private</td>\n",
              "      <td>Urban</td>\n",
              "      <td>228.69</td>\n",
              "      <td>36.6</td>\n",
              "      <td>formerly smoked</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>51676</td>\n",
              "      <td>Female</td>\n",
              "      <td>61.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Self-employed</td>\n",
              "      <td>Rural</td>\n",
              "      <td>202.21</td>\n",
              "      <td>NaN</td>\n",
              "      <td>never smoked</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>31112</td>\n",
              "      <td>Male</td>\n",
              "      <td>80.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Private</td>\n",
              "      <td>Rural</td>\n",
              "      <td>105.92</td>\n",
              "      <td>32.5</td>\n",
              "      <td>never smoked</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>60182</td>\n",
              "      <td>Female</td>\n",
              "      <td>49.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Private</td>\n",
              "      <td>Urban</td>\n",
              "      <td>171.23</td>\n",
              "      <td>34.4</td>\n",
              "      <td>smokes</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1665</td>\n",
              "      <td>Female</td>\n",
              "      <td>79.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Self-employed</td>\n",
              "      <td>Rural</td>\n",
              "      <td>174.12</td>\n",
              "      <td>24.0</td>\n",
              "      <td>never smoked</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5105</th>\n",
              "      <td>18234</td>\n",
              "      <td>Female</td>\n",
              "      <td>80.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Private</td>\n",
              "      <td>Urban</td>\n",
              "      <td>83.75</td>\n",
              "      <td>NaN</td>\n",
              "      <td>never smoked</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5106</th>\n",
              "      <td>44873</td>\n",
              "      <td>Female</td>\n",
              "      <td>81.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Self-employed</td>\n",
              "      <td>Urban</td>\n",
              "      <td>125.20</td>\n",
              "      <td>40.0</td>\n",
              "      <td>never smoked</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5107</th>\n",
              "      <td>19723</td>\n",
              "      <td>Female</td>\n",
              "      <td>35.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Self-employed</td>\n",
              "      <td>Rural</td>\n",
              "      <td>82.99</td>\n",
              "      <td>30.6</td>\n",
              "      <td>never smoked</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5108</th>\n",
              "      <td>37544</td>\n",
              "      <td>Male</td>\n",
              "      <td>51.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Private</td>\n",
              "      <td>Rural</td>\n",
              "      <td>166.29</td>\n",
              "      <td>25.6</td>\n",
              "      <td>formerly smoked</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5109</th>\n",
              "      <td>44679</td>\n",
              "      <td>Female</td>\n",
              "      <td>44.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Govt_job</td>\n",
              "      <td>Urban</td>\n",
              "      <td>85.28</td>\n",
              "      <td>26.2</td>\n",
              "      <td>Unknown</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5110 rows × 12 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fedd6207-0d57-45bf-a474-f86055a3879e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-fedd6207-0d57-45bf-a474-f86055a3879e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-fedd6207-0d57-45bf-a474-f86055a3879e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.work_type.value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZOkNL7OmypV1",
        "outputId": "6e9a7387-aa68-4620-9305-702e89dab496"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Private          2925\n",
              "Self-employed     819\n",
              "children          687\n",
              "Govt_job          657\n",
              "Never_worked       22\n",
              "Name: work_type, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Visualization"
      ],
      "metadata": {
        "id": "kqoenaHhHXF2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "msno.matrix(data,color=(.33,.45,.67))\n",
        "#It seem that we have random missing values on the 'bmi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 552
        },
        "id": "vdqUwXFl0i6u",
        "outputId": "19a4d1ee-ac5d-4169-c713-d6832923b695"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f037b81e450>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1800x720 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fig = px.histogram(data, x=\"age\", color=\"stroke\",color_discrete_map={0:'purple',1:'red'})\n",
        "fig.show()\n",
        "# it can be clearly be seen that the people having age above 50 suffered stroke more."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "iHJAiUbQ2Dl1",
        "outputId": "3325777b-6052-4015-8fc0-4cd532729196"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-2.8.3.min.js\"></script>                <div id=\"51127037-9a72-4ce8-8dd5-9b2e89a3a4f6\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"51127037-9a72-4ce8-8dd5-9b2e89a3a4f6\")) {                    Plotly.newPlot(                        \"51127037-9a72-4ce8-8dd5-9b2e89a3a4f6\",                        [{\"alignmentgroup\":\"True\",\"bingroup\":\"x\",\"hovertemplate\":\"stroke=1<br>age=%{x}<br>count=%{y}<extra></extra>\",\"legendgroup\":\"1\",\"marker\":{\"color\":\"red\",\"pattern\":{\"shape\":\"\"}},\"name\":\"1\",\"offsetgroup\":\"1\",\"orientation\":\"v\",\"showlegend\":true,\"x\":[67.0,61.0,80.0,49.0,79.0,81.0,74.0,69.0,59.0,78.0,81.0,61.0,54.0,78.0,79.0,50.0,64.0,75.0,60.0,57.0,71.0,52.0,79.0,82.0,71.0,80.0,65.0,58.0,69.0,59.0,57.0,42.0,82.0,80.0,48.0,82.0,74.0,72.0,58.0,49.0,78.0,54.0,82.0,63.0,60.0,76.0,75.0,58.0,81.0,39.0,76.0,78.0,79.0,77.0,63.0,63.0,82.0,78.0,73.0,54.0,56.0,80.0,67.0,45.0,75.0,78.0,70.0,76.0,59.0,80.0,76.0,67.0,66.0,63.0,52.0,80.0,80.0,79.0,51.0,43.0,59.0,66.0,79.0,68.0,58.0,54.0,61.0,70.0,47.0,74.0,79.0,81.0,57.0,80.0,45.0,78.0,70.0,58.0,57.0,69.0,64.0,77.0,74.0,81.0,57.0,58.0,50.0,54.0,79.0,53.0,79.0,80.0,76.0,45.0,68.0,71.0,61.0,74.0,38.0,77.0,58.0,53.0,80.0,56.0,72.0,72.0,78.0,80.0,82.0,75.0,73.0,78.0,69.0,38.0,68.0,71.0,76.0,76.0,76.0,75.0,82.0,59.0,74.0,69.0,72.0,66.0,65.0,78.0,57.0,70.0,79.0,68.0,80.0,68.0,55.0,77.0,50.0,57.0,71.0,81.0,76.0,71.0,1.32,78.0,70.0,78.0,56.0,79.0,79.0,81.0,64.0,79.0,60.0,80.0,78.0,72.0,80.0,78.0,80.0,81.0,46.0,59.0,32.0,77.0,61.0,63.0,63.0,82.0,82.0,61.0,65.0,51.0,59.0,68.0,72.0,59.0,70.0,69.0,79.0,74.0,74.0,80.0,77.0,78.0,54.0,78.0,81.0,78.0,78.0,63.0,39.0,51.0,63.0,48.0,81.0,79.0,78.0,55.0,76.0,73.0,81.0,79.0,63.0,81.0,49.0,57.0,81.0,74.0,39.0,80.0,81.0,79.0,73.0,77.0,78.0,68.0,57.0,77.0,51.0,60.0,66.0,57.0,68.0,68.0,57.0,14.0,75.0,71.0,78.0],\"xaxis\":\"x\",\"yaxis\":\"y\",\"type\":\"histogram\"},{\"alignmentgroup\":\"True\",\"bingroup\":\"x\",\"hovertemplate\":\"stroke=0<br>age=%{x}<br>count=%{y}<extra></extra>\",\"legendgroup\":\"0\",\"marker\":{\"color\":\"purple\",\"pattern\":{\"shape\":\"\"}},\"name\":\"0\",\"offsetgroup\":\"0\",\"orientation\":\"v\",\"showlegend\":true,\"x\":[3.0,58.0,8.0,70.0,14.0,47.0,52.0,75.0,32.0,74.0,79.0,79.0,37.0,37.0,40.0,35.0,20.0,42.0,44.0,79.0,65.0,57.0,49.0,71.0,59.0,25.0,67.0,38.0,54.0,70.0,27.0,47.0,58.0,3.0,58.0,14.0,32.0,23.0,55.0,17.0,59.0,13.0,4.0,16.0,67.0,22.0,45.0,66.0,58.0,69.0,58.0,53.0,78.0,44.0,66.0,27.0,43.0,13.0,51.0,30.0,46.0,43.0,79.0,27.0,38.0,78.0,57.0,61.0,37.0,48.0,29.0,22.0,11.0,22.0,53.0,27.0,76.0,57.0,8.0,21.0,18.0,78.0,78.0,33.0,52.0,51.0,11.0,48.0,82.0,54.0,49.0,24.0,37.0,34.0,64.0,66.0,23.0,68.0,55.0,25.0,48.0,79.0,47.0,20.0,60.0,32.0,66.0,43.0,36.0,52.0,29.0,76.0,39.0,76.0,0.64,34.0,72.0,43.0,57.0,44.0,4.0,44.0,18.0,41.0,23.0,53.0,56.0,0.88,25.0,14.0,53.0,4.0,39.0,53.0,5.0,4.0,37.0,70.0,24.0,55.0,70.0,34.0,26.0,39.0,38.0,20.0,17.0,60.0,75.0,31.0,58.0,5.0,13.0,22.0,52.0,61.0,78.0,57.0,21.0,22.0,80.0,7.0,64.0,64.0,38.0,12.0,33.0,3.0,37.0,22.0,24.0,75.0,12.0,63.0,52.0,68.0,5.0,56.0,43.0,40.0,53.0,52.0,31.0,63.0,69.0,64.0,64.0,62.0,2.0,53.0,65.0,22.0,26.0,53.0,20.0,63.0,13.0,21.0,65.0,65.0,42.0,72.0,13.0,29.0,59.0,42.0,13.0,75.0,33.0,43.0,11.0,7.0,16.0,44.0,78.0,25.0,69.0,61.0,43.0,38.0,68.0,26.0,18.0,43.0,43.0,32.0,81.0,25.0,61.0,66.0,54.0,11.0,53.0,78.0,9.0,48.0,31.0,20.0,21.0,42.0,35.0,53.0,60.0,74.0,23.0,55.0,71.0,5.0,14.0,15.0,66.0,56.0,60.0,57.0,29.0,76.0,52.0,42.0,71.0,64.0,39.0,46.0,51.0,31.0,22.0,41.0,28.0,44.0,68.0,49.0,10.0,31.0,67.0,40.0,70.0,38.0,5.0,54.0,30.0,23.0,31.0,72.0,23.0,25.0,51.0,20.0,12.0,57.0,65.0,16.0,43.0,30.0,29.0,54.0,57.0,42.0,18.0,9.0,26.0,40.0,77.0,15.0,76.0,52.0,55.0,5.0,55.0,36.0,46.0,5.0,39.0,12.0,67.0,1.8,72.0,0.32,64.0,27.0,25.0,81.0,32.0,57.0,52.0,54.0,36.0,18.0,45.0,29.0,51.0,23.0,54.0,54.0,18.0,26.0,72.0,5.0,65.0,42.0,47.0,24.0,57.0,51.0,48.0,56.0,30.0,63.0,46.0,53.0,1.08,15.0,59.0,24.0,53.0,39.0,23.0,31.0,5.0,44.0,1.8,40.0,7.0,56.0,42.0,48.0,82.0,52.0,42.0,73.0,55.0,50.0,43.0,33.0,80.0,33.0,74.0,65.0,40.0,52.0,66.0,20.0,51.0,60.0,59.0,58.0,42.0,28.0,57.0,66.0,56.0,48.0,37.0,27.0,15.0,61.0,80.0,43.0,53.0,70.0,58.0,49.0,65.0,54.0,74.0,56.0,79.0,71.0,28.0,9.0,4.0,36.0,78.0,52.0,80.0,28.0,38.0,56.0,75.0,76.0,10.0,48.0,40.0,82.0,61.0,17.0,58.0,12.0,53.0,26.0,48.0,25.0,27.0,31.0,16.0,20.0,2.0,1.8,28.0,32.0,35.0,52.0,55.0,42.0,52.0,18.0,13.0,45.0,29.0,12.0,37.0,30.0,44.0,79.0,38.0,45.0,66.0,19.0,49.0,66.0,47.0,59.0,23.0,79.0,37.0,78.0,70.0,34.0,28.0,29.0,13.0,22.0,56.0,81.0,28.0,9.0,50.0,70.0,30.0,51.0,24.0,17.0,43.0,9.0,50.0,49.0,6.0,30.0,73.0,20.0,42.0,79.0,55.0,27.0,71.0,9.0,23.0,71.0,56.0,31.0,64.0,46.0,55.0,2.0,58.0,78.0,1.16,35.0,64.0,18.0,19.0,47.0,54.0,39.0,37.0,17.0,20.0,31.0,56.0,31.0,82.0,33.0,42.0,20.0,22.0,61.0,31.0,31.0,17.0,30.0,69.0,63.0,19.0,7.0,51.0,38.0,2.0,58.0,69.0,64.0,31.0,59.0,54.0,24.0,19.0,17.0,29.0,42.0,31.0,29.0,23.0,25.0,14.0,66.0,77.0,79.0,52.0,41.0,31.0,39.0,51.0,40.0,48.0,55.0,41.0,39.0,41.0,5.0,38.0,40.0,12.0,20.0,53.0,21.0,70.0,61.0,70.0,38.0,59.0,36.0,31.0,65.0,61.0,2.0,52.0,33.0,5.0,32.0,54.0,51.0,39.0,40.0,19.0,9.0,53.0,23.0,19.0,1.0,48.0,71.0,44.0,53.0,70.0,1.4,49.0,17.0,40.0,46.0,32.0,2.0,40.0,19.0,43.0,46.0,71.0,31.0,41.0,65.0,52.0,20.0,77.0,51.0,37.0,49.0,62.0,17.0,28.0,80.0,45.0,37.0,3.0,26.0,71.0,58.0,59.0,74.0,17.0,62.0,37.0,19.0,59.0,59.0,62.0,80.0,54.0,27.0,4.0,81.0,41.0,27.0,51.0,59.0,51.0,71.0,48.0,49.0,35.0,25.0,31.0,68.0,39.0,32.0,39.0,63.0,69.0,29.0,1.72,58.0,32.0,63.0,57.0,77.0,8.0,21.0,16.0,8.0,71.0,74.0,7.0,19.0,64.0,23.0,75.0,80.0,40.0,24.0,74.0,52.0,54.0,23.0,19.0,23.0,13.0,51.0,60.0,79.0,75.0,69.0,57.0,47.0,33.0,51.0,47.0,15.0,1.0,20.0,6.0,50.0,31.0,15.0,3.0,30.0,17.0,24.0,5.0,33.0,30.0,66.0,40.0,27.0,21.0,55.0,19.0,75.0,71.0,16.0,49.0,10.0,37.0,59.0,7.0,61.0,34.0,9.0,46.0,0.88,50.0,19.0,21.0,2.0,37.0,20.0,50.0,61.0,48.0,82.0,64.0,50.0,1.4,0.24,55.0,29.0,4.0,70.0,35.0,80.0,54.0,39.0,26.0,6.0,41.0,42.0,9.0,55.0,71.0,14.0,77.0,50.0,49.0,51.0,79.0,63.0,66.0,20.0,37.0,22.0,60.0,39.0,53.0,55.0,63.0,57.0,82.0,56.0,41.0,8.0,34.0,75.0,57.0,72.0,21.0,51.0,15.0,24.0,30.0,82.0,62.0,79.0,19.0,45.0,5.0,57.0,31.0,61.0,27.0,61.0,53.0,76.0,57.0,9.0,34.0,51.0,61.0,19.0,50.0,80.0,13.0,55.0,67.0,30.0,67.0,82.0,5.0,81.0,48.0,66.0,38.0,8.0,47.0,27.0,53.0,27.0,36.0,50.0,32.0,58.0,73.0,62.0,50.0,51.0,19.0,30.0,45.0,30.0,28.0,70.0,0.32,23.0,18.0,41.0,52.0,77.0,34.0,67.0,1.64,23.0,59.0,62.0,47.0,71.0,22.0,33.0,27.0,44.0,18.0,47.0,66.0,42.0,13.0,56.0,69.0,65.0,53.0,36.0,69.0,19.0,3.0,15.0,59.0,61.0,28.0,52.0,33.0,80.0,47.0,2.0,48.0,1.56,26.0,62.0,1.72,38.0,28.0,67.0,57.0,40.0,10.0,55.0,7.0,56.0,37.0,69.0,45.0,28.0,52.0,46.0,45.0,21.0,4.0,45.0,71.0,46.0,3.0,79.0,71.0,74.0,52.0,49.0,32.0,62.0,78.0,48.0,18.0,80.0,34.0,40.0,59.0,11.0,35.0,29.0,23.0,59.0,44.0,62.0,32.0,2.0,73.0,79.0,2.0,43.0,43.0,62.0,73.0,31.0,42.0,20.0,55.0,3.0,23.0,33.0,14.0,79.0,64.0,76.0,46.0,80.0,21.0,33.0,32.0,0.72,49.0,41.0,37.0,58.0,79.0,23.0,78.0,51.0,41.0,68.0,30.0,1.88,32.0,20.0,20.0,10.0,8.0,65.0,65.0,46.0,53.0,79.0,43.0,56.0,3.0,32.0,41.0,53.0,35.0,67.0,33.0,21.0,26.0,69.0,73.0,15.0,3.0,1.24,80.0,2.0,50.0,30.0,15.0,71.0,4.0,2.0,11.0,45.0,22.0,63.0,50.0,25.0,49.0,39.0,43.0,67.0,48.0,38.0,14.0,63.0,37.0,20.0,60.0,13.0,34.0,22.0,46.0,53.0,28.0,62.0,6.0,11.0,66.0,80.0,8.0,53.0,63.0,31.0,43.0,79.0,8.0,38.0,80.0,49.0,50.0,13.0,46.0,73.0,60.0,44.0,79.0,5.0,51.0,71.0,5.0,65.0,81.0,46.0,44.0,54.0,25.0,49.0,80.0,22.0,61.0,3.0,50.0,45.0,55.0,21.0,0.8,50.0,73.0,58.0,30.0,55.0,57.0,80.0,77.0,29.0,46.0,40.0,29.0,37.0,35.0,54.0,56.0,26.0,75.0,44.0,63.0,17.0,46.0,47.0,50.0,49.0,76.0,47.0,47.0,49.0,71.0,65.0,40.0,82.0,64.0,72.0,50.0,40.0,74.0,30.0,68.0,6.0,4.0,60.0,59.0,72.0,62.0,13.0,72.0,1.08,35.0,54.0,40.0,3.0,2.0,41.0,61.0,58.0,17.0,64.0,32.0,42.0,39.0,10.0,78.0,68.0,24.0,59.0,45.0,12.0,37.0,43.0,12.0,13.0,74.0,2.0,59.0,21.0,55.0,14.0,53.0,75.0,37.0,49.0,55.0,57.0,45.0,46.0,12.0,12.0,77.0,6.0,76.0,52.0,62.0,82.0,69.0,78.0,37.0,50.0,41.0,54.0,43.0,37.0,9.0,11.0,56.0,5.0,17.0,6.0,25.0,57.0,18.0,2.0,76.0,1.0,54.0,45.0,54.0,67.0,53.0,47.0,44.0,65.0,40.0,3.0,81.0,24.0,9.0,52.0,63.0,78.0,22.0,2.0,79.0,49.0,74.0,62.0,16.0,62.0,27.0,50.0,49.0,24.0,21.0,17.0,22.0,13.0,21.0,51.0,8.0,48.0,16.0,18.0,7.0,68.0,49.0,80.0,31.0,25.0,39.0,35.0,71.0,71.0,40.0,41.0,2.0,3.0,53.0,1.88,60.0,5.0,30.0,49.0,68.0,23.0,2.0,24.0,41.0,63.0,64.0,38.0,1.24,38.0,43.0,27.0,61.0,42.0,46.0,67.0,34.0,51.0,77.0,30.0,81.0,12.0,18.0,35.0,82.0,53.0,75.0,32.0,27.0,56.0,71.0,78.0,44.0,62.0,27.0,42.0,66.0,25.0,82.0,49.0,77.0,59.0,54.0,38.0,55.0,13.0,45.0,54.0,30.0,51.0,47.0,25.0,61.0,55.0,23.0,71.0,59.0,4.0,65.0,50.0,42.0,51.0,66.0,22.0,5.0,19.0,47.0,12.0,53.0,26.0,62.0,81.0,63.0,25.0,8.0,76.0,44.0,65.0,54.0,24.0,65.0,12.0,33.0,74.0,18.0,77.0,48.0,52.0,23.0,25.0,44.0,78.0,37.0,32.0,67.0,41.0,2.0,75.0,17.0,13.0,25.0,57.0,31.0,61.0,46.0,47.0,15.0,47.0,68.0,0.4,40.0,62.0,45.0,47.0,35.0,51.0,60.0,59.0,1.24,18.0,81.0,15.0,73.0,0.08,53.0,45.0,70.0,56.0,7.0,66.0,53.0,20.0,15.0,51.0,34.0,33.0,53.0,69.0,28.0,81.0,20.0,1.48,2.0,77.0,38.0,23.0,67.0,59.0,41.0,76.0,21.0,41.0,54.0,29.0,25.0,48.0,6.0,21.0,32.0,57.0,64.0,70.0,44.0,60.0,56.0,53.0,59.0,53.0,63.0,42.0,63.0,52.0,62.0,68.0,36.0,3.0,40.0,8.0,58.0,45.0,65.0,28.0,40.0,65.0,58.0,44.0,54.0,79.0,62.0,37.0,66.0,63.0,27.0,6.0,30.0,15.0,50.0,32.0,33.0,62.0,82.0,71.0,20.0,44.0,57.0,50.0,50.0,44.0,47.0,35.0,8.0,3.0,29.0,36.0,19.0,41.0,23.0,14.0,35.0,45.0,52.0,19.0,21.0,8.0,35.0,33.0,53.0,59.0,34.0,31.0,43.0,61.0,57.0,11.0,36.0,16.0,60.0,13.0,69.0,69.0,22.0,63.0,45.0,58.0,61.0,30.0,78.0,68.0,16.0,38.0,39.0,51.0,37.0,16.0,39.0,24.0,51.0,50.0,27.0,73.0,65.0,76.0,66.0,53.0,65.0,48.0,31.0,1.72,45.0,56.0,62.0,35.0,16.0,31.0,5.0,26.0,10.0,22.0,82.0,50.0,47.0,31.0,22.0,12.0,63.0,78.0,4.0,76.0,32.0,81.0,39.0,59.0,2.0,37.0,78.0,75.0,34.0,48.0,13.0,54.0,13.0,24.0,76.0,1.0,57.0,46.0,26.0,56.0,34.0,25.0,60.0,22.0,35.0,48.0,38.0,12.0,22.0,0.64,13.0,78.0,23.0,35.0,78.0,50.0,61.0,60.0,43.0,60.0,51.0,21.0,16.0,25.0,36.0,8.0,48.0,14.0,60.0,61.0,60.0,56.0,9.0,45.0,14.0,37.0,52.0,30.0,60.0,47.0,82.0,64.0,12.0,79.0,77.0,25.0,26.0,14.0,42.0,37.0,8.0,78.0,18.0,78.0,55.0,68.0,47.0,47.0,51.0,43.0,78.0,63.0,45.0,53.0,12.0,56.0,29.0,10.0,55.0,49.0,23.0,53.0,56.0,56.0,61.0,45.0,80.0,47.0,3.0,63.0,68.0,76.0,62.0,30.0,44.0,47.0,25.0,31.0,71.0,32.0,72.0,44.0,63.0,37.0,54.0,20.0,56.0,25.0,19.0,62.0,27.0,5.0,20.0,21.0,44.0,39.0,38.0,77.0,26.0,51.0,39.0,5.0,59.0,67.0,45.0,43.0,80.0,42.0,8.0,68.0,5.0,57.0,44.0,16.0,60.0,58.0,43.0,50.0,1.48,5.0,9.0,67.0,21.0,36.0,70.0,57.0,52.0,28.0,41.0,81.0,33.0,31.0,42.0,10.0,34.0,70.0,33.0,58.0,25.0,1.4,47.0,14.0,82.0,52.0,72.0,52.0,61.0,15.0,1.56,6.0,3.0,18.0,53.0,58.0,31.0,29.0,5.0,40.0,75.0,52.0,39.0,40.0,78.0,39.0,17.0,45.0,0.56,13.0,26.0,42.0,44.0,3.0,42.0,25.0,41.0,51.0,20.0,25.0,18.0,37.0,51.0,2.0,38.0,64.0,60.0,22.0,71.0,32.0,32.0,63.0,0.24,54.0,25.0,80.0,31.0,53.0,35.0,31.0,60.0,0.56,21.0,78.0,59.0,0.64,10.0,60.0,11.0,48.0,50.0,69.0,20.0,22.0,55.0,57.0,29.0,32.0,54.0,37.0,58.0,41.0,72.0,0.48,32.0,54.0,79.0,56.0,45.0,6.0,45.0,60.0,65.0,57.0,58.0,8.0,18.0,49.0,2.0,52.0,63.0,57.0,50.0,12.0,35.0,35.0,64.0,42.0,62.0,3.0,43.0,52.0,64.0,59.0,81.0,15.0,50.0,73.0,19.0,30.0,40.0,47.0,66.0,47.0,41.0,63.0,12.0,1.32,46.0,8.0,74.0,74.0,4.0,26.0,63.0,48.0,24.0,47.0,70.0,41.0,42.0,57.0,51.0,15.0,11.0,27.0,53.0,52.0,68.0,65.0,23.0,43.0,55.0,52.0,21.0,78.0,35.0,49.0,50.0,27.0,52.0,22.0,19.0,77.0,57.0,13.0,14.0,29.0,49.0,1.24,21.0,36.0,42.0,56.0,46.0,79.0,25.0,67.0,37.0,44.0,36.0,17.0,50.0,53.0,39.0,71.0,18.0,55.0,52.0,27.0,24.0,72.0,41.0,29.0,26.0,23.0,43.0,43.0,49.0,13.0,26.0,10.0,39.0,41.0,25.0,10.0,54.0,7.0,53.0,55.0,6.0,72.0,42.0,50.0,55.0,47.0,3.0,49.0,12.0,28.0,40.0,55.0,9.0,77.0,18.0,73.0,67.0,58.0,2.0,38.0,5.0,34.0,78.0,57.0,17.0,71.0,19.0,56.0,64.0,13.0,40.0,80.0,62.0,79.0,9.0,77.0,26.0,1.72,16.0,40.0,46.0,45.0,59.0,31.0,69.0,73.0,56.0,80.0,60.0,40.0,30.0,66.0,78.0,37.0,41.0,34.0,18.0,69.0,67.0,28.0,3.0,57.0,34.0,50.0,55.0,2.0,27.0,57.0,73.0,52.0,65.0,48.0,54.0,8.0,45.0,48.0,77.0,34.0,33.0,39.0,39.0,40.0,46.0,1.0,5.0,14.0,49.0,45.0,13.0,76.0,14.0,20.0,9.0,78.0,49.0,55.0,43.0,16.0,58.0,67.0,71.0,8.0,18.0,47.0,59.0,28.0,20.0,67.0,71.0,56.0,44.0,6.0,78.0,32.0,40.0,63.0,51.0,22.0,82.0,17.0,34.0,42.0,32.0,73.0,47.0,34.0,64.0,52.0,49.0,55.0,64.0,23.0,18.0,65.0,12.0,61.0,66.0,59.0,47.0,47.0,71.0,62.0,28.0,7.0,68.0,37.0,75.0,5.0,1.08,34.0,49.0,8.0,50.0,2.0,1.16,76.0,18.0,82.0,67.0,27.0,57.0,51.0,68.0,56.0,77.0,52.0,18.0,63.0,31.0,37.0,64.0,47.0,1.8,42.0,37.0,69.0,13.0,73.0,48.0,78.0,21.0,54.0,43.0,19.0,82.0,80.0,69.0,21.0,46.0,14.0,6.0,3.0,47.0,34.0,41.0,67.0,5.0,20.0,63.0,73.0,62.0,0.88,50.0,71.0,30.0,80.0,64.0,7.0,36.0,79.0,35.0,28.0,72.0,12.0,25.0,27.0,62.0,58.0,30.0,56.0,28.0,47.0,16.0,29.0,26.0,26.0,55.0,29.0,29.0,33.0,19.0,10.0,3.0,60.0,16.0,35.0,41.0,19.0,79.0,41.0,1.64,51.0,33.0,33.0,48.0,45.0,61.0,31.0,60.0,51.0,53.0,52.0,42.0,56.0,14.0,40.0,58.0,52.0,30.0,47.0,34.0,82.0,31.0,58.0,47.0,65.0,13.0,37.0,9.0,7.0,37.0,62.0,14.0,77.0,36.0,3.0,78.0,49.0,44.0,10.0,8.0,60.0,56.0,73.0,65.0,34.0,13.0,80.0,46.0,80.0,65.0,24.0,33.0,11.0,57.0,19.0,82.0,39.0,14.0,60.0,3.0,57.0,79.0,65.0,67.0,60.0,36.0,36.0,26.0,71.0,78.0,77.0,74.0,50.0,9.0,1.64,54.0,8.0,36.0,38.0,34.0,7.0,5.0,14.0,0.88,30.0,39.0,17.0,14.0,52.0,78.0,2.0,32.0,0.88,50.0,48.0,66.0,78.0,46.0,54.0,81.0,15.0,77.0,59.0,48.0,76.0,49.0,44.0,39.0,34.0,50.0,62.0,38.0,43.0,28.0,58.0,28.0,18.0,62.0,31.0,55.0,54.0,73.0,26.0,73.0,38.0,75.0,81.0,20.0,12.0,78.0,42.0,71.0,16.0,4.0,79.0,60.0,45.0,23.0,21.0,67.0,10.0,24.0,50.0,79.0,14.0,13.0,71.0,66.0,32.0,46.0,48.0,45.0,55.0,31.0,25.0,73.0,14.0,56.0,60.0,27.0,28.0,46.0,11.0,63.0,59.0,57.0,35.0,54.0,7.0,48.0,69.0,59.0,72.0,49.0,73.0,24.0,26.0,27.0,78.0,77.0,59.0,0.32,39.0,35.0,54.0,75.0,80.0,35.0,22.0,39.0,6.0,62.0,13.0,56.0,53.0,5.0,44.0,13.0,59.0,35.0,52.0,76.0,51.0,79.0,69.0,78.0,60.0,10.0,42.0,21.0,56.0,59.0,69.0,25.0,63.0,25.0,58.0,28.0,46.0,53.0,37.0,12.0,14.0,60.0,42.0,65.0,80.0,32.0,53.0,50.0,23.0,45.0,0.8,49.0,70.0,82.0,23.0,79.0,74.0,78.0,50.0,34.0,47.0,52.0,67.0,62.0,18.0,75.0,42.0,29.0,52.0,18.0,67.0,66.0,5.0,18.0,52.0,44.0,46.0,36.0,61.0,7.0,15.0,61.0,20.0,2.0,47.0,25.0,66.0,2.0,63.0,53.0,33.0,23.0,23.0,81.0,55.0,69.0,58.0,70.0,48.0,15.0,31.0,2.0,80.0,69.0,52.0,80.0,54.0,2.0,39.0,38.0,76.0,45.0,1.24,77.0,46.0,50.0,52.0,73.0,41.0,40.0,59.0,48.0,42.0,26.0,39.0,34.0,54.0,57.0,1.56,50.0,64.0,44.0,38.0,32.0,17.0,81.0,15.0,5.0,70.0,52.0,67.0,17.0,61.0,31.0,58.0,12.0,30.0,65.0,23.0,14.0,27.0,53.0,58.0,9.0,59.0,46.0,41.0,55.0,43.0,5.0,15.0,36.0,36.0,47.0,18.0,19.0,65.0,17.0,54.0,46.0,59.0,48.0,38.0,18.0,56.0,3.0,41.0,67.0,60.0,47.0,24.0,43.0,17.0,45.0,24.0,79.0,79.0,27.0,72.0,64.0,34.0,50.0,58.0,26.0,50.0,80.0,2.0,46.0,29.0,6.0,32.0,16.0,44.0,23.0,48.0,34.0,78.0,42.0,14.0,40.0,10.0,39.0,42.0,47.0,14.0,45.0,58.0,73.0,62.0,62.0,51.0,0.8,57.0,8.0,69.0,16.0,56.0,41.0,1.24,42.0,57.0,20.0,8.0,43.0,62.0,42.0,50.0,63.0,80.0,13.0,20.0,71.0,50.0,76.0,41.0,76.0,78.0,5.0,29.0,43.0,49.0,70.0,24.0,41.0,20.0,34.0,32.0,27.0,44.0,20.0,52.0,57.0,29.0,16.0,35.0,5.0,63.0,59.0,63.0,52.0,50.0,43.0,27.0,30.0,8.0,75.0,14.0,23.0,6.0,37.0,38.0,3.0,26.0,58.0,57.0,58.0,76.0,68.0,79.0,34.0,75.0,11.0,71.0,40.0,24.0,0.64,82.0,32.0,81.0,33.0,79.0,62.0,39.0,60.0,48.0,24.0,70.0,17.0,56.0,3.0,65.0,72.0,10.0,29.0,44.0,46.0,33.0,63.0,0.24,55.0,56.0,50.0,78.0,63.0,31.0,65.0,51.0,60.0,69.0,23.0,46.0,16.0,26.0,44.0,56.0,23.0,38.0,18.0,63.0,23.0,32.0,8.0,77.0,41.0,34.0,25.0,35.0,15.0,1.64,4.0,33.0,28.0,37.0,50.0,76.0,72.0,16.0,44.0,46.0,46.0,73.0,29.0,19.0,27.0,36.0,61.0,9.0,25.0,68.0,26.0,17.0,75.0,34.0,53.0,18.0,48.0,5.0,79.0,16.0,32.0,70.0,55.0,70.0,51.0,39.0,79.0,80.0,34.0,59.0,54.0,22.0,21.0,4.0,26.0,62.0,33.0,51.0,75.0,42.0,82.0,61.0,62.0,59.0,31.0,12.0,76.0,71.0,15.0,44.0,30.0,47.0,47.0,60.0,62.0,47.0,78.0,35.0,71.0,57.0,12.0,26.0,33.0,60.0,35.0,10.0,50.0,44.0,73.0,41.0,7.0,45.0,60.0,49.0,45.0,55.0,54.0,39.0,76.0,28.0,70.0,28.0,79.0,30.0,26.0,57.0,16.0,40.0,77.0,67.0,36.0,40.0,2.0,52.0,78.0,22.0,33.0,40.0,20.0,19.0,25.0,23.0,28.0,6.0,37.0,10.0,34.0,60.0,22.0,62.0,52.0,61.0,10.0,36.0,29.0,69.0,62.0,62.0,79.0,13.0,38.0,49.0,41.0,56.0,8.0,24.0,61.0,40.0,22.0,80.0,60.0,57.0,55.0,39.0,51.0,47.0,77.0,32.0,45.0,49.0,13.0,74.0,72.0,57.0,51.0,55.0,73.0,12.0,6.0,76.0,38.0,50.0,75.0,1.16,32.0,12.0,32.0,13.0,1.32,63.0,29.0,53.0,49.0,81.0,66.0,42.0,61.0,52.0,8.0,82.0,43.0,4.0,58.0,45.0,62.0,42.0,72.0,26.0,9.0,31.0,20.0,22.0,23.0,57.0,52.0,64.0,26.0,54.0,32.0,66.0,13.0,77.0,18.0,11.0,16.0,73.0,44.0,36.0,10.0,54.0,42.0,52.0,32.0,43.0,28.0,79.0,11.0,75.0,55.0,78.0,48.0,73.0,56.0,54.0,55.0,65.0,69.0,29.0,64.0,16.0,75.0,17.0,42.0,78.0,24.0,68.0,50.0,52.0,82.0,56.0,56.0,18.0,33.0,57.0,30.0,52.0,3.0,39.0,44.0,33.0,24.0,24.0,54.0,72.0,37.0,36.0,22.0,68.0,24.0,35.0,32.0,52.0,21.0,82.0,33.0,62.0,57.0,14.0,60.0,63.0,50.0,12.0,80.0,74.0,46.0,66.0,26.0,70.0,62.0,15.0,67.0,63.0,42.0,49.0,78.0,31.0,67.0,52.0,61.0,41.0,73.0,64.0,65.0,81.0,47.0,40.0,46.0,2.0,56.0,54.0,26.0,45.0,57.0,78.0,2.0,76.0,51.0,54.0,36.0,57.0,25.0,7.0,76.0,45.0,66.0,45.0,79.0,25.0,53.0,35.0,78.0,32.0,0.56,26.0,34.0,65.0,15.0,17.0,71.0,42.0,30.0,75.0,9.0,47.0,75.0,61.0,61.0,27.0,55.0,2.0,51.0,45.0,36.0,46.0,48.0,79.0,50.0,79.0,32.0,36.0,27.0,22.0,5.0,9.0,31.0,26.0,43.0,33.0,34.0,66.0,44.0,56.0,67.0,18.0,55.0,61.0,0.08,48.0,44.0,68.0,52.0,15.0,2.0,60.0,37.0,5.0,25.0,52.0,79.0,61.0,36.0,34.0,2.0,43.0,1.48,49.0,2.0,82.0,81.0,81.0,1.08,60.0,1.88,58.0,8.0,9.0,34.0,23.0,74.0,72.0,47.0,56.0,5.0,27.0,38.0,13.0,41.0,50.0,41.0,6.0,62.0,4.0,59.0,63.0,9.0,41.0,72.0,45.0,80.0,19.0,37.0,58.0,77.0,38.0,49.0,20.0,23.0,55.0,16.0,81.0,23.0,82.0,48.0,56.0,61.0,43.0,39.0,22.0,41.0,37.0,65.0,8.0,51.0,63.0,48.0,17.0,53.0,75.0,51.0,51.0,41.0,75.0,57.0,33.0,72.0,52.0,11.0,28.0,78.0,82.0,74.0,31.0,53.0,0.24,67.0,17.0,29.0,56.0,15.0,29.0,79.0,82.0,17.0,8.0,23.0,36.0,47.0,24.0,60.0,63.0,44.0,38.0,26.0,18.0,18.0,13.0,13.0,47.0,80.0,24.0,72.0,5.0,51.0,82.0,5.0,66.0,53.0,15.0,53.0,78.0,62.0,41.0,49.0,41.0,78.0,14.0,1.48,71.0,32.0,16.0,68.0,0.56,59.0,32.0,58.0,40.0,41.0,21.0,1.88,55.0,67.0,49.0,42.0,54.0,25.0,62.0,75.0,72.0,14.0,38.0,59.0,23.0,63.0,82.0,34.0,8.0,28.0,49.0,24.0,17.0,69.0,58.0,50.0,5.0,34.0,64.0,47.0,61.0,14.0,57.0,53.0,67.0,57.0,38.0,13.0,37.0,39.0,13.0,57.0,11.0,68.0,79.0,24.0,44.0,46.0,66.0,61.0,16.0,37.0,43.0,27.0,44.0,14.0,81.0,52.0,54.0,77.0,27.0,35.0,30.0,48.0,15.0,26.0,38.0,29.0,49.0,55.0,52.0,49.0,21.0,24.0,18.0,52.0,70.0,51.0,58.0,46.0,79.0,11.0,61.0,51.0,21.0,71.0,13.0,16.0,61.0,49.0,65.0,40.0,44.0,11.0,20.0,24.0,44.0,5.0,41.0,23.0,7.0,74.0,61.0,80.0,35.0,43.0,25.0,72.0,45.0,9.0,33.0,53.0,67.0,59.0,1.32,27.0,41.0,64.0,55.0,40.0,33.0,33.0,39.0,74.0,38.0,53.0,22.0,5.0,24.0,27.0,41.0,20.0,71.0,65.0,38.0,25.0,53.0,50.0,1.24,55.0,38.0,72.0,43.0,30.0,69.0,61.0,34.0,43.0,62.0,48.0,37.0,64.0,51.0,69.0,75.0,27.0,49.0,82.0,36.0,1.88,45.0,64.0,32.0,15.0,1.64,34.0,17.0,76.0,61.0,30.0,18.0,48.0,0.16,4.0,38.0,27.0,50.0,19.0,8.0,78.0,0.8,53.0,73.0,34.0,58.0,62.0,78.0,51.0,78.0,40.0,35.0,82.0,46.0,51.0,53.0,55.0,43.0,81.0,12.0,20.0,53.0,1.32,22.0,75.0,66.0,7.0,26.0,14.0,32.0,6.0,42.0,4.0,75.0,80.0,52.0,11.0,14.0,74.0,58.0,80.0,31.0,28.0,25.0,71.0,51.0,15.0,45.0,53.0,69.0,42.0,4.0,64.0,5.0,44.0,78.0,16.0,69.0,80.0,7.0,2.0,80.0,69.0,58.0,75.0,60.0,75.0,10.0,38.0,28.0,3.0,31.0,59.0,31.0,45.0,58.0,57.0,31.0,43.0,40.0,1.08,34.0,55.0,39.0,42.0,44.0,69.0,16.0,8.0,1.48,1.88,69.0,13.0,53.0,16.0,64.0,7.0,41.0,65.0,61.0,63.0,1.8,54.0,14.0,45.0,51.0,8.0,52.0,39.0,13.0,69.0,71.0,73.0,54.0,10.0,26.0,41.0,71.0,46.0,15.0,29.0,8.0,21.0,56.0,14.0,78.0,36.0,57.0,79.0,26.0,22.0,72.0,54.0,8.0,62.0,28.0,50.0,7.0,33.0,55.0,25.0,25.0,37.0,58.0,45.0,60.0,66.0,80.0,38.0,11.0,63.0,19.0,17.0,19.0,40.0,49.0,69.0,46.0,78.0,63.0,3.0,1.8,18.0,46.0,8.0,53.0,38.0,74.0,24.0,78.0,60.0,12.0,32.0,5.0,40.0,19.0,28.0,61.0,44.0,50.0,50.0,18.0,1.64,37.0,5.0,39.0,65.0,26.0,42.0,34.0,45.0,43.0,40.0,35.0,2.0,61.0,64.0,32.0,23.0,51.0,52.0,75.0,40.0,39.0,6.0,32.0,55.0,23.0,52.0,58.0,17.0,3.0,23.0,56.0,45.0,14.0,45.0,57.0,35.0,8.0,42.0,8.0,62.0,43.0,8.0,40.0,2.0,27.0,47.0,53.0,62.0,50.0,26.0,19.0,0.32,45.0,45.0,54.0,64.0,2.0,66.0,73.0,31.0,1.88,58.0,12.0,60.0,32.0,23.0,26.0,36.0,3.0,21.0,67.0,35.0,26.0,47.0,81.0,1.64,52.0,28.0,45.0,20.0,1.56,65.0,45.0,77.0,37.0,50.0,0.56,30.0,31.0,4.0,65.0,68.0,63.0,46.0,54.0,66.0,29.0,78.0,56.0,57.0,2.0,49.0,31.0,47.0,37.0,79.0,65.0,61.0,66.0,24.0,66.0,64.0,38.0,7.0,63.0,71.0,18.0,65.0,57.0,62.0,1.8,35.0,50.0,73.0,23.0,32.0,38.0,50.0,39.0,7.0,15.0,67.0,8.0,32.0,5.0,56.0,49.0,75.0,11.0,61.0,76.0,34.0,20.0,79.0,24.0,39.0,55.0,16.0,36.0,38.0,20.0,38.0,52.0,49.0,80.0,75.0,13.0,54.0,28.0,61.0,0.16,59.0,12.0,38.0,15.0,31.0,52.0,61.0,50.0,41.0,20.0,67.0,45.0,73.0,52.0,51.0,56.0,49.0,10.0,51.0,57.0,76.0,28.0,57.0,39.0,41.0,72.0,45.0,33.0,62.0,27.0,31.0,24.0,1.88,28.0,24.0,30.0,38.0,1.64,0.72,57.0,27.0,30.0,42.0,36.0,44.0,59.0,61.0,18.0,44.0,16.0,13.0,9.0,0.16,81.0,38.0,58.0,5.0,64.0,38.0,56.0,58.0,9.0,34.0,79.0,62.0,60.0,42.0,59.0,54.0,59.0,15.0,14.0,5.0,17.0,13.0,48.0,37.0,69.0,74.0,54.0,64.0,26.0,55.0,74.0,0.48,41.0,68.0,9.0,36.0,17.0,24.0,69.0,38.0,69.0,32.0,25.0,2.0,79.0,28.0,16.0,31.0,66.0,57.0,61.0,74.0,70.0,8.0,49.0,30.0,51.0,10.0,34.0,40.0,3.0,45.0,4.0,52.0,68.0,8.0,82.0,36.0,42.0,27.0,55.0,31.0,82.0,57.0,78.0,55.0,51.0,80.0,17.0,61.0,62.0,14.0,62.0,56.0,41.0,59.0,29.0,39.0,66.0,35.0,36.0,35.0,26.0,31.0,56.0,36.0,41.0,50.0,42.0,79.0,57.0,68.0,25.0,69.0,42.0,37.0,2.0,78.0,36.0,10.0,39.0,4.0,48.0,72.0,63.0,28.0,80.0,49.0,57.0,59.0,43.0,47.0,54.0,57.0,56.0,66.0,18.0,81.0,30.0,8.0,55.0,79.0,49.0,53.0,26.0,14.0,25.0,20.0,18.0,38.0,72.0,52.0,82.0,71.0,46.0,33.0,37.0,54.0,5.0,45.0,14.0,5.0,35.0,20.0,51.0,40.0,79.0,61.0,33.0,27.0,28.0,67.0,35.0,78.0,20.0,43.0,27.0,45.0,11.0,31.0,30.0,27.0,34.0,19.0,3.0,53.0,81.0,44.0,59.0,43.0,32.0,5.0,31.0,47.0,12.0,40.0,49.0,38.0,15.0,81.0,48.0,24.0,47.0,13.0,16.0,64.0,11.0,55.0,38.0,37.0,34.0,52.0,50.0,37.0,55.0,2.0,68.0,27.0,17.0,53.0,5.0,3.0,20.0,19.0,31.0,63.0,49.0,72.0,50.0,41.0,40.0,17.0,3.0,33.0,12.0,23.0,31.0,65.0,43.0,22.0,7.0,81.0,10.0,18.0,5.0,24.0,45.0,46.0,64.0,25.0,12.0,81.0,65.0,40.0,81.0,36.0,32.0,31.0,55.0,39.0,17.0,31.0,36.0,5.0,29.0,2.0,62.0,45.0,18.0,29.0,52.0,59.0,69.0,71.0,3.0,33.0,43.0,39.0,60.0,54.0,61.0,0.24,11.0,75.0,64.0,78.0,14.0,66.0,48.0,44.0,30.0,1.48,61.0,54.0,22.0,47.0,67.0,53.0,45.0,65.0,39.0,57.0,45.0,28.0,30.0,31.0,70.0,17.0,44.0,65.0,6.0,15.0,80.0,54.0,79.0,60.0,12.0,36.0,54.0,63.0,2.0,28.0,38.0,37.0,80.0,43.0,60.0,66.0,45.0,29.0,4.0,48.0,68.0,57.0,29.0,30.0,47.0,73.0,66.0,39.0,66.0,52.0,34.0,79.0,39.0,61.0,26.0,37.0,66.0,16.0,51.0,15.0,1.72,60.0,66.0,75.0,40.0,52.0,13.0,44.0,37.0,2.0,48.0,81.0,76.0,58.0,11.0,9.0,54.0,37.0,16.0,11.0,32.0,26.0,21.0,45.0,40.0,41.0,71.0,16.0,7.0,27.0,22.0,79.0,38.0,64.0,4.0,23.0,35.0,66.0,34.0,19.0,73.0,70.0,45.0,34.0,81.0,0.72,13.0,57.0,38.0,21.0,38.0,41.0,26.0,48.0,18.0,66.0,27.0,18.0,20.0,11.0,7.0,54.0,43.0,61.0,31.0,40.0,71.0,57.0,13.0,21.0,63.0,7.0,78.0,66.0,41.0,11.0,55.0,42.0,51.0,79.0,28.0,73.0,42.0,37.0,78.0,74.0,59.0,78.0,82.0,71.0,19.0,18.0,53.0,62.0,3.0,49.0,51.0,53.0,10.0,54.0,40.0,3.0,12.0,56.0,43.0,28.0,28.0,56.0,14.0,63.0,29.0,48.0,47.0,63.0,40.0,40.0,55.0,43.0,59.0,78.0,27.0,49.0,14.0,17.0,42.0,36.0,19.0,55.0,8.0,56.0,54.0,15.0,43.0,52.0,62.0,54.0,60.0,7.0,3.0,39.0,60.0,60.0,46.0,26.0,12.0,16.0,2.0,82.0,32.0,62.0,75.0,81.0,37.0,28.0,25.0,44.0,11.0,54.0,52.0,43.0,56.0,37.0,60.0,4.0,51.0,82.0,56.0,60.0,35.0,32.0,45.0,10.0,68.0,51.0,8.0,63.0,4.0,33.0,56.0,49.0,30.0,16.0,1.8,54.0,49.0,17.0,11.0,51.0,74.0,42.0,69.0,22.0,25.0,17.0,64.0,50.0,52.0,65.0,37.0,31.0,52.0,56.0,43.0,11.0,2.0,16.0,23.0,40.0,15.0,48.0,33.0,46.0,53.0,68.0,60.0,57.0,51.0,0.4,76.0,46.0,23.0,9.0,53.0,4.0,62.0,37.0,82.0,33.0,3.0,14.0,16.0,40.0,18.0,29.0,56.0,33.0,2.0,36.0,30.0,31.0,16.0,58.0,19.0,47.0,59.0,40.0,26.0,17.0,30.0,19.0,78.0,55.0,59.0,57.0,33.0,35.0,32.0,55.0,28.0,25.0,45.0,34.0,33.0,65.0,62.0,36.0,31.0,54.0,53.0,44.0,77.0,67.0,48.0,42.0,72.0,49.0,1.32,45.0,63.0,33.0,32.0,0.48,63.0,70.0,57.0,8.0,54.0,37.0,59.0,78.0,59.0,10.0,21.0,2.0,55.0,20.0,38.0,33.0,14.0,32.0,32.0,68.0,70.0,24.0,44.0,39.0,81.0,19.0,69.0,42.0,8.0,8.0,28.0,66.0,66.0,47.0,78.0,65.0,78.0,68.0,78.0,65.0,70.0,59.0,31.0,32.0,5.0,55.0,61.0,48.0,1.16,50.0,63.0,67.0,43.0,59.0,47.0,50.0,51.0,44.0,39.0,24.0,62.0,61.0,78.0,15.0,23.0,79.0,57.0,70.0,9.0,55.0,82.0,19.0,41.0,79.0,23.0,77.0,78.0,24.0,81.0,46.0,29.0,59.0,41.0,17.0,8.0,23.0,45.0,67.0,78.0,18.0,35.0,54.0,71.0,24.0,60.0,75.0,48.0,62.0,20.0,69.0,60.0,12.0,28.0,55.0,70.0,51.0,16.0,56.0,52.0,59.0,9.0,34.0,47.0,46.0,49.0,10.0,76.0,82.0,3.0,76.0,16.0,44.0,17.0,73.0,31.0,17.0,18.0,73.0,8.0,42.0,40.0,79.0,53.0,58.0,48.0,17.0,23.0,9.0,81.0,16.0,21.0,29.0,8.0,39.0,37.0,64.0,9.0,17.0,8.0,62.0,73.0,48.0,17.0,10.0,74.0,62.0,5.0,43.0,39.0,37.0,15.0,36.0,34.0,75.0,53.0,61.0,45.0,17.0,17.0,19.0,54.0,51.0,44.0,82.0,49.0,34.0,63.0,79.0,81.0,14.0,31.0,57.0,32.0,66.0,22.0,1.32,20.0,41.0,48.0,49.0,73.0,19.0,51.0,1.08,31.0,4.0,1.8,44.0,4.0,55.0,34.0,30.0,7.0,75.0,14.0,61.0,55.0,14.0,36.0,57.0,20.0,32.0,43.0,43.0,1.08,49.0,53.0,18.0,13.0,5.0,37.0,49.0,45.0,50.0,12.0,12.0,5.0,39.0,41.0,41.0,47.0,57.0,16.0,3.0,65.0,80.0,58.0,74.0,62.0,33.0,21.0,17.0,49.0,24.0,56.0,26.0,54.0,42.0,34.0,56.0,39.0,77.0,12.0,65.0,7.0,25.0,31.0,14.0,5.0,60.0,53.0,55.0,69.0,39.0,0.32,34.0,80.0,20.0,45.0,41.0,54.0,23.0,75.0,36.0,75.0,72.0,47.0,15.0,40.0,71.0,38.0,10.0,11.0,0.72,9.0,53.0,28.0,81.0,1.32,16.0,24.0,62.0,62.0,59.0,19.0,51.0,38.0,26.0,13.0,4.0,55.0,44.0,31.0,58.0,17.0,23.0,51.0,46.0,81.0,38.0,50.0,34.0,60.0,50.0,49.0,2.0,47.0,34.0,22.0,11.0,54.0,60.0,3.0,46.0,30.0,63.0,50.0,65.0,78.0,36.0,18.0,44.0,4.0,60.0,19.0,15.0,20.0,76.0,31.0,39.0,58.0,64.0,79.0,11.0,4.0,43.0,44.0,37.0,34.0,59.0,40.0,8.0,24.0,18.0,20.0,70.0,68.0,17.0,17.0,21.0,38.0,59.0,79.0,50.0,72.0,54.0,44.0,48.0,29.0,44.0,61.0,58.0,81.0,29.0,5.0,35.0,40.0,37.0,33.0,35.0,38.0,26.0,10.0,72.0,21.0,20.0,1.24,26.0,79.0,78.0,56.0,46.0,55.0,41.0,30.0,53.0,32.0,38.0,33.0,44.0,44.0,51.0,40.0,41.0,5.0,42.0,6.0,46.0,47.0,25.0,40.0,49.0,21.0,61.0,78.0,41.0,82.0,39.0,70.0,31.0,37.0,21.0,80.0,21.0,5.0,81.0,35.0,24.0,52.0,70.0,34.0,17.0,8.0,1.72,29.0,55.0,44.0,19.0,67.0,72.0,51.0,63.0,64.0,0.72,26.0,59.0,76.0,45.0,13.0,1.08,57.0,68.0,9.0,40.0,82.0,45.0,57.0,18.0,13.0,80.0,81.0,35.0,51.0,44.0],\"xaxis\":\"x\",\"yaxis\":\"y\",\"type\":\"histogram\"}],                        {\"template\":{\"data\":{\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"white\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"age\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"count\"}},\"legend\":{\"title\":{\"text\":\"stroke\"},\"tracegroupgap\":0},\"margin\":{\"t\":60},\"barmode\":\"relative\"},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('51127037-9a72-4ce8-8dd5-9b2e89a3a4f6');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fig = px.histogram(data, x=\"ever_married\", color=\"stroke\",color_discrete_map={0:'purple',1:'red'},height=800)\n",
        "fig.show()\n",
        "\n",
        "print(\"Married person has stroke rate of\",220/5110*100,\"%\")\n",
        "print(\"Unmarried person has stroke rate of\",29/5110*100,\"%\")\n",
        "\n",
        "#If you marry more chances are there you will die :))))))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 852
        },
        "id": "pfTjHnz92Wy3",
        "outputId": "205e13b2-6b27-42e6-de82-a197742e6c43"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-2.8.3.min.js\"></script>                <div id=\"9c85b6b7-927e-4e0d-947c-4007297d2f6b\" class=\"plotly-graph-div\" style=\"height:800px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"9c85b6b7-927e-4e0d-947c-4007297d2f6b\")) {                    Plotly.newPlot(                        \"9c85b6b7-927e-4e0d-947c-4007297d2f6b\",                        [{\"alignmentgroup\":\"True\",\"bingroup\":\"x\",\"hovertemplate\":\"stroke=1<br>ever_married=%{x}<br>count=%{y}<extra></extra>\",\"legendgroup\":\"1\",\"marker\":{\"color\":\"red\",\"pattern\":{\"shape\":\"\"}},\"name\":\"1\",\"offsetgroup\":\"1\",\"orientation\":\"v\",\"showlegend\":true,\"x\":[\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"No\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"No\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"Yes\"],\"xaxis\":\"x\",\"yaxis\":\"y\",\"type\":\"histogram\"},{\"alignmentgroup\":\"True\",\"bingroup\":\"x\",\"hovertemplate\":\"stroke=0<br>ever_married=%{x}<br>count=%{y}<extra></extra>\",\"legendgroup\":\"0\",\"marker\":{\"color\":\"purple\",\"pattern\":{\"shape\":\"\"}},\"name\":\"0\",\"offsetgroup\":\"0\",\"orientation\":\"v\",\"showlegend\":true,\"x\":[\"No\",\"Yes\",\"No\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"No\",\"Yes\",\"No\",\"Yes\",\"No\",\"Yes\",\"No\",\"Yes\",\"No\",\"No\",\"No\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"No\",\"No\",\"No\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"No\",\"No\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"No\",\"No\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"No\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"No\",\"No\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"No\",\"No\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"No\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"No\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"No\",\"Yes\",\"No\",\"Yes\",\"No\",\"Yes\",\"No\",\"No\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"No\",\"No\",\"Yes\",\"No\",\"Yes\",\"No\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"No\",\"Yes\",\"Yes\",\"No\",\"No\",\"Yes\",\"Yes\",\"No\",\"No\",\"No\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"No\",\"No\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"No\",\"No\",\"No\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"No\",\"No\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"No\",\"Yes\",\"No\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"No\",\"No\",\"Yes\",\"No\",\"Yes\",\"No\",\"Yes\",\"No\",\"Yes\",\"No\",\"Yes\",\"No\",\"No\",\"No\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"No\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"No\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"No\",\"Yes\",\"No\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"No\",\"No\",\"Yes\",\"No\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"No\",\"No\",\"No\",\"No\",\"No\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"No\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"No\",\"No\",\"No\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"No\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"No\",\"No\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"No\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"No\",\"No\",\"Yes\",\"Yes\",\"No\",\"No\",\"Yes\",\"No\",\"Yes\",\"No\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"No\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"No\",\"No\",\"Yes\",\"Yes\",\"No\",\"No\",\"No\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"No\",\"Yes\",\"Yes\",\"No\",\"No\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"No\",\"No\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"No\",\"No\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"No\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"No\",\"No\",\"No\",\"Yes\",\"Yes\",\"No\",\"No\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"No\",\"No\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"No\",\"No\",\"No\",\"No\",\"Yes\",\"No\",\"No\",\"Yes\",\"No\",\"No\",\"No\",\"No\",\"No\",\"Yes\",\"No\",\"No\",\"No\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"No\",\"No\",\"No\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"No\",\"No\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"No\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"No\",\"Yes\",\"No\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"No\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"No\",\"Yes\",\"No\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"No\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"No\",\"No\",\"No\",\"No\",\"Yes\",\"Yes\",\"No\",\"No\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"No\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"No\",\"No\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"No\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"No\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"No\",\"Yes\",\"No\",\"Yes\",\"No\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"No\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"No\",\"No\",\"No\",\"No\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"No\",\"No\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"No\",\"No\",\"No\",\"No\",\"No\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"No\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"No\",\"Yes\",\"Yes\",\"No\",\"No\",\"No\",\"Yes\",\"No\",\"Yes\",\"No\",\"No\",\"Yes\",\"No\",\"No\",\"No\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"No\",\"No\",\"Yes\",\"No\",\"No\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"No\",\"No\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"No\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"No\",\"No\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"No\",\"No\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"No\",\"No\",\"Yes\",\"No\",\"Yes\",\"No\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"No\",\"No\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"No\",\"Yes\",\"No\",\"No\",\"No\",\"Yes\",\"Yes\",\"No\",\"No\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"No\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"No\",\"No\",\"No\",\"No\",\"Yes\",\"No\",\"Yes\",\"No\",\"No\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"No\",\"Yes\",\"No\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"No\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"No\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"No\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"No\",\"No\",\"Yes\",\"No\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"No\",\"No\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"No\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"No\",\"Yes\",\"Yes\",\"No\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"No\",\"No\",\"Yes\",\"No\",\"No\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"No\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"No\",\"No\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"No\",\"No\",\"Yes\",\"No\",\"No\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"No\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"No\",\"No\",\"Yes\",\"No\",\"No\",\"Yes\",\"No\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"No\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"No\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"No\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"No\",\"Yes\",\"No\",\"Yes\",\"No\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"No\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"No\",\"Yes\",\"No\",\"No\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"No\",\"No\",\"No\",\"Yes\",\"No\",\"Yes\",\"No\",\"No\",\"No\",\"No\",\"Yes\",\"No\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"No\",\"No\",\"Yes\",\"No\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"No\",\"Yes\",\"No\",\"No\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"No\",\"No\",\"No\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"No\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"No\",\"No\",\"Yes\",\"No\",\"No\",\"No\",\"No\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"No\",\"No\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"No\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"No\",\"No\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"No\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"No\",\"No\",\"No\",\"No\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"No\",\"No\",\"Yes\",\"Yes\",\"No\",\"No\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"No\",\"No\",\"Yes\",\"Yes\",\"No\",\"No\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"No\",\"Yes\",\"No\",\"No\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"No\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"No\",\"No\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"No\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"No\",\"No\",\"Yes\",\"No\",\"No\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"No\",\"No\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"No\",\"No\",\"No\",\"Yes\",\"Yes\",\"No\",\"No\",\"Yes\",\"Yes\",\"No\",\"No\",\"No\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"No\",\"No\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"No\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"No\",\"No\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"No\",\"No\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"No\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"No\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"No\",\"No\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"No\",\"No\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"No\",\"Yes\",\"Yes\",\"No\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"No\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"No\",\"No\",\"Yes\",\"No\",\"Yes\",\"No\",\"No\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"No\",\"No\",\"No\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"No\",\"No\",\"No\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"No\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"No\",\"No\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"No\",\"No\",\"No\",\"No\",\"No\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"No\",\"No\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"No\",\"No\",\"No\",\"No\",\"No\",\"Yes\",\"Yes\",\"No\",\"No\",\"Yes\",\"Yes\",\"No\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"No\",\"Yes\",\"No\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"No\",\"No\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"No\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"No\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"No\",\"No\",\"No\",\"Yes\",\"Yes\",\"No\",\"No\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"No\",\"No\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"No\",\"Yes\",\"No\",\"Yes\",\"No\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"No\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"No\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"No\",\"No\",\"No\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"No\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"No\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"No\",\"Yes\",\"No\",\"No\",\"Yes\",\"No\",\"Yes\",\"No\",\"Yes\",\"No\",\"Yes\",\"No\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"No\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"No\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"No\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"No\",\"No\",\"Yes\",\"No\",\"Yes\",\"No\",\"Yes\",\"No\",\"Yes\",\"No\",\"No\",\"Yes\",\"No\",\"No\",\"No\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"No\",\"No\",\"Yes\",\"Yes\",\"No\",\"No\",\"No\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"No\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"No\",\"Yes\",\"No\",\"Yes\",\"No\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"No\",\"No\",\"Yes\",\"No\",\"Yes\",\"No\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"No\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"No\",\"No\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"No\",\"No\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"No\",\"No\",\"No\",\"Yes\",\"No\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"No\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"No\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"No\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"No\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"No\",\"No\",\"No\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"No\",\"No\",\"No\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"No\",\"Yes\",\"Yes\",\"No\",\"No\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"No\",\"Yes\",\"No\",\"Yes\",\"No\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"No\",\"No\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"No\",\"Yes\",\"No\",\"No\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"No\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"No\",\"No\",\"Yes\",\"No\",\"Yes\",\"No\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"No\",\"No\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"No\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"No\",\"Yes\",\"No\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"No\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"No\",\"No\",\"No\",\"No\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"No\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"No\",\"No\",\"Yes\",\"No\",\"No\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"No\",\"Yes\",\"No\",\"Yes\",\"No\",\"No\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"No\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"No\",\"No\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"No\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"No\",\"Yes\",\"Yes\",\"No\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"No\",\"No\",\"No\",\"No\",\"No\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"No\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"No\",\"Yes\",\"Yes\",\"No\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"No\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"No\",\"No\",\"Yes\",\"No\",\"No\",\"No\",\"No\",\"Yes\",\"No\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"No\",\"No\",\"No\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"No\",\"No\",\"No\",\"No\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"No\",\"No\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"No\",\"No\",\"Yes\",\"Yes\",\"No\",\"No\",\"No\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"No\",\"No\",\"No\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"No\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"No\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"No\",\"No\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"No\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"No\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"No\",\"No\",\"No\",\"Yes\",\"No\",\"Yes\",\"No\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"No\",\"No\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"No\",\"No\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"No\",\"No\",\"No\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"No\",\"No\",\"Yes\",\"Yes\",\"No\",\"No\",\"No\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"No\",\"Yes\",\"No\",\"No\",\"Yes\",\"Yes\",\"No\",\"No\",\"No\",\"Yes\",\"No\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"No\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"No\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"No\",\"No\",\"No\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"No\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"No\",\"No\",\"No\",\"No\",\"No\",\"No\",\"Yes\",\"No\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"No\",\"No\",\"Yes\",\"No\",\"No\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"No\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"No\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"No\",\"No\",\"No\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"No\",\"No\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"No\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"No\",\"No\",\"No\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"No\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"No\",\"No\",\"Yes\",\"Yes\",\"No\",\"No\",\"No\",\"Yes\",\"No\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"No\",\"No\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"No\",\"No\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"No\",\"No\",\"Yes\",\"No\",\"Yes\",\"No\",\"No\",\"No\",\"Yes\",\"No\",\"No\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"No\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"No\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"No\",\"Yes\",\"No\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"No\",\"Yes\",\"No\",\"Yes\",\"No\",\"Yes\",\"No\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"No\",\"No\",\"Yes\",\"No\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"No\",\"Yes\",\"No\",\"No\",\"No\",\"No\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"No\",\"No\",\"Yes\",\"Yes\",\"No\",\"No\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"No\",\"No\",\"No\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"No\",\"No\",\"No\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"No\",\"No\",\"Yes\",\"No\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"No\",\"No\",\"No\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"No\",\"No\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"No\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"No\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"No\",\"No\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"No\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"No\",\"No\",\"Yes\",\"No\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"No\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"No\",\"Yes\",\"No\",\"Yes\",\"No\",\"No\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"No\",\"No\",\"Yes\",\"No\",\"No\",\"No\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"No\",\"No\",\"No\",\"No\",\"No\",\"Yes\",\"Yes\",\"No\",\"No\",\"Yes\",\"No\",\"No\",\"No\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"No\",\"No\",\"Yes\",\"No\",\"No\",\"No\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"No\",\"Yes\",\"Yes\",\"No\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"No\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"No\",\"No\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"No\",\"Yes\",\"Yes\",\"No\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"No\",\"Yes\",\"No\",\"Yes\",\"No\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"No\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"No\",\"Yes\",\"No\",\"No\",\"No\",\"Yes\",\"No\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"No\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"No\",\"No\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"No\",\"No\",\"No\",\"No\",\"No\",\"No\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"No\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"No\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"No\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"No\",\"No\",\"No\",\"Yes\",\"No\",\"No\",\"No\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"No\",\"No\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"No\",\"Yes\",\"No\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"No\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"No\",\"No\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"No\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"No\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"No\",\"Yes\",\"Yes\",\"No\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"No\",\"No\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"No\",\"No\",\"No\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"No\",\"No\",\"Yes\",\"No\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"No\",\"No\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"No\",\"No\",\"No\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"No\",\"No\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"No\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"No\",\"No\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"No\",\"No\",\"No\",\"Yes\",\"Yes\",\"No\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"No\",\"No\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"No\",\"No\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"No\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"No\",\"No\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"No\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"No\",\"No\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"No\",\"No\",\"Yes\",\"No\",\"No\",\"No\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"No\",\"No\",\"Yes\",\"No\",\"Yes\",\"No\",\"No\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"No\",\"Yes\",\"No\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"No\",\"No\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"No\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"No\",\"No\",\"No\",\"No\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"No\",\"No\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"No\",\"No\",\"No\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"No\",\"No\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"No\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"No\",\"No\",\"Yes\",\"No\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"No\",\"Yes\",\"No\",\"Yes\",\"No\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"No\",\"No\",\"No\",\"Yes\",\"No\",\"Yes\",\"No\",\"No\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"No\",\"No\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"No\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"No\",\"No\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"No\",\"No\",\"No\",\"No\",\"No\",\"No\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"No\",\"No\",\"Yes\",\"Yes\",\"No\",\"No\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"No\",\"No\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"No\",\"No\",\"No\",\"No\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"No\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"No\",\"Yes\",\"No\",\"No\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"No\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"No\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"Yes\"],\"xaxis\":\"x\",\"yaxis\":\"y\",\"type\":\"histogram\"}],                        {\"template\":{\"data\":{\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"white\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"ever_married\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"count\"}},\"legend\":{\"title\":{\"text\":\"stroke\"},\"tracegroupgap\":0},\"margin\":{\"t\":60},\"barmode\":\"relative\",\"height\":800},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('9c85b6b7-927e-4e0d-947c-4007297d2f6b');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Married person has stroke rate of 4.305283757338552 %\n",
            "Unmarried person has stroke rate of 0.5675146771037182 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.isnull().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4QOwUAFYfRDI",
        "outputId": "336240a9-ad75-458a-cc8e-416d10cadfe2"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "id                     0\n",
              "gender                 0\n",
              "age                    0\n",
              "hypertension           0\n",
              "heart_disease          0\n",
              "ever_married           0\n",
              "work_type              0\n",
              "Residence_type         0\n",
              "avg_glucose_level      0\n",
              "bmi                  201\n",
              "smoking_status         0\n",
              "stroke                 0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sns.countplot(x ='stroke', data = data)\n",
        "#data is imbalanced"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "id": "mmehKONqey6s",
        "outputId": "04eb8797-0a59-4565-9423-c2257efbdffa"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f03788e8d50>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Splitting into dependent and independent variables"
      ],
      "metadata": {
        "id": "VCyfe2g9H3ek"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "xtrain = data.drop(columns=['stroke','id'])"
      ],
      "metadata": {
        "id": "ZA1n2ZemoLl0"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ytrain = data.stroke"
      ],
      "metadata": {
        "id": "X9C2rw9doGZu"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ytrain"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6sspXkN4ojuU",
        "outputId": "3b2d9647-d984-4477-c35a-f83e5ba444fe"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       1\n",
              "1       1\n",
              "2       1\n",
              "3       1\n",
              "4       1\n",
              "       ..\n",
              "5105    0\n",
              "5106    0\n",
              "5107    0\n",
              "5108    0\n",
              "5109    0\n",
              "Name: stroke, Length: 5110, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cols = xtrain.columns\n",
        "num_cols= xtrain._get_numeric_data().columns\n",
        "cat_cols = list(set(cols) - set(num_cols))"
      ],
      "metadata": {
        "id": "AoPuYbtweyVp"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Encoding"
      ],
      "metadata": {
        "id": "wYz4X2A1IBdc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder"
      ],
      "metadata": {
        "id": "MMj84M15o9Nj"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data1 = xtrain[cat_cols].apply(LabelEncoder().fit_transform)\n",
        "trainx = data1.join(data[num_cols])"
      ],
      "metadata": {
        "id": "HtbscrvIo1VJ"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainx=trainx.drop(columns=['bmi'])"
      ],
      "metadata": {
        "id": "6C29XKvVpFQU"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainx"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "aueQneN7pSrs",
        "outputId": "bacd7d67-81e5-400b-de93-6db6686178c2"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      gender  Residence_type  work_type  smoking_status  ever_married   age  \\\n",
              "0          1               1          2               1             1  67.0   \n",
              "1          0               0          3               2             1  61.0   \n",
              "2          1               0          2               2             1  80.0   \n",
              "3          0               1          2               3             1  49.0   \n",
              "4          0               0          3               2             1  79.0   \n",
              "...      ...             ...        ...             ...           ...   ...   \n",
              "5105       0               1          2               2             1  80.0   \n",
              "5106       0               1          3               2             1  81.0   \n",
              "5107       0               0          3               2             1  35.0   \n",
              "5108       1               0          2               1             1  51.0   \n",
              "5109       0               1          0               0             1  44.0   \n",
              "\n",
              "      hypertension  heart_disease  avg_glucose_level  \n",
              "0                0              1             228.69  \n",
              "1                0              0             202.21  \n",
              "2                0              1             105.92  \n",
              "3                0              0             171.23  \n",
              "4                1              0             174.12  \n",
              "...            ...            ...                ...  \n",
              "5105             1              0              83.75  \n",
              "5106             0              0             125.20  \n",
              "5107             0              0              82.99  \n",
              "5108             0              0             166.29  \n",
              "5109             0              0              85.28  \n",
              "\n",
              "[5110 rows x 9 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2ec16c38-8ad7-4bb8-bdc3-97c8bf0ed5c3\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>gender</th>\n",
              "      <th>Residence_type</th>\n",
              "      <th>work_type</th>\n",
              "      <th>smoking_status</th>\n",
              "      <th>ever_married</th>\n",
              "      <th>age</th>\n",
              "      <th>hypertension</th>\n",
              "      <th>heart_disease</th>\n",
              "      <th>avg_glucose_level</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>67.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>228.69</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>61.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>202.21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>80.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>105.92</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>49.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>171.23</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>79.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>174.12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5105</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>80.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>83.75</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5106</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>81.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>125.20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5107</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>35.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>82.99</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5108</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>51.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>166.29</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5109</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>44.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>85.28</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5110 rows × 9 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2ec16c38-8ad7-4bb8-bdc3-97c8bf0ed5c3')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-2ec16c38-8ad7-4bb8-bdc3-97c8bf0ed5c3 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-2ec16c38-8ad7-4bb8-bdc3-97c8bf0ed5c3');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train Test Split"
      ],
      "metadata": {
        "id": "WIZgzAgbIEL4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(trainx, ytrain, test_size=0.15, random_state=50)"
      ],
      "metadata": {
        "id": "isPeedAUqNUU"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ensemble Learning"
      ],
      "metadata": {
        "id": "jR3EmTvJ49MJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import classification_report"
      ],
      "metadata": {
        "id": "Xtm0rAUwqt7v"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "RFC = RandomForestClassifier()"
      ],
      "metadata": {
        "id": "Kw9Gh-rup1zP"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "RFC.fit(x_train,y_train)   "
      ],
      "metadata": {
        "id": "y_5hIvp1p71t",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d4ff284-12d8-421a-e4f1-64da27339265"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier()"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred=RFC.predict_proba(x_test)"
      ],
      "metadata": {
        "id": "m0fK-ED-qGfc"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def threshold(model,min_threshold=0.1,max_threshold=0.8):\n",
        "    step_factor = 0.01\n",
        "    min_threshold = 0.2\n",
        "    roc_score=0\n",
        "    predicted_proba = model.predict_proba(x_train) \n",
        "    while min_threshold <=max_threshold: \n",
        "        temp_thresh = min_threshold\n",
        "        predicted = (predicted_proba [:,1] >= temp_thresh).astype('int') \n",
        "        # print('Threshold',temp_thresh,'--',roc_auc_score(y_train, predicted))\n",
        "        if roc_score<roc_auc_score(y_train, predicted):\n",
        "            roc_score = roc_auc_score(y_train, predicted)\n",
        "            thrsh_score = min_threshold\n",
        "        min_threshold = min_threshold + step_factor\n",
        "    print('---Optimum Threshold ---',thrsh_score,'--ROC--',roc_score)\n",
        "    return thrsh_score"
      ],
      "metadata": {
        "id": "Ps7BOmccqcGg"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "thrsvalue=threshold(RFC)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aF8_WjowtiRq",
        "outputId": "027bd346-bf67-48fb-e6ab-19655ee1cdb3"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---Optimum Threshold --- 0.37000000000000016 --ROC-- 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = y_pred[:, 1]"
      ],
      "metadata": {
        "id": "uhTrTJj4q1Ca"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ans=[]"
      ],
      "metadata": {
        "id": "kJL9qqbYrCEh"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(y_pred)):\n",
        "  if y_pred[i]>=thrsvalue:\n",
        "    ans.append(1)\n",
        "  else:\n",
        "    ans.append(0)"
      ],
      "metadata": {
        "id": "jiBaA4qAq-Qv"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "report = pd.DataFrame(classification_report(y_test, ans, output_dict=True))"
      ],
      "metadata": {
        "id": "bWCR0PqFrGKC"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "report"
      ],
      "metadata": {
        "id": "ByGreJN2r2VS",
        "outputId": "d379207d-2c13-4a21-fdb7-429af2439d2d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 174
        }
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                    0          1  accuracy   macro avg  weighted avg\n",
              "precision    0.953826   0.111111  0.943937    0.532468      0.914272\n",
              "recall       0.989056   0.027778  0.943937    0.508417      0.943937\n",
              "f1-score     0.971122   0.044444  0.943937    0.507783      0.927627\n",
              "support    731.000000  36.000000  0.943937  767.000000    767.000000"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5688e35d-1f1f-4f2a-b46e-ab90241bd03d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>macro avg</th>\n",
              "      <th>weighted avg</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>precision</th>\n",
              "      <td>0.953826</td>\n",
              "      <td>0.111111</td>\n",
              "      <td>0.943937</td>\n",
              "      <td>0.532468</td>\n",
              "      <td>0.914272</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>recall</th>\n",
              "      <td>0.989056</td>\n",
              "      <td>0.027778</td>\n",
              "      <td>0.943937</td>\n",
              "      <td>0.508417</td>\n",
              "      <td>0.943937</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>f1-score</th>\n",
              "      <td>0.971122</td>\n",
              "      <td>0.044444</td>\n",
              "      <td>0.943937</td>\n",
              "      <td>0.507783</td>\n",
              "      <td>0.927627</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>support</th>\n",
              "      <td>731.000000</td>\n",
              "      <td>36.000000</td>\n",
              "      <td>0.943937</td>\n",
              "      <td>767.000000</td>\n",
              "      <td>767.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5688e35d-1f1f-4f2a-b46e-ab90241bd03d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-5688e35d-1f1f-4f2a-b46e-ab90241bd03d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-5688e35d-1f1f-4f2a-b46e-ab90241bd03d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Boosting"
      ],
      "metadata": {
        "id": "uXp56jGp5BOE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install catboost"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YBlsWRCYpsgx",
        "outputId": "8544ce4a-9b58-4e0e-de9d-6556b8098ea2"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting catboost\n",
            "  Downloading catboost-1.0.5-cp37-none-manylinux1_x86_64.whl (76.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 76.6 MB 70 kB/s \n",
            "\u001b[?25hRequirement already satisfied: graphviz in /usr/local/lib/python3.7/dist-packages (from catboost) (0.10.1)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.7/dist-packages (from catboost) (5.5.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from catboost) (1.15.0)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from catboost) (1.21.6)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from catboost) (1.4.1)\n",
            "Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.7/dist-packages (from catboost) (1.3.5)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from catboost) (3.2.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->catboost) (2022.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->catboost) (2.8.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->catboost) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->catboost) (1.4.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->catboost) (3.0.8)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib->catboost) (4.2.0)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.7/dist-packages (from plotly->catboost) (8.0.1)\n",
            "Installing collected packages: catboost\n",
            "Successfully installed catboost-1.0.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import lightgbm as lgb\n",
        "from catboost import CatBoostClassifier\n",
        "import xgboost as xgb\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "metadata": {
        "id": "8ixnv3s9Tfqq"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "LGBM = lgb.LGBMClassifier()"
      ],
      "metadata": {
        "id": "KGHln7FMTdi2"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "CAT = CatBoostClassifier()"
      ],
      "metadata": {
        "id": "3ME8ovBEqHlS"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "XG = xgb.XGBClassifier()"
      ],
      "metadata": {
        "id": "r4bOwOE-qNko"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "LGBM.fit(x_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dhM1ZfdvUUMv",
        "outputId": "cb98e70d-3f0f-40b1-ca06-4b4bb8df3488"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LGBMClassifier()"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preds = LGBM.predict(x_test)"
      ],
      "metadata": {
        "id": "PTfYpaY1URu8"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "report = pd.DataFrame(classification_report(y_test, preds, output_dict=True))\n",
        "report"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "b6sv6EDyqcUo",
        "outputId": "107e4087-6009-4489-f435-a1e43cc35b81"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                    0     1  accuracy   macro avg  weighted avg\n",
              "precision    0.952756   0.0  0.946545    0.476378      0.908037\n",
              "recall       0.993160   0.0  0.946545    0.496580      0.946545\n",
              "f1-score     0.972539   0.0  0.946545    0.486269      0.926891\n",
              "support    731.000000  36.0  0.946545  767.000000    767.000000"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e7dcdc44-d50f-4561-a0a4-59a7dbd89494\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>macro avg</th>\n",
              "      <th>weighted avg</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>precision</th>\n",
              "      <td>0.952756</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.946545</td>\n",
              "      <td>0.476378</td>\n",
              "      <td>0.908037</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>recall</th>\n",
              "      <td>0.993160</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.946545</td>\n",
              "      <td>0.496580</td>\n",
              "      <td>0.946545</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>f1-score</th>\n",
              "      <td>0.972539</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.946545</td>\n",
              "      <td>0.486269</td>\n",
              "      <td>0.926891</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>support</th>\n",
              "      <td>731.000000</td>\n",
              "      <td>36.0</td>\n",
              "      <td>0.946545</td>\n",
              "      <td>767.000000</td>\n",
              "      <td>767.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e7dcdc44-d50f-4561-a0a4-59a7dbd89494')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e7dcdc44-d50f-4561-a0a4-59a7dbd89494 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e7dcdc44-d50f-4561-a0a4-59a7dbd89494');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "thrsvalue=threshold(LGBM)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tZyVPRVkqpwt",
        "outputId": "434d5810-96fd-4a01-e53e-3df1c97ea584"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---Optimum Threshold --- 0.22000000000000003 --ROC-- 0.9854516932101081\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = LGBM.predict_proba(x_test)"
      ],
      "metadata": {
        "id": "QNuJrDB96d4w"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = y_pred[:, 1]"
      ],
      "metadata": {
        "id": "lAGfYW6b6Y2q"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ans=[]"
      ],
      "metadata": {
        "id": "TyXnq86k6Y2r"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(y_pred)):\n",
        "  if y_pred[i]>=thrsvalue:\n",
        "    ans.append(1)\n",
        "  else:\n",
        "    ans.append(0)"
      ],
      "metadata": {
        "id": "Mbmq6tL06Y2r"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "report = pd.DataFrame(classification_report(y_test, ans, output_dict=True))\n",
        "report"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "KsBYETag6Y2s",
        "outputId": "6c0089ed-fd5d-490c-c2a8-b32d3f3ddf60"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                    0          1  accuracy   macro avg  weighted avg\n",
              "precision    0.960811   0.259259  0.936115    0.610035      0.927883\n",
              "recall       0.972640   0.194444  0.936115    0.583542      0.936115\n",
              "f1-score     0.966689   0.222222  0.936115    0.594456      0.931747\n",
              "support    731.000000  36.000000  0.936115  767.000000    767.000000"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-00216e30-e02f-4cb2-b1c4-0f70bc4e16f6\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>macro avg</th>\n",
              "      <th>weighted avg</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>precision</th>\n",
              "      <td>0.960811</td>\n",
              "      <td>0.259259</td>\n",
              "      <td>0.936115</td>\n",
              "      <td>0.610035</td>\n",
              "      <td>0.927883</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>recall</th>\n",
              "      <td>0.972640</td>\n",
              "      <td>0.194444</td>\n",
              "      <td>0.936115</td>\n",
              "      <td>0.583542</td>\n",
              "      <td>0.936115</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>f1-score</th>\n",
              "      <td>0.966689</td>\n",
              "      <td>0.222222</td>\n",
              "      <td>0.936115</td>\n",
              "      <td>0.594456</td>\n",
              "      <td>0.931747</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>support</th>\n",
              "      <td>731.000000</td>\n",
              "      <td>36.000000</td>\n",
              "      <td>0.936115</td>\n",
              "      <td>767.000000</td>\n",
              "      <td>767.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-00216e30-e02f-4cb2-b1c4-0f70bc4e16f6')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-00216e30-e02f-4cb2-b1c4-0f70bc4e16f6 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-00216e30-e02f-4cb2-b1c4-0f70bc4e16f6');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "CAT.fit(x_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "87dadd15-f1a4-45ab-f3b3-756437f2df99",
        "id": "Zk7mRRo3qvu0"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Learning rate set to 0.019287\n",
            "0:\tlearn: 0.6579009\ttotal: 49.1ms\tremaining: 49s\n",
            "1:\tlearn: 0.6281037\ttotal: 50.9ms\tremaining: 25.4s\n",
            "2:\tlearn: 0.6008443\ttotal: 52.7ms\tremaining: 17.5s\n",
            "3:\tlearn: 0.5767537\ttotal: 54.4ms\tremaining: 13.6s\n",
            "4:\tlearn: 0.5565189\ttotal: 56.2ms\tremaining: 11.2s\n",
            "5:\tlearn: 0.5378810\ttotal: 57.4ms\tremaining: 9.51s\n",
            "6:\tlearn: 0.5164818\ttotal: 59.3ms\tremaining: 8.42s\n",
            "7:\tlearn: 0.4983978\ttotal: 61ms\tremaining: 7.56s\n",
            "8:\tlearn: 0.4827669\ttotal: 62.3ms\tremaining: 6.85s\n",
            "9:\tlearn: 0.4609011\ttotal: 64.2ms\tremaining: 6.36s\n",
            "10:\tlearn: 0.4412293\ttotal: 66ms\tremaining: 5.94s\n",
            "11:\tlearn: 0.4225875\ttotal: 72.9ms\tremaining: 6s\n",
            "12:\tlearn: 0.4101545\ttotal: 74.8ms\tremaining: 5.68s\n",
            "13:\tlearn: 0.3968638\ttotal: 76.5ms\tremaining: 5.39s\n",
            "14:\tlearn: 0.3858418\ttotal: 78ms\tremaining: 5.12s\n",
            "15:\tlearn: 0.3747714\ttotal: 80ms\tremaining: 4.92s\n",
            "16:\tlearn: 0.3615327\ttotal: 82ms\tremaining: 4.74s\n",
            "17:\tlearn: 0.3527567\ttotal: 83.4ms\tremaining: 4.55s\n",
            "18:\tlearn: 0.3409155\ttotal: 85.2ms\tremaining: 4.4s\n",
            "19:\tlearn: 0.3306172\ttotal: 87ms\tremaining: 4.26s\n",
            "20:\tlearn: 0.3213513\ttotal: 88.8ms\tremaining: 4.14s\n",
            "21:\tlearn: 0.3128126\ttotal: 90.5ms\tremaining: 4.03s\n",
            "22:\tlearn: 0.3041447\ttotal: 92.3ms\tremaining: 3.92s\n",
            "23:\tlearn: 0.2963074\ttotal: 94.1ms\tremaining: 3.83s\n",
            "24:\tlearn: 0.2887159\ttotal: 95.9ms\tremaining: 3.74s\n",
            "25:\tlearn: 0.2825717\ttotal: 97.9ms\tremaining: 3.67s\n",
            "26:\tlearn: 0.2760285\ttotal: 99.8ms\tremaining: 3.6s\n",
            "27:\tlearn: 0.2701083\ttotal: 102ms\tremaining: 3.53s\n",
            "28:\tlearn: 0.2652959\ttotal: 103ms\tremaining: 3.45s\n",
            "29:\tlearn: 0.2603932\ttotal: 105ms\tremaining: 3.39s\n",
            "30:\tlearn: 0.2555803\ttotal: 106ms\tremaining: 3.32s\n",
            "31:\tlearn: 0.2512191\ttotal: 108ms\tremaining: 3.26s\n",
            "32:\tlearn: 0.2470641\ttotal: 109ms\tremaining: 3.21s\n",
            "33:\tlearn: 0.2434614\ttotal: 111ms\tremaining: 3.15s\n",
            "34:\tlearn: 0.2397290\ttotal: 113ms\tremaining: 3.1s\n",
            "35:\tlearn: 0.2364947\ttotal: 114ms\tremaining: 3.05s\n",
            "36:\tlearn: 0.2336804\ttotal: 115ms\tremaining: 3s\n",
            "37:\tlearn: 0.2291317\ttotal: 118ms\tremaining: 2.98s\n",
            "38:\tlearn: 0.2246429\ttotal: 120ms\tremaining: 2.94s\n",
            "39:\tlearn: 0.2198940\ttotal: 122ms\tremaining: 2.92s\n",
            "40:\tlearn: 0.2163178\ttotal: 123ms\tremaining: 2.88s\n",
            "41:\tlearn: 0.2140711\ttotal: 125ms\tremaining: 2.85s\n",
            "42:\tlearn: 0.2108335\ttotal: 127ms\tremaining: 2.82s\n",
            "43:\tlearn: 0.2081758\ttotal: 128ms\tremaining: 2.79s\n",
            "44:\tlearn: 0.2061277\ttotal: 130ms\tremaining: 2.76s\n",
            "45:\tlearn: 0.2041103\ttotal: 132ms\tremaining: 2.75s\n",
            "46:\tlearn: 0.2025821\ttotal: 134ms\tremaining: 2.71s\n",
            "47:\tlearn: 0.2010578\ttotal: 136ms\tremaining: 2.69s\n",
            "48:\tlearn: 0.1989325\ttotal: 138ms\tremaining: 2.67s\n",
            "49:\tlearn: 0.1966907\ttotal: 140ms\tremaining: 2.65s\n",
            "50:\tlearn: 0.1945520\ttotal: 141ms\tremaining: 2.63s\n",
            "51:\tlearn: 0.1926287\ttotal: 143ms\tremaining: 2.62s\n",
            "52:\tlearn: 0.1907981\ttotal: 146ms\tremaining: 2.6s\n",
            "53:\tlearn: 0.1893914\ttotal: 147ms\tremaining: 2.58s\n",
            "54:\tlearn: 0.1877516\ttotal: 149ms\tremaining: 2.56s\n",
            "55:\tlearn: 0.1862438\ttotal: 151ms\tremaining: 2.55s\n",
            "56:\tlearn: 0.1847850\ttotal: 153ms\tremaining: 2.53s\n",
            "57:\tlearn: 0.1837189\ttotal: 155ms\tremaining: 2.52s\n",
            "58:\tlearn: 0.1828303\ttotal: 157ms\tremaining: 2.5s\n",
            "59:\tlearn: 0.1817969\ttotal: 159ms\tremaining: 2.49s\n",
            "60:\tlearn: 0.1802677\ttotal: 161ms\tremaining: 2.47s\n",
            "61:\tlearn: 0.1789566\ttotal: 163ms\tremaining: 2.46s\n",
            "62:\tlearn: 0.1776897\ttotal: 165ms\tremaining: 2.45s\n",
            "63:\tlearn: 0.1766539\ttotal: 167ms\tremaining: 2.44s\n",
            "64:\tlearn: 0.1754102\ttotal: 169ms\tremaining: 2.42s\n",
            "65:\tlearn: 0.1741945\ttotal: 171ms\tremaining: 2.41s\n",
            "66:\tlearn: 0.1729440\ttotal: 173ms\tremaining: 2.4s\n",
            "67:\tlearn: 0.1719523\ttotal: 175ms\tremaining: 2.4s\n",
            "68:\tlearn: 0.1714538\ttotal: 176ms\tremaining: 2.38s\n",
            "69:\tlearn: 0.1704762\ttotal: 186ms\tremaining: 2.47s\n",
            "70:\tlearn: 0.1696788\ttotal: 189ms\tremaining: 2.47s\n",
            "71:\tlearn: 0.1689336\ttotal: 193ms\tremaining: 2.49s\n",
            "72:\tlearn: 0.1683068\ttotal: 195ms\tremaining: 2.47s\n",
            "73:\tlearn: 0.1673658\ttotal: 197ms\tremaining: 2.46s\n",
            "74:\tlearn: 0.1666440\ttotal: 199ms\tremaining: 2.45s\n",
            "75:\tlearn: 0.1661416\ttotal: 200ms\tremaining: 2.44s\n",
            "76:\tlearn: 0.1653368\ttotal: 202ms\tremaining: 2.42s\n",
            "77:\tlearn: 0.1647766\ttotal: 204ms\tremaining: 2.41s\n",
            "78:\tlearn: 0.1645207\ttotal: 205ms\tremaining: 2.39s\n",
            "79:\tlearn: 0.1640056\ttotal: 207ms\tremaining: 2.38s\n",
            "80:\tlearn: 0.1635737\ttotal: 208ms\tremaining: 2.36s\n",
            "81:\tlearn: 0.1629625\ttotal: 210ms\tremaining: 2.35s\n",
            "82:\tlearn: 0.1624248\ttotal: 212ms\tremaining: 2.34s\n",
            "83:\tlearn: 0.1619258\ttotal: 214ms\tremaining: 2.33s\n",
            "84:\tlearn: 0.1614257\ttotal: 216ms\tremaining: 2.33s\n",
            "85:\tlearn: 0.1610325\ttotal: 218ms\tremaining: 2.32s\n",
            "86:\tlearn: 0.1604315\ttotal: 220ms\tremaining: 2.31s\n",
            "87:\tlearn: 0.1600033\ttotal: 222ms\tremaining: 2.3s\n",
            "88:\tlearn: 0.1592621\ttotal: 224ms\tremaining: 2.29s\n",
            "89:\tlearn: 0.1584723\ttotal: 226ms\tremaining: 2.28s\n",
            "90:\tlearn: 0.1580702\ttotal: 228ms\tremaining: 2.28s\n",
            "91:\tlearn: 0.1575161\ttotal: 230ms\tremaining: 2.27s\n",
            "92:\tlearn: 0.1573578\ttotal: 231ms\tremaining: 2.25s\n",
            "93:\tlearn: 0.1568903\ttotal: 234ms\tremaining: 2.25s\n",
            "94:\tlearn: 0.1564458\ttotal: 236ms\tremaining: 2.25s\n",
            "95:\tlearn: 0.1563350\ttotal: 237ms\tremaining: 2.23s\n",
            "96:\tlearn: 0.1558583\ttotal: 239ms\tremaining: 2.23s\n",
            "97:\tlearn: 0.1555226\ttotal: 241ms\tremaining: 2.22s\n",
            "98:\tlearn: 0.1552730\ttotal: 243ms\tremaining: 2.21s\n",
            "99:\tlearn: 0.1547337\ttotal: 245ms\tremaining: 2.2s\n",
            "100:\tlearn: 0.1544128\ttotal: 247ms\tremaining: 2.2s\n",
            "101:\tlearn: 0.1540232\ttotal: 252ms\tremaining: 2.21s\n",
            "102:\tlearn: 0.1534856\ttotal: 254ms\tremaining: 2.21s\n",
            "103:\tlearn: 0.1532552\ttotal: 255ms\tremaining: 2.2s\n",
            "104:\tlearn: 0.1529567\ttotal: 258ms\tremaining: 2.19s\n",
            "105:\tlearn: 0.1527150\ttotal: 260ms\tremaining: 2.19s\n",
            "106:\tlearn: 0.1523923\ttotal: 262ms\tremaining: 2.19s\n",
            "107:\tlearn: 0.1520257\ttotal: 268ms\tremaining: 2.21s\n",
            "108:\tlearn: 0.1515139\ttotal: 271ms\tremaining: 2.22s\n",
            "109:\tlearn: 0.1512741\ttotal: 274ms\tremaining: 2.21s\n",
            "110:\tlearn: 0.1511475\ttotal: 275ms\tremaining: 2.21s\n",
            "111:\tlearn: 0.1509548\ttotal: 277ms\tremaining: 2.2s\n",
            "112:\tlearn: 0.1505584\ttotal: 279ms\tremaining: 2.19s\n",
            "113:\tlearn: 0.1501529\ttotal: 281ms\tremaining: 2.19s\n",
            "114:\tlearn: 0.1498521\ttotal: 284ms\tremaining: 2.18s\n",
            "115:\tlearn: 0.1494510\ttotal: 286ms\tremaining: 2.18s\n",
            "116:\tlearn: 0.1492072\ttotal: 287ms\tremaining: 2.17s\n",
            "117:\tlearn: 0.1488587\ttotal: 289ms\tremaining: 2.16s\n",
            "118:\tlearn: 0.1485065\ttotal: 291ms\tremaining: 2.16s\n",
            "119:\tlearn: 0.1482223\ttotal: 293ms\tremaining: 2.15s\n",
            "120:\tlearn: 0.1479873\ttotal: 295ms\tremaining: 2.14s\n",
            "121:\tlearn: 0.1476918\ttotal: 297ms\tremaining: 2.14s\n",
            "122:\tlearn: 0.1473455\ttotal: 299ms\tremaining: 2.13s\n",
            "123:\tlearn: 0.1471107\ttotal: 301ms\tremaining: 2.13s\n",
            "124:\tlearn: 0.1469176\ttotal: 303ms\tremaining: 2.12s\n",
            "125:\tlearn: 0.1466179\ttotal: 305ms\tremaining: 2.12s\n",
            "126:\tlearn: 0.1463240\ttotal: 307ms\tremaining: 2.11s\n",
            "127:\tlearn: 0.1461017\ttotal: 309ms\tremaining: 2.1s\n",
            "128:\tlearn: 0.1458328\ttotal: 311ms\tremaining: 2.1s\n",
            "129:\tlearn: 0.1455548\ttotal: 313ms\tremaining: 2.1s\n",
            "130:\tlearn: 0.1454157\ttotal: 315ms\tremaining: 2.09s\n",
            "131:\tlearn: 0.1451333\ttotal: 317ms\tremaining: 2.08s\n",
            "132:\tlearn: 0.1448629\ttotal: 319ms\tremaining: 2.08s\n",
            "133:\tlearn: 0.1446053\ttotal: 321ms\tremaining: 2.07s\n",
            "134:\tlearn: 0.1444380\ttotal: 323ms\tremaining: 2.07s\n",
            "135:\tlearn: 0.1442762\ttotal: 325ms\tremaining: 2.06s\n",
            "136:\tlearn: 0.1440849\ttotal: 327ms\tremaining: 2.06s\n",
            "137:\tlearn: 0.1438860\ttotal: 328ms\tremaining: 2.05s\n",
            "138:\tlearn: 0.1437080\ttotal: 330ms\tremaining: 2.05s\n",
            "139:\tlearn: 0.1434739\ttotal: 332ms\tremaining: 2.04s\n",
            "140:\tlearn: 0.1432543\ttotal: 335ms\tremaining: 2.04s\n",
            "141:\tlearn: 0.1431079\ttotal: 342ms\tremaining: 2.07s\n",
            "142:\tlearn: 0.1429650\ttotal: 345ms\tremaining: 2.06s\n",
            "143:\tlearn: 0.1428742\ttotal: 349ms\tremaining: 2.08s\n",
            "144:\tlearn: 0.1426796\ttotal: 352ms\tremaining: 2.08s\n",
            "145:\tlearn: 0.1425670\ttotal: 354ms\tremaining: 2.07s\n",
            "146:\tlearn: 0.1423098\ttotal: 356ms\tremaining: 2.07s\n",
            "147:\tlearn: 0.1420722\ttotal: 358ms\tremaining: 2.06s\n",
            "148:\tlearn: 0.1418724\ttotal: 360ms\tremaining: 2.06s\n",
            "149:\tlearn: 0.1416522\ttotal: 362ms\tremaining: 2.05s\n",
            "150:\tlearn: 0.1415315\ttotal: 364ms\tremaining: 2.04s\n",
            "151:\tlearn: 0.1412438\ttotal: 366ms\tremaining: 2.04s\n",
            "152:\tlearn: 0.1410589\ttotal: 368ms\tremaining: 2.04s\n",
            "153:\tlearn: 0.1408372\ttotal: 371ms\tremaining: 2.04s\n",
            "154:\tlearn: 0.1406444\ttotal: 373ms\tremaining: 2.03s\n",
            "155:\tlearn: 0.1404988\ttotal: 375ms\tremaining: 2.03s\n",
            "156:\tlearn: 0.1403692\ttotal: 377ms\tremaining: 2.02s\n",
            "157:\tlearn: 0.1401944\ttotal: 379ms\tremaining: 2.02s\n",
            "158:\tlearn: 0.1400796\ttotal: 381ms\tremaining: 2.01s\n",
            "159:\tlearn: 0.1400153\ttotal: 382ms\tremaining: 2.01s\n",
            "160:\tlearn: 0.1399991\ttotal: 384ms\tremaining: 2s\n",
            "161:\tlearn: 0.1399279\ttotal: 386ms\tremaining: 2s\n",
            "162:\tlearn: 0.1398298\ttotal: 388ms\tremaining: 1.99s\n",
            "163:\tlearn: 0.1396082\ttotal: 390ms\tremaining: 1.99s\n",
            "164:\tlearn: 0.1394440\ttotal: 392ms\tremaining: 1.98s\n",
            "165:\tlearn: 0.1392732\ttotal: 394ms\tremaining: 1.98s\n",
            "166:\tlearn: 0.1391151\ttotal: 395ms\tremaining: 1.97s\n",
            "167:\tlearn: 0.1389598\ttotal: 397ms\tremaining: 1.97s\n",
            "168:\tlearn: 0.1388077\ttotal: 399ms\tremaining: 1.96s\n",
            "169:\tlearn: 0.1387395\ttotal: 402ms\tremaining: 1.96s\n",
            "170:\tlearn: 0.1385906\ttotal: 404ms\tremaining: 1.96s\n",
            "171:\tlearn: 0.1384145\ttotal: 405ms\tremaining: 1.95s\n",
            "172:\tlearn: 0.1382791\ttotal: 407ms\tremaining: 1.95s\n",
            "173:\tlearn: 0.1381153\ttotal: 409ms\tremaining: 1.94s\n",
            "174:\tlearn: 0.1380067\ttotal: 411ms\tremaining: 1.94s\n",
            "175:\tlearn: 0.1378954\ttotal: 413ms\tremaining: 1.94s\n",
            "176:\tlearn: 0.1377931\ttotal: 415ms\tremaining: 1.93s\n",
            "177:\tlearn: 0.1376277\ttotal: 417ms\tremaining: 1.93s\n",
            "178:\tlearn: 0.1375390\ttotal: 420ms\tremaining: 1.92s\n",
            "179:\tlearn: 0.1374201\ttotal: 422ms\tremaining: 1.92s\n",
            "180:\tlearn: 0.1372503\ttotal: 424ms\tremaining: 1.92s\n",
            "181:\tlearn: 0.1371102\ttotal: 426ms\tremaining: 1.92s\n",
            "182:\tlearn: 0.1370119\ttotal: 429ms\tremaining: 1.91s\n",
            "183:\tlearn: 0.1368448\ttotal: 433ms\tremaining: 1.92s\n",
            "184:\tlearn: 0.1367731\ttotal: 436ms\tremaining: 1.92s\n",
            "185:\tlearn: 0.1366730\ttotal: 438ms\tremaining: 1.92s\n",
            "186:\tlearn: 0.1365518\ttotal: 440ms\tremaining: 1.91s\n",
            "187:\tlearn: 0.1364135\ttotal: 441ms\tremaining: 1.91s\n",
            "188:\tlearn: 0.1362797\ttotal: 443ms\tremaining: 1.9s\n",
            "189:\tlearn: 0.1361405\ttotal: 445ms\tremaining: 1.9s\n",
            "190:\tlearn: 0.1360442\ttotal: 447ms\tremaining: 1.89s\n",
            "191:\tlearn: 0.1359997\ttotal: 449ms\tremaining: 1.89s\n",
            "192:\tlearn: 0.1358387\ttotal: 451ms\tremaining: 1.89s\n",
            "193:\tlearn: 0.1357249\ttotal: 454ms\tremaining: 1.88s\n",
            "194:\tlearn: 0.1355595\ttotal: 456ms\tremaining: 1.88s\n",
            "195:\tlearn: 0.1354170\ttotal: 457ms\tremaining: 1.88s\n",
            "196:\tlearn: 0.1353819\ttotal: 459ms\tremaining: 1.87s\n",
            "197:\tlearn: 0.1352536\ttotal: 462ms\tremaining: 1.87s\n",
            "198:\tlearn: 0.1351106\ttotal: 464ms\tremaining: 1.87s\n",
            "199:\tlearn: 0.1349794\ttotal: 466ms\tremaining: 1.86s\n",
            "200:\tlearn: 0.1348464\ttotal: 468ms\tremaining: 1.86s\n",
            "201:\tlearn: 0.1347295\ttotal: 470ms\tremaining: 1.86s\n",
            "202:\tlearn: 0.1345921\ttotal: 472ms\tremaining: 1.85s\n",
            "203:\tlearn: 0.1344019\ttotal: 475ms\tremaining: 1.85s\n",
            "204:\tlearn: 0.1342489\ttotal: 477ms\tremaining: 1.85s\n",
            "205:\tlearn: 0.1340961\ttotal: 479ms\tremaining: 1.84s\n",
            "206:\tlearn: 0.1339943\ttotal: 481ms\tremaining: 1.84s\n",
            "207:\tlearn: 0.1338961\ttotal: 483ms\tremaining: 1.84s\n",
            "208:\tlearn: 0.1337781\ttotal: 485ms\tremaining: 1.83s\n",
            "209:\tlearn: 0.1336555\ttotal: 487ms\tremaining: 1.83s\n",
            "210:\tlearn: 0.1334936\ttotal: 489ms\tremaining: 1.83s\n",
            "211:\tlearn: 0.1333297\ttotal: 491ms\tremaining: 1.83s\n",
            "212:\tlearn: 0.1332330\ttotal: 493ms\tremaining: 1.82s\n",
            "213:\tlearn: 0.1331285\ttotal: 495ms\tremaining: 1.82s\n",
            "214:\tlearn: 0.1329725\ttotal: 497ms\tremaining: 1.81s\n",
            "215:\tlearn: 0.1328868\ttotal: 499ms\tremaining: 1.81s\n",
            "216:\tlearn: 0.1327858\ttotal: 501ms\tremaining: 1.81s\n",
            "217:\tlearn: 0.1326787\ttotal: 502ms\tremaining: 1.8s\n",
            "218:\tlearn: 0.1325236\ttotal: 506ms\tremaining: 1.8s\n",
            "219:\tlearn: 0.1323871\ttotal: 508ms\tremaining: 1.8s\n",
            "220:\tlearn: 0.1322656\ttotal: 511ms\tremaining: 1.8s\n",
            "221:\tlearn: 0.1321250\ttotal: 514ms\tremaining: 1.8s\n",
            "222:\tlearn: 0.1320396\ttotal: 517ms\tremaining: 1.8s\n",
            "223:\tlearn: 0.1319662\ttotal: 519ms\tremaining: 1.8s\n",
            "224:\tlearn: 0.1318446\ttotal: 523ms\tremaining: 1.8s\n",
            "225:\tlearn: 0.1317335\ttotal: 526ms\tremaining: 1.8s\n",
            "226:\tlearn: 0.1316429\ttotal: 528ms\tremaining: 1.8s\n",
            "227:\tlearn: 0.1315410\ttotal: 529ms\tremaining: 1.79s\n",
            "228:\tlearn: 0.1314792\ttotal: 531ms\tremaining: 1.79s\n",
            "229:\tlearn: 0.1313144\ttotal: 533ms\tremaining: 1.78s\n",
            "230:\tlearn: 0.1312141\ttotal: 535ms\tremaining: 1.78s\n",
            "231:\tlearn: 0.1310974\ttotal: 537ms\tremaining: 1.78s\n",
            "232:\tlearn: 0.1309280\ttotal: 539ms\tremaining: 1.77s\n",
            "233:\tlearn: 0.1308296\ttotal: 541ms\tremaining: 1.77s\n",
            "234:\tlearn: 0.1307093\ttotal: 544ms\tremaining: 1.77s\n",
            "235:\tlearn: 0.1305859\ttotal: 546ms\tremaining: 1.77s\n",
            "236:\tlearn: 0.1304704\ttotal: 548ms\tremaining: 1.76s\n",
            "237:\tlearn: 0.1303832\ttotal: 551ms\tremaining: 1.76s\n",
            "238:\tlearn: 0.1302829\ttotal: 554ms\tremaining: 1.76s\n",
            "239:\tlearn: 0.1301676\ttotal: 556ms\tremaining: 1.76s\n",
            "240:\tlearn: 0.1301426\ttotal: 558ms\tremaining: 1.76s\n",
            "241:\tlearn: 0.1300258\ttotal: 560ms\tremaining: 1.75s\n",
            "242:\tlearn: 0.1299379\ttotal: 562ms\tremaining: 1.75s\n",
            "243:\tlearn: 0.1298662\ttotal: 565ms\tremaining: 1.75s\n",
            "244:\tlearn: 0.1298163\ttotal: 567ms\tremaining: 1.75s\n",
            "245:\tlearn: 0.1297409\ttotal: 569ms\tremaining: 1.74s\n",
            "246:\tlearn: 0.1296246\ttotal: 571ms\tremaining: 1.74s\n",
            "247:\tlearn: 0.1295465\ttotal: 573ms\tremaining: 1.74s\n",
            "248:\tlearn: 0.1294581\ttotal: 574ms\tremaining: 1.73s\n",
            "249:\tlearn: 0.1294263\ttotal: 576ms\tremaining: 1.73s\n",
            "250:\tlearn: 0.1293616\ttotal: 578ms\tremaining: 1.72s\n",
            "251:\tlearn: 0.1292739\ttotal: 580ms\tremaining: 1.72s\n",
            "252:\tlearn: 0.1292369\ttotal: 581ms\tremaining: 1.72s\n",
            "253:\tlearn: 0.1291149\ttotal: 583ms\tremaining: 1.71s\n",
            "254:\tlearn: 0.1290185\ttotal: 585ms\tremaining: 1.71s\n",
            "255:\tlearn: 0.1289100\ttotal: 587ms\tremaining: 1.71s\n",
            "256:\tlearn: 0.1288027\ttotal: 589ms\tremaining: 1.7s\n",
            "257:\tlearn: 0.1286922\ttotal: 591ms\tremaining: 1.7s\n",
            "258:\tlearn: 0.1285739\ttotal: 593ms\tremaining: 1.7s\n",
            "259:\tlearn: 0.1284748\ttotal: 595ms\tremaining: 1.69s\n",
            "260:\tlearn: 0.1284252\ttotal: 597ms\tremaining: 1.69s\n",
            "261:\tlearn: 0.1283664\ttotal: 599ms\tremaining: 1.69s\n",
            "262:\tlearn: 0.1282567\ttotal: 601ms\tremaining: 1.68s\n",
            "263:\tlearn: 0.1281886\ttotal: 603ms\tremaining: 1.68s\n",
            "264:\tlearn: 0.1281363\ttotal: 606ms\tremaining: 1.68s\n",
            "265:\tlearn: 0.1280669\ttotal: 610ms\tremaining: 1.68s\n",
            "266:\tlearn: 0.1279972\ttotal: 612ms\tremaining: 1.68s\n",
            "267:\tlearn: 0.1279645\ttotal: 614ms\tremaining: 1.68s\n",
            "268:\tlearn: 0.1278797\ttotal: 616ms\tremaining: 1.67s\n",
            "269:\tlearn: 0.1277810\ttotal: 619ms\tremaining: 1.67s\n",
            "270:\tlearn: 0.1276826\ttotal: 621ms\tremaining: 1.67s\n",
            "271:\tlearn: 0.1276223\ttotal: 623ms\tremaining: 1.67s\n",
            "272:\tlearn: 0.1275130\ttotal: 628ms\tremaining: 1.67s\n",
            "273:\tlearn: 0.1274134\ttotal: 631ms\tremaining: 1.67s\n",
            "274:\tlearn: 0.1273202\ttotal: 635ms\tremaining: 1.67s\n",
            "275:\tlearn: 0.1272378\ttotal: 639ms\tremaining: 1.68s\n",
            "276:\tlearn: 0.1271263\ttotal: 641ms\tremaining: 1.67s\n",
            "277:\tlearn: 0.1270494\ttotal: 644ms\tremaining: 1.67s\n",
            "278:\tlearn: 0.1269651\ttotal: 650ms\tremaining: 1.68s\n",
            "279:\tlearn: 0.1268617\ttotal: 653ms\tremaining: 1.68s\n",
            "280:\tlearn: 0.1267975\ttotal: 663ms\tremaining: 1.7s\n",
            "281:\tlearn: 0.1266895\ttotal: 666ms\tremaining: 1.69s\n",
            "282:\tlearn: 0.1266421\ttotal: 668ms\tremaining: 1.69s\n",
            "283:\tlearn: 0.1265661\ttotal: 670ms\tremaining: 1.69s\n",
            "284:\tlearn: 0.1264999\ttotal: 672ms\tremaining: 1.69s\n",
            "285:\tlearn: 0.1264225\ttotal: 674ms\tremaining: 1.68s\n",
            "286:\tlearn: 0.1263362\ttotal: 676ms\tremaining: 1.68s\n",
            "287:\tlearn: 0.1262157\ttotal: 678ms\tremaining: 1.68s\n",
            "288:\tlearn: 0.1261579\ttotal: 680ms\tremaining: 1.67s\n",
            "289:\tlearn: 0.1261114\ttotal: 682ms\tremaining: 1.67s\n",
            "290:\tlearn: 0.1260375\ttotal: 685ms\tremaining: 1.67s\n",
            "291:\tlearn: 0.1258666\ttotal: 687ms\tremaining: 1.66s\n",
            "292:\tlearn: 0.1257826\ttotal: 689ms\tremaining: 1.66s\n",
            "293:\tlearn: 0.1256863\ttotal: 691ms\tremaining: 1.66s\n",
            "294:\tlearn: 0.1256513\ttotal: 693ms\tremaining: 1.66s\n",
            "295:\tlearn: 0.1255661\ttotal: 695ms\tremaining: 1.65s\n",
            "296:\tlearn: 0.1255560\ttotal: 697ms\tremaining: 1.65s\n",
            "297:\tlearn: 0.1254998\ttotal: 699ms\tremaining: 1.65s\n",
            "298:\tlearn: 0.1254319\ttotal: 700ms\tremaining: 1.64s\n",
            "299:\tlearn: 0.1253334\ttotal: 702ms\tremaining: 1.64s\n",
            "300:\tlearn: 0.1252896\ttotal: 704ms\tremaining: 1.64s\n",
            "301:\tlearn: 0.1251397\ttotal: 707ms\tremaining: 1.63s\n",
            "302:\tlearn: 0.1250191\ttotal: 709ms\tremaining: 1.63s\n",
            "303:\tlearn: 0.1249338\ttotal: 711ms\tremaining: 1.63s\n",
            "304:\tlearn: 0.1248410\ttotal: 714ms\tremaining: 1.63s\n",
            "305:\tlearn: 0.1248153\ttotal: 716ms\tremaining: 1.62s\n",
            "306:\tlearn: 0.1247493\ttotal: 718ms\tremaining: 1.62s\n",
            "307:\tlearn: 0.1246714\ttotal: 720ms\tremaining: 1.62s\n",
            "308:\tlearn: 0.1245479\ttotal: 722ms\tremaining: 1.61s\n",
            "309:\tlearn: 0.1244307\ttotal: 724ms\tremaining: 1.61s\n",
            "310:\tlearn: 0.1243102\ttotal: 726ms\tremaining: 1.61s\n",
            "311:\tlearn: 0.1241707\ttotal: 730ms\tremaining: 1.61s\n",
            "312:\tlearn: 0.1241087\ttotal: 732ms\tremaining: 1.61s\n",
            "313:\tlearn: 0.1240691\ttotal: 736ms\tremaining: 1.61s\n",
            "314:\tlearn: 0.1240100\ttotal: 738ms\tremaining: 1.6s\n",
            "315:\tlearn: 0.1239554\ttotal: 740ms\tremaining: 1.6s\n",
            "316:\tlearn: 0.1239550\ttotal: 741ms\tremaining: 1.6s\n",
            "317:\tlearn: 0.1238284\ttotal: 743ms\tremaining: 1.59s\n",
            "318:\tlearn: 0.1237468\ttotal: 745ms\tremaining: 1.59s\n",
            "319:\tlearn: 0.1236504\ttotal: 747ms\tremaining: 1.59s\n",
            "320:\tlearn: 0.1235490\ttotal: 749ms\tremaining: 1.58s\n",
            "321:\tlearn: 0.1234653\ttotal: 751ms\tremaining: 1.58s\n",
            "322:\tlearn: 0.1234137\ttotal: 754ms\tremaining: 1.58s\n",
            "323:\tlearn: 0.1233554\ttotal: 755ms\tremaining: 1.58s\n",
            "324:\tlearn: 0.1232648\ttotal: 757ms\tremaining: 1.57s\n",
            "325:\tlearn: 0.1232064\ttotal: 759ms\tremaining: 1.57s\n",
            "326:\tlearn: 0.1231609\ttotal: 761ms\tremaining: 1.57s\n",
            "327:\tlearn: 0.1231078\ttotal: 763ms\tremaining: 1.56s\n",
            "328:\tlearn: 0.1230392\ttotal: 765ms\tremaining: 1.56s\n",
            "329:\tlearn: 0.1229085\ttotal: 767ms\tremaining: 1.56s\n",
            "330:\tlearn: 0.1228537\ttotal: 769ms\tremaining: 1.55s\n",
            "331:\tlearn: 0.1227710\ttotal: 771ms\tremaining: 1.55s\n",
            "332:\tlearn: 0.1226555\ttotal: 773ms\tremaining: 1.55s\n",
            "333:\tlearn: 0.1225452\ttotal: 775ms\tremaining: 1.54s\n",
            "334:\tlearn: 0.1224363\ttotal: 777ms\tremaining: 1.54s\n",
            "335:\tlearn: 0.1223780\ttotal: 779ms\tremaining: 1.54s\n",
            "336:\tlearn: 0.1223064\ttotal: 781ms\tremaining: 1.54s\n",
            "337:\tlearn: 0.1222463\ttotal: 783ms\tremaining: 1.53s\n",
            "338:\tlearn: 0.1221604\ttotal: 785ms\tremaining: 1.53s\n",
            "339:\tlearn: 0.1220838\ttotal: 787ms\tremaining: 1.53s\n",
            "340:\tlearn: 0.1220813\ttotal: 788ms\tremaining: 1.52s\n",
            "341:\tlearn: 0.1219746\ttotal: 790ms\tremaining: 1.52s\n",
            "342:\tlearn: 0.1218812\ttotal: 797ms\tremaining: 1.53s\n",
            "343:\tlearn: 0.1218127\ttotal: 800ms\tremaining: 1.52s\n",
            "344:\tlearn: 0.1216856\ttotal: 801ms\tremaining: 1.52s\n",
            "345:\tlearn: 0.1216490\ttotal: 803ms\tremaining: 1.52s\n",
            "346:\tlearn: 0.1215892\ttotal: 805ms\tremaining: 1.51s\n",
            "347:\tlearn: 0.1214970\ttotal: 807ms\tremaining: 1.51s\n",
            "348:\tlearn: 0.1214344\ttotal: 809ms\tremaining: 1.51s\n",
            "349:\tlearn: 0.1213615\ttotal: 811ms\tremaining: 1.5s\n",
            "350:\tlearn: 0.1212526\ttotal: 813ms\tremaining: 1.5s\n",
            "351:\tlearn: 0.1211830\ttotal: 815ms\tremaining: 1.5s\n",
            "352:\tlearn: 0.1210790\ttotal: 817ms\tremaining: 1.5s\n",
            "353:\tlearn: 0.1209782\ttotal: 819ms\tremaining: 1.49s\n",
            "354:\tlearn: 0.1209100\ttotal: 820ms\tremaining: 1.49s\n",
            "355:\tlearn: 0.1208282\ttotal: 823ms\tremaining: 1.49s\n",
            "356:\tlearn: 0.1207516\ttotal: 824ms\tremaining: 1.48s\n",
            "357:\tlearn: 0.1206614\ttotal: 826ms\tremaining: 1.48s\n",
            "358:\tlearn: 0.1205980\ttotal: 828ms\tremaining: 1.48s\n",
            "359:\tlearn: 0.1204598\ttotal: 830ms\tremaining: 1.48s\n",
            "360:\tlearn: 0.1203597\ttotal: 832ms\tremaining: 1.47s\n",
            "361:\tlearn: 0.1202811\ttotal: 834ms\tremaining: 1.47s\n",
            "362:\tlearn: 0.1201876\ttotal: 836ms\tremaining: 1.47s\n",
            "363:\tlearn: 0.1201101\ttotal: 838ms\tremaining: 1.46s\n",
            "364:\tlearn: 0.1199983\ttotal: 839ms\tremaining: 1.46s\n",
            "365:\tlearn: 0.1199190\ttotal: 841ms\tremaining: 1.46s\n",
            "366:\tlearn: 0.1198583\ttotal: 843ms\tremaining: 1.45s\n",
            "367:\tlearn: 0.1197890\ttotal: 845ms\tremaining: 1.45s\n",
            "368:\tlearn: 0.1197388\ttotal: 847ms\tremaining: 1.45s\n",
            "369:\tlearn: 0.1196483\ttotal: 849ms\tremaining: 1.45s\n",
            "370:\tlearn: 0.1195812\ttotal: 852ms\tremaining: 1.44s\n",
            "371:\tlearn: 0.1195278\ttotal: 853ms\tremaining: 1.44s\n",
            "372:\tlearn: 0.1195274\ttotal: 854ms\tremaining: 1.44s\n",
            "373:\tlearn: 0.1194828\ttotal: 856ms\tremaining: 1.43s\n",
            "374:\tlearn: 0.1193929\ttotal: 859ms\tremaining: 1.43s\n",
            "375:\tlearn: 0.1193190\ttotal: 860ms\tremaining: 1.43s\n",
            "376:\tlearn: 0.1192577\ttotal: 862ms\tremaining: 1.42s\n",
            "377:\tlearn: 0.1191536\ttotal: 864ms\tremaining: 1.42s\n",
            "378:\tlearn: 0.1190916\ttotal: 866ms\tremaining: 1.42s\n",
            "379:\tlearn: 0.1190452\ttotal: 868ms\tremaining: 1.42s\n",
            "380:\tlearn: 0.1189705\ttotal: 870ms\tremaining: 1.41s\n",
            "381:\tlearn: 0.1188553\ttotal: 872ms\tremaining: 1.41s\n",
            "382:\tlearn: 0.1187595\ttotal: 874ms\tremaining: 1.41s\n",
            "383:\tlearn: 0.1186937\ttotal: 877ms\tremaining: 1.41s\n",
            "384:\tlearn: 0.1185884\ttotal: 880ms\tremaining: 1.41s\n",
            "385:\tlearn: 0.1184969\ttotal: 883ms\tremaining: 1.4s\n",
            "386:\tlearn: 0.1184270\ttotal: 887ms\tremaining: 1.41s\n",
            "387:\tlearn: 0.1183612\ttotal: 890ms\tremaining: 1.4s\n",
            "388:\tlearn: 0.1182891\ttotal: 892ms\tremaining: 1.4s\n",
            "389:\tlearn: 0.1181796\ttotal: 894ms\tremaining: 1.4s\n",
            "390:\tlearn: 0.1181010\ttotal: 896ms\tremaining: 1.4s\n",
            "391:\tlearn: 0.1180233\ttotal: 898ms\tremaining: 1.39s\n",
            "392:\tlearn: 0.1179562\ttotal: 900ms\tremaining: 1.39s\n",
            "393:\tlearn: 0.1178638\ttotal: 902ms\tremaining: 1.39s\n",
            "394:\tlearn: 0.1177890\ttotal: 904ms\tremaining: 1.38s\n",
            "395:\tlearn: 0.1176215\ttotal: 909ms\tremaining: 1.39s\n",
            "396:\tlearn: 0.1175283\ttotal: 912ms\tremaining: 1.39s\n",
            "397:\tlearn: 0.1174363\ttotal: 915ms\tremaining: 1.38s\n",
            "398:\tlearn: 0.1173224\ttotal: 918ms\tremaining: 1.38s\n",
            "399:\tlearn: 0.1172613\ttotal: 919ms\tremaining: 1.38s\n",
            "400:\tlearn: 0.1171829\ttotal: 922ms\tremaining: 1.38s\n",
            "401:\tlearn: 0.1171483\ttotal: 924ms\tremaining: 1.37s\n",
            "402:\tlearn: 0.1170661\ttotal: 925ms\tremaining: 1.37s\n",
            "403:\tlearn: 0.1169842\ttotal: 927ms\tremaining: 1.37s\n",
            "404:\tlearn: 0.1168642\ttotal: 929ms\tremaining: 1.36s\n",
            "405:\tlearn: 0.1168193\ttotal: 932ms\tremaining: 1.36s\n",
            "406:\tlearn: 0.1167763\ttotal: 934ms\tremaining: 1.36s\n",
            "407:\tlearn: 0.1166798\ttotal: 936ms\tremaining: 1.36s\n",
            "408:\tlearn: 0.1166124\ttotal: 938ms\tremaining: 1.35s\n",
            "409:\tlearn: 0.1165275\ttotal: 941ms\tremaining: 1.35s\n",
            "410:\tlearn: 0.1164680\ttotal: 943ms\tremaining: 1.35s\n",
            "411:\tlearn: 0.1163746\ttotal: 945ms\tremaining: 1.35s\n",
            "412:\tlearn: 0.1162967\ttotal: 948ms\tremaining: 1.35s\n",
            "413:\tlearn: 0.1162268\ttotal: 950ms\tremaining: 1.34s\n",
            "414:\tlearn: 0.1161709\ttotal: 952ms\tremaining: 1.34s\n",
            "415:\tlearn: 0.1160894\ttotal: 954ms\tremaining: 1.34s\n",
            "416:\tlearn: 0.1159781\ttotal: 956ms\tremaining: 1.34s\n",
            "417:\tlearn: 0.1159062\ttotal: 958ms\tremaining: 1.33s\n",
            "418:\tlearn: 0.1158001\ttotal: 960ms\tremaining: 1.33s\n",
            "419:\tlearn: 0.1157172\ttotal: 962ms\tremaining: 1.33s\n",
            "420:\tlearn: 0.1156342\ttotal: 964ms\tremaining: 1.33s\n",
            "421:\tlearn: 0.1155556\ttotal: 966ms\tremaining: 1.32s\n",
            "422:\tlearn: 0.1154199\ttotal: 968ms\tremaining: 1.32s\n",
            "423:\tlearn: 0.1153708\ttotal: 970ms\tremaining: 1.32s\n",
            "424:\tlearn: 0.1152741\ttotal: 972ms\tremaining: 1.31s\n",
            "425:\tlearn: 0.1152074\ttotal: 974ms\tremaining: 1.31s\n",
            "426:\tlearn: 0.1151168\ttotal: 978ms\tremaining: 1.31s\n",
            "427:\tlearn: 0.1150660\ttotal: 982ms\tremaining: 1.31s\n",
            "428:\tlearn: 0.1150232\ttotal: 984ms\tremaining: 1.31s\n",
            "429:\tlearn: 0.1149203\ttotal: 986ms\tremaining: 1.31s\n",
            "430:\tlearn: 0.1148700\ttotal: 988ms\tremaining: 1.3s\n",
            "431:\tlearn: 0.1147735\ttotal: 990ms\tremaining: 1.3s\n",
            "432:\tlearn: 0.1147206\ttotal: 991ms\tremaining: 1.3s\n",
            "433:\tlearn: 0.1146382\ttotal: 993ms\tremaining: 1.29s\n",
            "434:\tlearn: 0.1145627\ttotal: 995ms\tremaining: 1.29s\n",
            "435:\tlearn: 0.1144823\ttotal: 997ms\tremaining: 1.29s\n",
            "436:\tlearn: 0.1143943\ttotal: 999ms\tremaining: 1.29s\n",
            "437:\tlearn: 0.1143115\ttotal: 1s\tremaining: 1.28s\n",
            "438:\tlearn: 0.1142272\ttotal: 1s\tremaining: 1.28s\n",
            "439:\tlearn: 0.1141846\ttotal: 1s\tremaining: 1.28s\n",
            "440:\tlearn: 0.1141085\ttotal: 1.01s\tremaining: 1.28s\n",
            "441:\tlearn: 0.1140174\ttotal: 1.01s\tremaining: 1.27s\n",
            "442:\tlearn: 0.1139097\ttotal: 1.01s\tremaining: 1.27s\n",
            "443:\tlearn: 0.1138359\ttotal: 1.01s\tremaining: 1.27s\n",
            "444:\tlearn: 0.1137916\ttotal: 1.01s\tremaining: 1.26s\n",
            "445:\tlearn: 0.1137459\ttotal: 1.02s\tremaining: 1.26s\n",
            "446:\tlearn: 0.1136774\ttotal: 1.02s\tremaining: 1.26s\n",
            "447:\tlearn: 0.1136023\ttotal: 1.02s\tremaining: 1.26s\n",
            "448:\tlearn: 0.1135691\ttotal: 1.02s\tremaining: 1.25s\n",
            "449:\tlearn: 0.1134818\ttotal: 1.02s\tremaining: 1.25s\n",
            "450:\tlearn: 0.1133448\ttotal: 1.03s\tremaining: 1.25s\n",
            "451:\tlearn: 0.1132598\ttotal: 1.03s\tremaining: 1.25s\n",
            "452:\tlearn: 0.1132104\ttotal: 1.03s\tremaining: 1.24s\n",
            "453:\tlearn: 0.1131229\ttotal: 1.03s\tremaining: 1.24s\n",
            "454:\tlearn: 0.1130523\ttotal: 1.03s\tremaining: 1.24s\n",
            "455:\tlearn: 0.1129962\ttotal: 1.04s\tremaining: 1.24s\n",
            "456:\tlearn: 0.1128947\ttotal: 1.04s\tremaining: 1.24s\n",
            "457:\tlearn: 0.1128224\ttotal: 1.04s\tremaining: 1.23s\n",
            "458:\tlearn: 0.1127307\ttotal: 1.04s\tremaining: 1.23s\n",
            "459:\tlearn: 0.1126683\ttotal: 1.04s\tremaining: 1.23s\n",
            "460:\tlearn: 0.1125994\ttotal: 1.05s\tremaining: 1.22s\n",
            "461:\tlearn: 0.1125213\ttotal: 1.05s\tremaining: 1.22s\n",
            "462:\tlearn: 0.1124166\ttotal: 1.05s\tremaining: 1.22s\n",
            "463:\tlearn: 0.1123741\ttotal: 1.05s\tremaining: 1.22s\n",
            "464:\tlearn: 0.1122715\ttotal: 1.05s\tremaining: 1.21s\n",
            "465:\tlearn: 0.1121899\ttotal: 1.06s\tremaining: 1.21s\n",
            "466:\tlearn: 0.1120958\ttotal: 1.06s\tremaining: 1.21s\n",
            "467:\tlearn: 0.1120413\ttotal: 1.06s\tremaining: 1.21s\n",
            "468:\tlearn: 0.1119632\ttotal: 1.06s\tremaining: 1.2s\n",
            "469:\tlearn: 0.1118912\ttotal: 1.06s\tremaining: 1.2s\n",
            "470:\tlearn: 0.1117879\ttotal: 1.07s\tremaining: 1.2s\n",
            "471:\tlearn: 0.1117120\ttotal: 1.07s\tremaining: 1.2s\n",
            "472:\tlearn: 0.1116763\ttotal: 1.07s\tremaining: 1.19s\n",
            "473:\tlearn: 0.1115981\ttotal: 1.07s\tremaining: 1.19s\n",
            "474:\tlearn: 0.1115585\ttotal: 1.07s\tremaining: 1.19s\n",
            "475:\tlearn: 0.1114761\ttotal: 1.08s\tremaining: 1.19s\n",
            "476:\tlearn: 0.1114040\ttotal: 1.08s\tremaining: 1.18s\n",
            "477:\tlearn: 0.1113103\ttotal: 1.08s\tremaining: 1.18s\n",
            "478:\tlearn: 0.1112203\ttotal: 1.08s\tremaining: 1.18s\n",
            "479:\tlearn: 0.1111015\ttotal: 1.08s\tremaining: 1.17s\n",
            "480:\tlearn: 0.1110451\ttotal: 1.08s\tremaining: 1.17s\n",
            "481:\tlearn: 0.1109606\ttotal: 1.09s\tremaining: 1.18s\n",
            "482:\tlearn: 0.1108838\ttotal: 1.1s\tremaining: 1.17s\n",
            "483:\tlearn: 0.1108105\ttotal: 1.1s\tremaining: 1.17s\n",
            "484:\tlearn: 0.1107185\ttotal: 1.1s\tremaining: 1.17s\n",
            "485:\tlearn: 0.1106817\ttotal: 1.1s\tremaining: 1.17s\n",
            "486:\tlearn: 0.1105986\ttotal: 1.1s\tremaining: 1.16s\n",
            "487:\tlearn: 0.1105565\ttotal: 1.11s\tremaining: 1.17s\n",
            "488:\tlearn: 0.1105098\ttotal: 1.12s\tremaining: 1.17s\n",
            "489:\tlearn: 0.1104103\ttotal: 1.12s\tremaining: 1.16s\n",
            "490:\tlearn: 0.1103418\ttotal: 1.12s\tremaining: 1.16s\n",
            "491:\tlearn: 0.1102940\ttotal: 1.12s\tremaining: 1.16s\n",
            "492:\tlearn: 0.1102575\ttotal: 1.12s\tremaining: 1.16s\n",
            "493:\tlearn: 0.1102033\ttotal: 1.13s\tremaining: 1.15s\n",
            "494:\tlearn: 0.1100958\ttotal: 1.13s\tremaining: 1.15s\n",
            "495:\tlearn: 0.1100317\ttotal: 1.13s\tremaining: 1.15s\n",
            "496:\tlearn: 0.1099567\ttotal: 1.13s\tremaining: 1.15s\n",
            "497:\tlearn: 0.1098605\ttotal: 1.14s\tremaining: 1.14s\n",
            "498:\tlearn: 0.1097561\ttotal: 1.14s\tremaining: 1.14s\n",
            "499:\tlearn: 0.1096677\ttotal: 1.14s\tremaining: 1.14s\n",
            "500:\tlearn: 0.1095831\ttotal: 1.14s\tremaining: 1.14s\n",
            "501:\tlearn: 0.1094903\ttotal: 1.14s\tremaining: 1.13s\n",
            "502:\tlearn: 0.1093889\ttotal: 1.15s\tremaining: 1.13s\n",
            "503:\tlearn: 0.1093331\ttotal: 1.15s\tremaining: 1.13s\n",
            "504:\tlearn: 0.1092593\ttotal: 1.15s\tremaining: 1.13s\n",
            "505:\tlearn: 0.1091580\ttotal: 1.15s\tremaining: 1.12s\n",
            "506:\tlearn: 0.1090668\ttotal: 1.15s\tremaining: 1.12s\n",
            "507:\tlearn: 0.1089768\ttotal: 1.16s\tremaining: 1.12s\n",
            "508:\tlearn: 0.1089069\ttotal: 1.16s\tremaining: 1.12s\n",
            "509:\tlearn: 0.1088329\ttotal: 1.16s\tremaining: 1.11s\n",
            "510:\tlearn: 0.1087722\ttotal: 1.16s\tremaining: 1.11s\n",
            "511:\tlearn: 0.1086705\ttotal: 1.17s\tremaining: 1.11s\n",
            "512:\tlearn: 0.1085663\ttotal: 1.17s\tremaining: 1.11s\n",
            "513:\tlearn: 0.1084752\ttotal: 1.17s\tremaining: 1.11s\n",
            "514:\tlearn: 0.1083842\ttotal: 1.17s\tremaining: 1.1s\n",
            "515:\tlearn: 0.1083152\ttotal: 1.18s\tremaining: 1.1s\n",
            "516:\tlearn: 0.1082450\ttotal: 1.18s\tremaining: 1.1s\n",
            "517:\tlearn: 0.1081826\ttotal: 1.18s\tremaining: 1.1s\n",
            "518:\tlearn: 0.1081240\ttotal: 1.18s\tremaining: 1.09s\n",
            "519:\tlearn: 0.1080050\ttotal: 1.18s\tremaining: 1.09s\n",
            "520:\tlearn: 0.1079356\ttotal: 1.19s\tremaining: 1.09s\n",
            "521:\tlearn: 0.1078690\ttotal: 1.19s\tremaining: 1.09s\n",
            "522:\tlearn: 0.1078209\ttotal: 1.19s\tremaining: 1.08s\n",
            "523:\tlearn: 0.1077695\ttotal: 1.19s\tremaining: 1.08s\n",
            "524:\tlearn: 0.1077132\ttotal: 1.19s\tremaining: 1.08s\n",
            "525:\tlearn: 0.1076690\ttotal: 1.2s\tremaining: 1.08s\n",
            "526:\tlearn: 0.1076095\ttotal: 1.2s\tremaining: 1.07s\n",
            "527:\tlearn: 0.1075134\ttotal: 1.2s\tremaining: 1.07s\n",
            "528:\tlearn: 0.1074246\ttotal: 1.2s\tremaining: 1.07s\n",
            "529:\tlearn: 0.1073573\ttotal: 1.2s\tremaining: 1.07s\n",
            "530:\tlearn: 0.1072930\ttotal: 1.21s\tremaining: 1.06s\n",
            "531:\tlearn: 0.1072146\ttotal: 1.21s\tremaining: 1.06s\n",
            "532:\tlearn: 0.1071549\ttotal: 1.21s\tremaining: 1.06s\n",
            "533:\tlearn: 0.1070227\ttotal: 1.21s\tremaining: 1.06s\n",
            "534:\tlearn: 0.1069630\ttotal: 1.21s\tremaining: 1.05s\n",
            "535:\tlearn: 0.1068749\ttotal: 1.22s\tremaining: 1.05s\n",
            "536:\tlearn: 0.1068147\ttotal: 1.22s\tremaining: 1.05s\n",
            "537:\tlearn: 0.1067544\ttotal: 1.22s\tremaining: 1.05s\n",
            "538:\tlearn: 0.1066329\ttotal: 1.22s\tremaining: 1.04s\n",
            "539:\tlearn: 0.1065750\ttotal: 1.22s\tremaining: 1.04s\n",
            "540:\tlearn: 0.1065095\ttotal: 1.23s\tremaining: 1.04s\n",
            "541:\tlearn: 0.1064539\ttotal: 1.23s\tremaining: 1.04s\n",
            "542:\tlearn: 0.1063661\ttotal: 1.23s\tremaining: 1.03s\n",
            "543:\tlearn: 0.1063178\ttotal: 1.23s\tremaining: 1.03s\n",
            "544:\tlearn: 0.1062708\ttotal: 1.23s\tremaining: 1.03s\n",
            "545:\tlearn: 0.1061758\ttotal: 1.24s\tremaining: 1.03s\n",
            "546:\tlearn: 0.1061308\ttotal: 1.24s\tremaining: 1.02s\n",
            "547:\tlearn: 0.1060798\ttotal: 1.24s\tremaining: 1.02s\n",
            "548:\tlearn: 0.1060375\ttotal: 1.24s\tremaining: 1.02s\n",
            "549:\tlearn: 0.1059477\ttotal: 1.24s\tremaining: 1.02s\n",
            "550:\tlearn: 0.1058851\ttotal: 1.25s\tremaining: 1.01s\n",
            "551:\tlearn: 0.1058259\ttotal: 1.25s\tremaining: 1.01s\n",
            "552:\tlearn: 0.1057712\ttotal: 1.25s\tremaining: 1.01s\n",
            "553:\tlearn: 0.1057161\ttotal: 1.25s\tremaining: 1.01s\n",
            "554:\tlearn: 0.1056606\ttotal: 1.25s\tremaining: 1.01s\n",
            "555:\tlearn: 0.1055740\ttotal: 1.26s\tremaining: 1s\n",
            "556:\tlearn: 0.1055337\ttotal: 1.26s\tremaining: 1s\n",
            "557:\tlearn: 0.1054708\ttotal: 1.26s\tremaining: 999ms\n",
            "558:\tlearn: 0.1054181\ttotal: 1.26s\tremaining: 997ms\n",
            "559:\tlearn: 0.1053582\ttotal: 1.26s\tremaining: 994ms\n",
            "560:\tlearn: 0.1052794\ttotal: 1.27s\tremaining: 992ms\n",
            "561:\tlearn: 0.1051961\ttotal: 1.27s\tremaining: 990ms\n",
            "562:\tlearn: 0.1051233\ttotal: 1.27s\tremaining: 988ms\n",
            "563:\tlearn: 0.1050412\ttotal: 1.28s\tremaining: 988ms\n",
            "564:\tlearn: 0.1050008\ttotal: 1.28s\tremaining: 990ms\n",
            "565:\tlearn: 0.1049159\ttotal: 1.3s\tremaining: 997ms\n",
            "566:\tlearn: 0.1048357\ttotal: 1.3s\tremaining: 995ms\n",
            "567:\tlearn: 0.1047788\ttotal: 1.3s\tremaining: 993ms\n",
            "568:\tlearn: 0.1047245\ttotal: 1.31s\tremaining: 991ms\n",
            "569:\tlearn: 0.1046473\ttotal: 1.31s\tremaining: 990ms\n",
            "570:\tlearn: 0.1045790\ttotal: 1.31s\tremaining: 989ms\n",
            "571:\tlearn: 0.1045124\ttotal: 1.32s\tremaining: 987ms\n",
            "572:\tlearn: 0.1044288\ttotal: 1.32s\tremaining: 987ms\n",
            "573:\tlearn: 0.1043557\ttotal: 1.33s\tremaining: 984ms\n",
            "574:\tlearn: 0.1042839\ttotal: 1.33s\tremaining: 983ms\n",
            "575:\tlearn: 0.1042045\ttotal: 1.33s\tremaining: 982ms\n",
            "576:\tlearn: 0.1041229\ttotal: 1.34s\tremaining: 983ms\n",
            "577:\tlearn: 0.1040693\ttotal: 1.35s\tremaining: 988ms\n",
            "578:\tlearn: 0.1040084\ttotal: 1.36s\tremaining: 987ms\n",
            "579:\tlearn: 0.1039382\ttotal: 1.36s\tremaining: 986ms\n",
            "580:\tlearn: 0.1038791\ttotal: 1.37s\tremaining: 987ms\n",
            "581:\tlearn: 0.1038262\ttotal: 1.37s\tremaining: 986ms\n",
            "582:\tlearn: 0.1037765\ttotal: 1.38s\tremaining: 984ms\n",
            "583:\tlearn: 0.1037063\ttotal: 1.38s\tremaining: 982ms\n",
            "584:\tlearn: 0.1036278\ttotal: 1.38s\tremaining: 981ms\n",
            "585:\tlearn: 0.1035924\ttotal: 1.39s\tremaining: 980ms\n",
            "586:\tlearn: 0.1035520\ttotal: 1.39s\tremaining: 980ms\n",
            "587:\tlearn: 0.1035008\ttotal: 1.4s\tremaining: 979ms\n",
            "588:\tlearn: 0.1034483\ttotal: 1.4s\tremaining: 979ms\n",
            "589:\tlearn: 0.1033910\ttotal: 1.41s\tremaining: 978ms\n",
            "590:\tlearn: 0.1033283\ttotal: 1.41s\tremaining: 979ms\n",
            "591:\tlearn: 0.1032795\ttotal: 1.42s\tremaining: 978ms\n",
            "592:\tlearn: 0.1032202\ttotal: 1.42s\tremaining: 977ms\n",
            "593:\tlearn: 0.1031533\ttotal: 1.43s\tremaining: 975ms\n",
            "594:\tlearn: 0.1031247\ttotal: 1.43s\tremaining: 974ms\n",
            "595:\tlearn: 0.1030649\ttotal: 1.43s\tremaining: 972ms\n",
            "596:\tlearn: 0.1030236\ttotal: 1.44s\tremaining: 970ms\n",
            "597:\tlearn: 0.1029663\ttotal: 1.44s\tremaining: 968ms\n",
            "598:\tlearn: 0.1028951\ttotal: 1.44s\tremaining: 966ms\n",
            "599:\tlearn: 0.1028199\ttotal: 1.45s\tremaining: 966ms\n",
            "600:\tlearn: 0.1027532\ttotal: 1.45s\tremaining: 965ms\n",
            "601:\tlearn: 0.1027149\ttotal: 1.47s\tremaining: 970ms\n",
            "602:\tlearn: 0.1026516\ttotal: 1.47s\tremaining: 969ms\n",
            "603:\tlearn: 0.1026145\ttotal: 1.48s\tremaining: 968ms\n",
            "604:\tlearn: 0.1025396\ttotal: 1.48s\tremaining: 968ms\n",
            "605:\tlearn: 0.1025082\ttotal: 1.49s\tremaining: 967ms\n",
            "606:\tlearn: 0.1024415\ttotal: 1.49s\tremaining: 965ms\n",
            "607:\tlearn: 0.1023797\ttotal: 1.49s\tremaining: 963ms\n",
            "608:\tlearn: 0.1023201\ttotal: 1.5s\tremaining: 961ms\n",
            "609:\tlearn: 0.1022457\ttotal: 1.5s\tremaining: 958ms\n",
            "610:\tlearn: 0.1021821\ttotal: 1.5s\tremaining: 956ms\n",
            "611:\tlearn: 0.1021349\ttotal: 1.51s\tremaining: 957ms\n",
            "612:\tlearn: 0.1020759\ttotal: 1.52s\tremaining: 957ms\n",
            "613:\tlearn: 0.1020415\ttotal: 1.52s\tremaining: 958ms\n",
            "614:\tlearn: 0.1019686\ttotal: 1.53s\tremaining: 958ms\n",
            "615:\tlearn: 0.1019197\ttotal: 1.54s\tremaining: 961ms\n",
            "616:\tlearn: 0.1018668\ttotal: 1.54s\tremaining: 959ms\n",
            "617:\tlearn: 0.1018025\ttotal: 1.55s\tremaining: 959ms\n",
            "618:\tlearn: 0.1017319\ttotal: 1.56s\tremaining: 958ms\n",
            "619:\tlearn: 0.1016900\ttotal: 1.56s\tremaining: 959ms\n",
            "620:\tlearn: 0.1016379\ttotal: 1.57s\tremaining: 958ms\n",
            "621:\tlearn: 0.1015673\ttotal: 1.57s\tremaining: 957ms\n",
            "622:\tlearn: 0.1015273\ttotal: 1.58s\tremaining: 956ms\n",
            "623:\tlearn: 0.1014749\ttotal: 1.59s\tremaining: 956ms\n",
            "624:\tlearn: 0.1014415\ttotal: 1.59s\tremaining: 955ms\n",
            "625:\tlearn: 0.1013714\ttotal: 1.6s\tremaining: 955ms\n",
            "626:\tlearn: 0.1013268\ttotal: 1.6s\tremaining: 955ms\n",
            "627:\tlearn: 0.1012876\ttotal: 1.61s\tremaining: 953ms\n",
            "628:\tlearn: 0.1012575\ttotal: 1.61s\tremaining: 950ms\n",
            "629:\tlearn: 0.1012224\ttotal: 1.61s\tremaining: 947ms\n",
            "630:\tlearn: 0.1011498\ttotal: 1.61s\tremaining: 944ms\n",
            "631:\tlearn: 0.1011081\ttotal: 1.62s\tremaining: 941ms\n",
            "632:\tlearn: 0.1010380\ttotal: 1.62s\tremaining: 938ms\n",
            "633:\tlearn: 0.1009698\ttotal: 1.62s\tremaining: 935ms\n",
            "634:\tlearn: 0.1009032\ttotal: 1.62s\tremaining: 932ms\n",
            "635:\tlearn: 0.1008342\ttotal: 1.62s\tremaining: 929ms\n",
            "636:\tlearn: 0.1007678\ttotal: 1.63s\tremaining: 927ms\n",
            "637:\tlearn: 0.1006615\ttotal: 1.63s\tremaining: 924ms\n",
            "638:\tlearn: 0.1006283\ttotal: 1.63s\tremaining: 921ms\n",
            "639:\tlearn: 0.1005583\ttotal: 1.63s\tremaining: 919ms\n",
            "640:\tlearn: 0.1005202\ttotal: 1.64s\tremaining: 916ms\n",
            "641:\tlearn: 0.1004815\ttotal: 1.64s\tremaining: 914ms\n",
            "642:\tlearn: 0.1004306\ttotal: 1.64s\tremaining: 911ms\n",
            "643:\tlearn: 0.1003986\ttotal: 1.64s\tremaining: 908ms\n",
            "644:\tlearn: 0.1003625\ttotal: 1.64s\tremaining: 905ms\n",
            "645:\tlearn: 0.1003190\ttotal: 1.65s\tremaining: 902ms\n",
            "646:\tlearn: 0.1002628\ttotal: 1.65s\tremaining: 900ms\n",
            "647:\tlearn: 0.1002025\ttotal: 1.65s\tremaining: 897ms\n",
            "648:\tlearn: 0.1001680\ttotal: 1.66s\tremaining: 897ms\n",
            "649:\tlearn: 0.1000577\ttotal: 1.66s\tremaining: 895ms\n",
            "650:\tlearn: 0.1000022\ttotal: 1.66s\tremaining: 892ms\n",
            "651:\tlearn: 0.0999345\ttotal: 1.67s\tremaining: 889ms\n",
            "652:\tlearn: 0.0998773\ttotal: 1.67s\tremaining: 886ms\n",
            "653:\tlearn: 0.0998269\ttotal: 1.67s\tremaining: 883ms\n",
            "654:\tlearn: 0.0997791\ttotal: 1.67s\tremaining: 881ms\n",
            "655:\tlearn: 0.0997425\ttotal: 1.67s\tremaining: 878ms\n",
            "656:\tlearn: 0.0996934\ttotal: 1.68s\tremaining: 875ms\n",
            "657:\tlearn: 0.0996389\ttotal: 1.68s\tremaining: 872ms\n",
            "658:\tlearn: 0.0995910\ttotal: 1.68s\tremaining: 869ms\n",
            "659:\tlearn: 0.0994849\ttotal: 1.68s\tremaining: 866ms\n",
            "660:\tlearn: 0.0994574\ttotal: 1.68s\tremaining: 863ms\n",
            "661:\tlearn: 0.0994306\ttotal: 1.69s\tremaining: 861ms\n",
            "662:\tlearn: 0.0993901\ttotal: 1.69s\tremaining: 858ms\n",
            "663:\tlearn: 0.0993374\ttotal: 1.69s\tremaining: 855ms\n",
            "664:\tlearn: 0.0992783\ttotal: 1.69s\tremaining: 852ms\n",
            "665:\tlearn: 0.0992273\ttotal: 1.69s\tremaining: 850ms\n",
            "666:\tlearn: 0.0991866\ttotal: 1.7s\tremaining: 847ms\n",
            "667:\tlearn: 0.0991332\ttotal: 1.7s\tremaining: 844ms\n",
            "668:\tlearn: 0.0990314\ttotal: 1.7s\tremaining: 842ms\n",
            "669:\tlearn: 0.0989767\ttotal: 1.7s\tremaining: 839ms\n",
            "670:\tlearn: 0.0989123\ttotal: 1.7s\tremaining: 836ms\n",
            "671:\tlearn: 0.0988760\ttotal: 1.71s\tremaining: 833ms\n",
            "672:\tlearn: 0.0988236\ttotal: 1.71s\tremaining: 830ms\n",
            "673:\tlearn: 0.0987907\ttotal: 1.71s\tremaining: 827ms\n",
            "674:\tlearn: 0.0987554\ttotal: 1.71s\tremaining: 824ms\n",
            "675:\tlearn: 0.0987024\ttotal: 1.71s\tremaining: 822ms\n",
            "676:\tlearn: 0.0986398\ttotal: 1.72s\tremaining: 819ms\n",
            "677:\tlearn: 0.0986040\ttotal: 1.72s\tremaining: 816ms\n",
            "678:\tlearn: 0.0985526\ttotal: 1.72s\tremaining: 813ms\n",
            "679:\tlearn: 0.0984551\ttotal: 1.72s\tremaining: 811ms\n",
            "680:\tlearn: 0.0983964\ttotal: 1.73s\tremaining: 810ms\n",
            "681:\tlearn: 0.0983501\ttotal: 1.73s\tremaining: 807ms\n",
            "682:\tlearn: 0.0982933\ttotal: 1.73s\tremaining: 805ms\n",
            "683:\tlearn: 0.0982575\ttotal: 1.74s\tremaining: 802ms\n",
            "684:\tlearn: 0.0982083\ttotal: 1.74s\tremaining: 799ms\n",
            "685:\tlearn: 0.0981696\ttotal: 1.74s\tremaining: 796ms\n",
            "686:\tlearn: 0.0981178\ttotal: 1.74s\tremaining: 793ms\n",
            "687:\tlearn: 0.0980539\ttotal: 1.74s\tremaining: 790ms\n",
            "688:\tlearn: 0.0980120\ttotal: 1.74s\tremaining: 788ms\n",
            "689:\tlearn: 0.0979778\ttotal: 1.75s\tremaining: 785ms\n",
            "690:\tlearn: 0.0979238\ttotal: 1.75s\tremaining: 782ms\n",
            "691:\tlearn: 0.0978684\ttotal: 1.75s\tremaining: 779ms\n",
            "692:\tlearn: 0.0978309\ttotal: 1.75s\tremaining: 777ms\n",
            "693:\tlearn: 0.0977715\ttotal: 1.75s\tremaining: 774ms\n",
            "694:\tlearn: 0.0977375\ttotal: 1.76s\tremaining: 771ms\n",
            "695:\tlearn: 0.0977012\ttotal: 1.76s\tremaining: 768ms\n",
            "696:\tlearn: 0.0976659\ttotal: 1.76s\tremaining: 766ms\n",
            "697:\tlearn: 0.0976374\ttotal: 1.76s\tremaining: 763ms\n",
            "698:\tlearn: 0.0976045\ttotal: 1.76s\tremaining: 760ms\n",
            "699:\tlearn: 0.0975579\ttotal: 1.77s\tremaining: 758ms\n",
            "700:\tlearn: 0.0974964\ttotal: 1.77s\tremaining: 755ms\n",
            "701:\tlearn: 0.0974487\ttotal: 1.77s\tremaining: 752ms\n",
            "702:\tlearn: 0.0973986\ttotal: 1.77s\tremaining: 749ms\n",
            "703:\tlearn: 0.0973404\ttotal: 1.77s\tremaining: 747ms\n",
            "704:\tlearn: 0.0972875\ttotal: 1.78s\tremaining: 744ms\n",
            "705:\tlearn: 0.0972368\ttotal: 1.78s\tremaining: 741ms\n",
            "706:\tlearn: 0.0972087\ttotal: 1.78s\tremaining: 738ms\n",
            "707:\tlearn: 0.0971755\ttotal: 1.78s\tremaining: 735ms\n",
            "708:\tlearn: 0.0971391\ttotal: 1.78s\tremaining: 733ms\n",
            "709:\tlearn: 0.0970869\ttotal: 1.79s\tremaining: 730ms\n",
            "710:\tlearn: 0.0970555\ttotal: 1.79s\tremaining: 727ms\n",
            "711:\tlearn: 0.0969947\ttotal: 1.79s\tremaining: 726ms\n",
            "712:\tlearn: 0.0969338\ttotal: 1.79s\tremaining: 723ms\n",
            "713:\tlearn: 0.0968764\ttotal: 1.8s\tremaining: 720ms\n",
            "714:\tlearn: 0.0968276\ttotal: 1.8s\tremaining: 717ms\n",
            "715:\tlearn: 0.0967961\ttotal: 1.8s\tremaining: 715ms\n",
            "716:\tlearn: 0.0967028\ttotal: 1.8s\tremaining: 712ms\n",
            "717:\tlearn: 0.0966127\ttotal: 1.8s\tremaining: 709ms\n",
            "718:\tlearn: 0.0965532\ttotal: 1.81s\tremaining: 706ms\n",
            "719:\tlearn: 0.0965164\ttotal: 1.81s\tremaining: 704ms\n",
            "720:\tlearn: 0.0964664\ttotal: 1.81s\tremaining: 701ms\n",
            "721:\tlearn: 0.0964354\ttotal: 1.81s\tremaining: 698ms\n",
            "722:\tlearn: 0.0963837\ttotal: 1.81s\tremaining: 696ms\n",
            "723:\tlearn: 0.0963535\ttotal: 1.82s\tremaining: 693ms\n",
            "724:\tlearn: 0.0963057\ttotal: 1.82s\tremaining: 690ms\n",
            "725:\tlearn: 0.0962487\ttotal: 1.82s\tremaining: 687ms\n",
            "726:\tlearn: 0.0962169\ttotal: 1.82s\tremaining: 685ms\n",
            "727:\tlearn: 0.0961700\ttotal: 1.82s\tremaining: 682ms\n",
            "728:\tlearn: 0.0961432\ttotal: 1.83s\tremaining: 679ms\n",
            "729:\tlearn: 0.0960890\ttotal: 1.83s\tremaining: 677ms\n",
            "730:\tlearn: 0.0960628\ttotal: 1.83s\tremaining: 674ms\n",
            "731:\tlearn: 0.0959841\ttotal: 1.83s\tremaining: 672ms\n",
            "732:\tlearn: 0.0959484\ttotal: 1.83s\tremaining: 669ms\n",
            "733:\tlearn: 0.0959135\ttotal: 1.84s\tremaining: 666ms\n",
            "734:\tlearn: 0.0958747\ttotal: 1.84s\tremaining: 663ms\n",
            "735:\tlearn: 0.0958271\ttotal: 1.84s\tremaining: 661ms\n",
            "736:\tlearn: 0.0957981\ttotal: 1.85s\tremaining: 659ms\n",
            "737:\tlearn: 0.0957740\ttotal: 1.85s\tremaining: 656ms\n",
            "738:\tlearn: 0.0957336\ttotal: 1.85s\tremaining: 655ms\n",
            "739:\tlearn: 0.0956731\ttotal: 1.85s\tremaining: 652ms\n",
            "740:\tlearn: 0.0956329\ttotal: 1.86s\tremaining: 649ms\n",
            "741:\tlearn: 0.0955874\ttotal: 1.86s\tremaining: 646ms\n",
            "742:\tlearn: 0.0955422\ttotal: 1.86s\tremaining: 644ms\n",
            "743:\tlearn: 0.0955167\ttotal: 1.86s\tremaining: 641ms\n",
            "744:\tlearn: 0.0954693\ttotal: 1.86s\tremaining: 638ms\n",
            "745:\tlearn: 0.0954304\ttotal: 1.87s\tremaining: 636ms\n",
            "746:\tlearn: 0.0953843\ttotal: 1.87s\tremaining: 633ms\n",
            "747:\tlearn: 0.0953189\ttotal: 1.87s\tremaining: 630ms\n",
            "748:\tlearn: 0.0952814\ttotal: 1.87s\tremaining: 627ms\n",
            "749:\tlearn: 0.0952565\ttotal: 1.87s\tremaining: 625ms\n",
            "750:\tlearn: 0.0952153\ttotal: 1.88s\tremaining: 622ms\n",
            "751:\tlearn: 0.0951631\ttotal: 1.88s\tremaining: 619ms\n",
            "752:\tlearn: 0.0950947\ttotal: 1.88s\tremaining: 617ms\n",
            "753:\tlearn: 0.0950616\ttotal: 1.88s\tremaining: 614ms\n",
            "754:\tlearn: 0.0950230\ttotal: 1.88s\tremaining: 612ms\n",
            "755:\tlearn: 0.0949969\ttotal: 1.89s\tremaining: 609ms\n",
            "756:\tlearn: 0.0949523\ttotal: 1.89s\tremaining: 606ms\n",
            "757:\tlearn: 0.0948668\ttotal: 1.89s\tremaining: 604ms\n",
            "758:\tlearn: 0.0948163\ttotal: 1.89s\tremaining: 601ms\n",
            "759:\tlearn: 0.0947924\ttotal: 1.89s\tremaining: 598ms\n",
            "760:\tlearn: 0.0947246\ttotal: 1.9s\tremaining: 596ms\n",
            "761:\tlearn: 0.0947017\ttotal: 1.9s\tremaining: 593ms\n",
            "762:\tlearn: 0.0946746\ttotal: 1.9s\tremaining: 590ms\n",
            "763:\tlearn: 0.0946319\ttotal: 1.9s\tremaining: 588ms\n",
            "764:\tlearn: 0.0945607\ttotal: 1.9s\tremaining: 585ms\n",
            "765:\tlearn: 0.0945117\ttotal: 1.91s\tremaining: 583ms\n",
            "766:\tlearn: 0.0944748\ttotal: 1.91s\tremaining: 580ms\n",
            "767:\tlearn: 0.0943918\ttotal: 1.91s\tremaining: 578ms\n",
            "768:\tlearn: 0.0943537\ttotal: 1.92s\tremaining: 576ms\n",
            "769:\tlearn: 0.0943235\ttotal: 1.92s\tremaining: 574ms\n",
            "770:\tlearn: 0.0942852\ttotal: 1.92s\tremaining: 572ms\n",
            "771:\tlearn: 0.0942210\ttotal: 1.93s\tremaining: 569ms\n",
            "772:\tlearn: 0.0941669\ttotal: 1.93s\tremaining: 566ms\n",
            "773:\tlearn: 0.0941115\ttotal: 1.93s\tremaining: 564ms\n",
            "774:\tlearn: 0.0940294\ttotal: 1.93s\tremaining: 561ms\n",
            "775:\tlearn: 0.0939835\ttotal: 1.93s\tremaining: 558ms\n",
            "776:\tlearn: 0.0939603\ttotal: 1.94s\tremaining: 555ms\n",
            "777:\tlearn: 0.0939129\ttotal: 1.94s\tremaining: 553ms\n",
            "778:\tlearn: 0.0938649\ttotal: 1.94s\tremaining: 550ms\n",
            "779:\tlearn: 0.0938257\ttotal: 1.94s\tremaining: 547ms\n",
            "780:\tlearn: 0.0937373\ttotal: 1.94s\tremaining: 545ms\n",
            "781:\tlearn: 0.0936812\ttotal: 1.94s\tremaining: 542ms\n",
            "782:\tlearn: 0.0936587\ttotal: 1.95s\tremaining: 539ms\n",
            "783:\tlearn: 0.0936257\ttotal: 1.95s\tremaining: 537ms\n",
            "784:\tlearn: 0.0935575\ttotal: 1.95s\tremaining: 534ms\n",
            "785:\tlearn: 0.0934887\ttotal: 1.95s\tremaining: 531ms\n",
            "786:\tlearn: 0.0933774\ttotal: 1.95s\tremaining: 529ms\n",
            "787:\tlearn: 0.0932695\ttotal: 1.96s\tremaining: 526ms\n",
            "788:\tlearn: 0.0932032\ttotal: 1.96s\tremaining: 524ms\n",
            "789:\tlearn: 0.0931774\ttotal: 1.96s\tremaining: 521ms\n",
            "790:\tlearn: 0.0931467\ttotal: 1.96s\tremaining: 519ms\n",
            "791:\tlearn: 0.0931032\ttotal: 1.97s\tremaining: 516ms\n",
            "792:\tlearn: 0.0930188\ttotal: 1.97s\tremaining: 514ms\n",
            "793:\tlearn: 0.0929598\ttotal: 1.97s\tremaining: 511ms\n",
            "794:\tlearn: 0.0929178\ttotal: 1.97s\tremaining: 508ms\n",
            "795:\tlearn: 0.0928366\ttotal: 1.97s\tremaining: 506ms\n",
            "796:\tlearn: 0.0927987\ttotal: 1.98s\tremaining: 503ms\n",
            "797:\tlearn: 0.0927448\ttotal: 1.98s\tremaining: 501ms\n",
            "798:\tlearn: 0.0926994\ttotal: 1.98s\tremaining: 498ms\n",
            "799:\tlearn: 0.0925963\ttotal: 1.98s\tremaining: 496ms\n",
            "800:\tlearn: 0.0925330\ttotal: 1.98s\tremaining: 493ms\n",
            "801:\tlearn: 0.0924902\ttotal: 1.99s\tremaining: 490ms\n",
            "802:\tlearn: 0.0924250\ttotal: 1.99s\tremaining: 488ms\n",
            "803:\tlearn: 0.0923922\ttotal: 1.99s\tremaining: 485ms\n",
            "804:\tlearn: 0.0923353\ttotal: 1.99s\tremaining: 483ms\n",
            "805:\tlearn: 0.0922738\ttotal: 1.99s\tremaining: 480ms\n",
            "806:\tlearn: 0.0922122\ttotal: 2s\tremaining: 477ms\n",
            "807:\tlearn: 0.0921709\ttotal: 2s\tremaining: 475ms\n",
            "808:\tlearn: 0.0921110\ttotal: 2s\tremaining: 472ms\n",
            "809:\tlearn: 0.0920528\ttotal: 2s\tremaining: 470ms\n",
            "810:\tlearn: 0.0920094\ttotal: 2s\tremaining: 467ms\n",
            "811:\tlearn: 0.0919563\ttotal: 2.01s\tremaining: 465ms\n",
            "812:\tlearn: 0.0919077\ttotal: 2.01s\tremaining: 462ms\n",
            "813:\tlearn: 0.0918520\ttotal: 2.01s\tremaining: 459ms\n",
            "814:\tlearn: 0.0918152\ttotal: 2.01s\tremaining: 457ms\n",
            "815:\tlearn: 0.0917519\ttotal: 2.01s\tremaining: 454ms\n",
            "816:\tlearn: 0.0917280\ttotal: 2.02s\tremaining: 452ms\n",
            "817:\tlearn: 0.0916731\ttotal: 2.02s\tremaining: 449ms\n",
            "818:\tlearn: 0.0916189\ttotal: 2.02s\tremaining: 447ms\n",
            "819:\tlearn: 0.0915947\ttotal: 2.02s\tremaining: 444ms\n",
            "820:\tlearn: 0.0915470\ttotal: 2.02s\tremaining: 441ms\n",
            "821:\tlearn: 0.0914775\ttotal: 2.03s\tremaining: 439ms\n",
            "822:\tlearn: 0.0914475\ttotal: 2.03s\tremaining: 436ms\n",
            "823:\tlearn: 0.0914014\ttotal: 2.03s\tremaining: 434ms\n",
            "824:\tlearn: 0.0913545\ttotal: 2.04s\tremaining: 432ms\n",
            "825:\tlearn: 0.0913252\ttotal: 2.04s\tremaining: 429ms\n",
            "826:\tlearn: 0.0912826\ttotal: 2.04s\tremaining: 427ms\n",
            "827:\tlearn: 0.0912374\ttotal: 2.04s\tremaining: 424ms\n",
            "828:\tlearn: 0.0912126\ttotal: 2.04s\tremaining: 422ms\n",
            "829:\tlearn: 0.0911636\ttotal: 2.04s\tremaining: 419ms\n",
            "830:\tlearn: 0.0911024\ttotal: 2.05s\tremaining: 416ms\n",
            "831:\tlearn: 0.0910715\ttotal: 2.05s\tremaining: 414ms\n",
            "832:\tlearn: 0.0910207\ttotal: 2.05s\tremaining: 411ms\n",
            "833:\tlearn: 0.0909743\ttotal: 2.05s\tremaining: 409ms\n",
            "834:\tlearn: 0.0909458\ttotal: 2.05s\tremaining: 406ms\n",
            "835:\tlearn: 0.0909035\ttotal: 2.06s\tremaining: 403ms\n",
            "836:\tlearn: 0.0908389\ttotal: 2.06s\tremaining: 401ms\n",
            "837:\tlearn: 0.0907904\ttotal: 2.06s\tremaining: 398ms\n",
            "838:\tlearn: 0.0907512\ttotal: 2.06s\tremaining: 396ms\n",
            "839:\tlearn: 0.0906971\ttotal: 2.06s\tremaining: 393ms\n",
            "840:\tlearn: 0.0906444\ttotal: 2.06s\tremaining: 390ms\n",
            "841:\tlearn: 0.0905989\ttotal: 2.07s\tremaining: 388ms\n",
            "842:\tlearn: 0.0905574\ttotal: 2.07s\tremaining: 385ms\n",
            "843:\tlearn: 0.0905172\ttotal: 2.07s\tremaining: 383ms\n",
            "844:\tlearn: 0.0904837\ttotal: 2.07s\tremaining: 380ms\n",
            "845:\tlearn: 0.0904400\ttotal: 2.08s\tremaining: 378ms\n",
            "846:\tlearn: 0.0903434\ttotal: 2.08s\tremaining: 375ms\n",
            "847:\tlearn: 0.0903052\ttotal: 2.08s\tremaining: 373ms\n",
            "848:\tlearn: 0.0902609\ttotal: 2.08s\tremaining: 370ms\n",
            "849:\tlearn: 0.0902336\ttotal: 2.08s\tremaining: 368ms\n",
            "850:\tlearn: 0.0902005\ttotal: 2.08s\tremaining: 365ms\n",
            "851:\tlearn: 0.0901158\ttotal: 2.09s\tremaining: 362ms\n",
            "852:\tlearn: 0.0900342\ttotal: 2.09s\tremaining: 360ms\n",
            "853:\tlearn: 0.0899678\ttotal: 2.09s\tremaining: 358ms\n",
            "854:\tlearn: 0.0899445\ttotal: 2.1s\tremaining: 356ms\n",
            "855:\tlearn: 0.0899245\ttotal: 2.1s\tremaining: 353ms\n",
            "856:\tlearn: 0.0898784\ttotal: 2.1s\tremaining: 350ms\n",
            "857:\tlearn: 0.0898082\ttotal: 2.1s\tremaining: 348ms\n",
            "858:\tlearn: 0.0897439\ttotal: 2.1s\tremaining: 345ms\n",
            "859:\tlearn: 0.0897014\ttotal: 2.1s\tremaining: 343ms\n",
            "860:\tlearn: 0.0896747\ttotal: 2.11s\tremaining: 340ms\n",
            "861:\tlearn: 0.0896333\ttotal: 2.11s\tremaining: 338ms\n",
            "862:\tlearn: 0.0895600\ttotal: 2.11s\tremaining: 335ms\n",
            "863:\tlearn: 0.0895013\ttotal: 2.11s\tremaining: 333ms\n",
            "864:\tlearn: 0.0894580\ttotal: 2.12s\tremaining: 330ms\n",
            "865:\tlearn: 0.0894150\ttotal: 2.12s\tremaining: 328ms\n",
            "866:\tlearn: 0.0893245\ttotal: 2.12s\tremaining: 325ms\n",
            "867:\tlearn: 0.0892541\ttotal: 2.12s\tremaining: 323ms\n",
            "868:\tlearn: 0.0892187\ttotal: 2.12s\tremaining: 320ms\n",
            "869:\tlearn: 0.0891737\ttotal: 2.13s\tremaining: 318ms\n",
            "870:\tlearn: 0.0891416\ttotal: 2.13s\tremaining: 315ms\n",
            "871:\tlearn: 0.0890977\ttotal: 2.13s\tremaining: 313ms\n",
            "872:\tlearn: 0.0890716\ttotal: 2.13s\tremaining: 310ms\n",
            "873:\tlearn: 0.0890331\ttotal: 2.13s\tremaining: 308ms\n",
            "874:\tlearn: 0.0889049\ttotal: 2.13s\tremaining: 305ms\n",
            "875:\tlearn: 0.0888678\ttotal: 2.14s\tremaining: 303ms\n",
            "876:\tlearn: 0.0888369\ttotal: 2.14s\tremaining: 300ms\n",
            "877:\tlearn: 0.0888114\ttotal: 2.14s\tremaining: 298ms\n",
            "878:\tlearn: 0.0887660\ttotal: 2.14s\tremaining: 295ms\n",
            "879:\tlearn: 0.0887178\ttotal: 2.14s\tremaining: 292ms\n",
            "880:\tlearn: 0.0886556\ttotal: 2.15s\tremaining: 290ms\n",
            "881:\tlearn: 0.0886178\ttotal: 2.15s\tremaining: 287ms\n",
            "882:\tlearn: 0.0885531\ttotal: 2.15s\tremaining: 285ms\n",
            "883:\tlearn: 0.0885282\ttotal: 2.15s\tremaining: 283ms\n",
            "884:\tlearn: 0.0884834\ttotal: 2.15s\tremaining: 280ms\n",
            "885:\tlearn: 0.0884230\ttotal: 2.16s\tremaining: 278ms\n",
            "886:\tlearn: 0.0883908\ttotal: 2.16s\tremaining: 275ms\n",
            "887:\tlearn: 0.0883104\ttotal: 2.16s\tremaining: 273ms\n",
            "888:\tlearn: 0.0882702\ttotal: 2.16s\tremaining: 270ms\n",
            "889:\tlearn: 0.0882463\ttotal: 2.17s\tremaining: 268ms\n",
            "890:\tlearn: 0.0882059\ttotal: 2.17s\tremaining: 265ms\n",
            "891:\tlearn: 0.0881695\ttotal: 2.17s\tremaining: 263ms\n",
            "892:\tlearn: 0.0881018\ttotal: 2.17s\tremaining: 260ms\n",
            "893:\tlearn: 0.0880503\ttotal: 2.17s\tremaining: 258ms\n",
            "894:\tlearn: 0.0880150\ttotal: 2.17s\tremaining: 255ms\n",
            "895:\tlearn: 0.0879730\ttotal: 2.18s\tremaining: 253ms\n",
            "896:\tlearn: 0.0879432\ttotal: 2.18s\tremaining: 250ms\n",
            "897:\tlearn: 0.0879115\ttotal: 2.18s\tremaining: 248ms\n",
            "898:\tlearn: 0.0878830\ttotal: 2.18s\tremaining: 245ms\n",
            "899:\tlearn: 0.0878407\ttotal: 2.19s\tremaining: 243ms\n",
            "900:\tlearn: 0.0878098\ttotal: 2.19s\tremaining: 240ms\n",
            "901:\tlearn: 0.0877645\ttotal: 2.19s\tremaining: 238ms\n",
            "902:\tlearn: 0.0877222\ttotal: 2.19s\tremaining: 235ms\n",
            "903:\tlearn: 0.0876811\ttotal: 2.19s\tremaining: 233ms\n",
            "904:\tlearn: 0.0876587\ttotal: 2.19s\tremaining: 230ms\n",
            "905:\tlearn: 0.0876250\ttotal: 2.2s\tremaining: 228ms\n",
            "906:\tlearn: 0.0875446\ttotal: 2.2s\tremaining: 225ms\n",
            "907:\tlearn: 0.0875102\ttotal: 2.2s\tremaining: 223ms\n",
            "908:\tlearn: 0.0874742\ttotal: 2.2s\tremaining: 221ms\n",
            "909:\tlearn: 0.0874524\ttotal: 2.21s\tremaining: 218ms\n",
            "910:\tlearn: 0.0874034\ttotal: 2.21s\tremaining: 216ms\n",
            "911:\tlearn: 0.0873649\ttotal: 2.21s\tremaining: 213ms\n",
            "912:\tlearn: 0.0873317\ttotal: 2.21s\tremaining: 211ms\n",
            "913:\tlearn: 0.0872728\ttotal: 2.22s\tremaining: 209ms\n",
            "914:\tlearn: 0.0872385\ttotal: 2.22s\tremaining: 206ms\n",
            "915:\tlearn: 0.0871936\ttotal: 2.23s\tremaining: 204ms\n",
            "916:\tlearn: 0.0871511\ttotal: 2.23s\tremaining: 202ms\n",
            "917:\tlearn: 0.0871299\ttotal: 2.23s\tremaining: 199ms\n",
            "918:\tlearn: 0.0871022\ttotal: 2.23s\tremaining: 197ms\n",
            "919:\tlearn: 0.0870816\ttotal: 2.24s\tremaining: 194ms\n",
            "920:\tlearn: 0.0870600\ttotal: 2.24s\tremaining: 192ms\n",
            "921:\tlearn: 0.0870297\ttotal: 2.24s\tremaining: 189ms\n",
            "922:\tlearn: 0.0870016\ttotal: 2.24s\tremaining: 187ms\n",
            "923:\tlearn: 0.0869652\ttotal: 2.24s\tremaining: 185ms\n",
            "924:\tlearn: 0.0869315\ttotal: 2.25s\tremaining: 182ms\n",
            "925:\tlearn: 0.0868842\ttotal: 2.25s\tremaining: 180ms\n",
            "926:\tlearn: 0.0868658\ttotal: 2.25s\tremaining: 177ms\n",
            "927:\tlearn: 0.0868226\ttotal: 2.25s\tremaining: 175ms\n",
            "928:\tlearn: 0.0867941\ttotal: 2.25s\tremaining: 172ms\n",
            "929:\tlearn: 0.0867565\ttotal: 2.26s\tremaining: 170ms\n",
            "930:\tlearn: 0.0867331\ttotal: 2.26s\tremaining: 168ms\n",
            "931:\tlearn: 0.0866807\ttotal: 2.27s\tremaining: 166ms\n",
            "932:\tlearn: 0.0866451\ttotal: 2.27s\tremaining: 163ms\n",
            "933:\tlearn: 0.0866112\ttotal: 2.28s\tremaining: 161ms\n",
            "934:\tlearn: 0.0865912\ttotal: 2.28s\tremaining: 159ms\n",
            "935:\tlearn: 0.0865024\ttotal: 2.28s\tremaining: 156ms\n",
            "936:\tlearn: 0.0864467\ttotal: 2.28s\tremaining: 154ms\n",
            "937:\tlearn: 0.0863859\ttotal: 2.29s\tremaining: 151ms\n",
            "938:\tlearn: 0.0863664\ttotal: 2.29s\tremaining: 149ms\n",
            "939:\tlearn: 0.0862901\ttotal: 2.29s\tremaining: 146ms\n",
            "940:\tlearn: 0.0862712\ttotal: 2.29s\tremaining: 144ms\n",
            "941:\tlearn: 0.0861978\ttotal: 2.29s\tremaining: 141ms\n",
            "942:\tlearn: 0.0861670\ttotal: 2.3s\tremaining: 139ms\n",
            "943:\tlearn: 0.0861505\ttotal: 2.3s\tremaining: 136ms\n",
            "944:\tlearn: 0.0861216\ttotal: 2.3s\tremaining: 134ms\n",
            "945:\tlearn: 0.0860812\ttotal: 2.31s\tremaining: 132ms\n",
            "946:\tlearn: 0.0860236\ttotal: 2.31s\tremaining: 129ms\n",
            "947:\tlearn: 0.0859830\ttotal: 2.31s\tremaining: 127ms\n",
            "948:\tlearn: 0.0859577\ttotal: 2.31s\tremaining: 124ms\n",
            "949:\tlearn: 0.0859312\ttotal: 2.31s\tremaining: 122ms\n",
            "950:\tlearn: 0.0858973\ttotal: 2.31s\tremaining: 119ms\n",
            "951:\tlearn: 0.0858579\ttotal: 2.32s\tremaining: 117ms\n",
            "952:\tlearn: 0.0858218\ttotal: 2.32s\tremaining: 114ms\n",
            "953:\tlearn: 0.0857778\ttotal: 2.32s\tremaining: 112ms\n",
            "954:\tlearn: 0.0857501\ttotal: 2.32s\tremaining: 109ms\n",
            "955:\tlearn: 0.0857064\ttotal: 2.32s\tremaining: 107ms\n",
            "956:\tlearn: 0.0856882\ttotal: 2.33s\tremaining: 105ms\n",
            "957:\tlearn: 0.0856584\ttotal: 2.33s\tremaining: 102ms\n",
            "958:\tlearn: 0.0856158\ttotal: 2.33s\tremaining: 99.7ms\n",
            "959:\tlearn: 0.0854987\ttotal: 2.33s\tremaining: 97.2ms\n",
            "960:\tlearn: 0.0854570\ttotal: 2.33s\tremaining: 94.8ms\n",
            "961:\tlearn: 0.0854129\ttotal: 2.34s\tremaining: 92.4ms\n",
            "962:\tlearn: 0.0853853\ttotal: 2.34s\tremaining: 90ms\n",
            "963:\tlearn: 0.0853153\ttotal: 2.34s\tremaining: 87.6ms\n",
            "964:\tlearn: 0.0852765\ttotal: 2.35s\tremaining: 85.2ms\n",
            "965:\tlearn: 0.0852393\ttotal: 2.35s\tremaining: 82.9ms\n",
            "966:\tlearn: 0.0852054\ttotal: 2.36s\tremaining: 80.4ms\n",
            "967:\tlearn: 0.0851499\ttotal: 2.36s\tremaining: 78ms\n",
            "968:\tlearn: 0.0851280\ttotal: 2.36s\tremaining: 75.5ms\n",
            "969:\tlearn: 0.0850979\ttotal: 2.36s\tremaining: 73.1ms\n",
            "970:\tlearn: 0.0850695\ttotal: 2.37s\tremaining: 70.7ms\n",
            "971:\tlearn: 0.0850315\ttotal: 2.37s\tremaining: 68.2ms\n",
            "972:\tlearn: 0.0850001\ttotal: 2.37s\tremaining: 65.8ms\n",
            "973:\tlearn: 0.0849377\ttotal: 2.37s\tremaining: 63.3ms\n",
            "974:\tlearn: 0.0849001\ttotal: 2.37s\tremaining: 60.9ms\n",
            "975:\tlearn: 0.0848679\ttotal: 2.38s\tremaining: 58.4ms\n",
            "976:\tlearn: 0.0848101\ttotal: 2.38s\tremaining: 56ms\n",
            "977:\tlearn: 0.0847908\ttotal: 2.38s\tremaining: 53.5ms\n",
            "978:\tlearn: 0.0847588\ttotal: 2.38s\tremaining: 51.1ms\n",
            "979:\tlearn: 0.0847431\ttotal: 2.38s\tremaining: 48.6ms\n",
            "980:\tlearn: 0.0847048\ttotal: 2.38s\tremaining: 46.2ms\n",
            "981:\tlearn: 0.0846603\ttotal: 2.39s\tremaining: 43.8ms\n",
            "982:\tlearn: 0.0846315\ttotal: 2.39s\tremaining: 41.3ms\n",
            "983:\tlearn: 0.0845982\ttotal: 2.39s\tremaining: 38.9ms\n",
            "984:\tlearn: 0.0845498\ttotal: 2.39s\tremaining: 36.5ms\n",
            "985:\tlearn: 0.0844910\ttotal: 2.4s\tremaining: 34ms\n",
            "986:\tlearn: 0.0844518\ttotal: 2.4s\tremaining: 31.6ms\n",
            "987:\tlearn: 0.0844269\ttotal: 2.4s\tremaining: 29.2ms\n",
            "988:\tlearn: 0.0843700\ttotal: 2.4s\tremaining: 26.7ms\n",
            "989:\tlearn: 0.0843071\ttotal: 2.41s\tremaining: 24.3ms\n",
            "990:\tlearn: 0.0842548\ttotal: 2.41s\tremaining: 21.9ms\n",
            "991:\tlearn: 0.0841953\ttotal: 2.41s\tremaining: 19.4ms\n",
            "992:\tlearn: 0.0841634\ttotal: 2.41s\tremaining: 17ms\n",
            "993:\tlearn: 0.0841458\ttotal: 2.41s\tremaining: 14.6ms\n",
            "994:\tlearn: 0.0841142\ttotal: 2.42s\tremaining: 12.1ms\n",
            "995:\tlearn: 0.0840714\ttotal: 2.42s\tremaining: 9.71ms\n",
            "996:\tlearn: 0.0840397\ttotal: 2.42s\tremaining: 7.28ms\n",
            "997:\tlearn: 0.0840209\ttotal: 2.42s\tremaining: 4.86ms\n",
            "998:\tlearn: 0.0839768\ttotal: 2.42s\tremaining: 2.43ms\n",
            "999:\tlearn: 0.0839353\ttotal: 2.43s\tremaining: 0us\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<catboost.core.CatBoostClassifier at 0x7f036b428e10>"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preds = CAT.predict(x_test)"
      ],
      "metadata": {
        "id": "fxdeIlEUqvu1"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "report = pd.DataFrame(classification_report(y_test, preds, output_dict=True))\n",
        "report"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "132a15b0-e1f0-4b91-864c-17b0973a44a8",
        "id": "SEb2QwEvqvu2"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                    0          1  accuracy   macro avg  weighted avg\n",
              "precision    0.954128   0.250000  0.950456    0.602064      0.921079\n",
              "recall       0.995896   0.027778  0.950456    0.511837      0.950456\n",
              "f1-score     0.974565   0.050000  0.950456    0.512282      0.931169\n",
              "support    731.000000  36.000000  0.950456  767.000000    767.000000"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3ce3b1af-392b-4bd9-8c3e-d515c56fa97b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>macro avg</th>\n",
              "      <th>weighted avg</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>precision</th>\n",
              "      <td>0.954128</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>0.950456</td>\n",
              "      <td>0.602064</td>\n",
              "      <td>0.921079</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>recall</th>\n",
              "      <td>0.995896</td>\n",
              "      <td>0.027778</td>\n",
              "      <td>0.950456</td>\n",
              "      <td>0.511837</td>\n",
              "      <td>0.950456</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>f1-score</th>\n",
              "      <td>0.974565</td>\n",
              "      <td>0.050000</td>\n",
              "      <td>0.950456</td>\n",
              "      <td>0.512282</td>\n",
              "      <td>0.931169</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>support</th>\n",
              "      <td>731.000000</td>\n",
              "      <td>36.000000</td>\n",
              "      <td>0.950456</td>\n",
              "      <td>767.000000</td>\n",
              "      <td>767.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3ce3b1af-392b-4bd9-8c3e-d515c56fa97b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-3ce3b1af-392b-4bd9-8c3e-d515c56fa97b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-3ce3b1af-392b-4bd9-8c3e-d515c56fa97b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "thrsvalue=threshold(CAT)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "82c53136-ed46-4255-d1dc-737f1ae7710a",
        "id": "Y684av5-60jh"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---Optimum Threshold --- 0.2 --ROC-- 0.8836180927372143\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = CAT.predict_proba(x_test)"
      ],
      "metadata": {
        "id": "I4lvpE3V60ji"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = y_pred[:, 1]"
      ],
      "metadata": {
        "id": "kMxCU5_y60jj"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ans=[]"
      ],
      "metadata": {
        "id": "XsPMPde460jj"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(y_pred)):\n",
        "  if y_pred[i]>=thrsvalue:\n",
        "    ans.append(1)\n",
        "  else:\n",
        "    ans.append(0)"
      ],
      "metadata": {
        "id": "Deq6gKOH60jj"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "report = pd.DataFrame(classification_report(y_test, ans, output_dict=True))\n",
        "report"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "82cb1021-9d12-4ca6-94d0-adcef0d0032d",
        "id": "LjYaCM-u60jj"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                    0          1  accuracy   macro avg  weighted avg\n",
              "precision    0.962213   0.307692  0.940026    0.634953      0.931493\n",
              "recall       0.975376   0.222222  0.940026    0.598799      0.940026\n",
              "f1-score     0.968750   0.258065  0.940026    0.613407      0.935393\n",
              "support    731.000000  36.000000  0.940026  767.000000    767.000000"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4c28cf72-4c46-44bc-a443-6d2db13986f6\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>macro avg</th>\n",
              "      <th>weighted avg</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>precision</th>\n",
              "      <td>0.962213</td>\n",
              "      <td>0.307692</td>\n",
              "      <td>0.940026</td>\n",
              "      <td>0.634953</td>\n",
              "      <td>0.931493</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>recall</th>\n",
              "      <td>0.975376</td>\n",
              "      <td>0.222222</td>\n",
              "      <td>0.940026</td>\n",
              "      <td>0.598799</td>\n",
              "      <td>0.940026</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>f1-score</th>\n",
              "      <td>0.968750</td>\n",
              "      <td>0.258065</td>\n",
              "      <td>0.940026</td>\n",
              "      <td>0.613407</td>\n",
              "      <td>0.935393</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>support</th>\n",
              "      <td>731.000000</td>\n",
              "      <td>36.000000</td>\n",
              "      <td>0.940026</td>\n",
              "      <td>767.000000</td>\n",
              "      <td>767.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4c28cf72-4c46-44bc-a443-6d2db13986f6')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-4c28cf72-4c46-44bc-a443-6d2db13986f6 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-4c28cf72-4c46-44bc-a443-6d2db13986f6');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "XG.fit(x_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ad2339f7-f3cf-4e11-d2ac-eefe2955c5f9",
        "id": "gbKhaX7Yqwhi"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XGBClassifier()"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preds = XG.predict(x_test)"
      ],
      "metadata": {
        "id": "XMSBg33tqwhj"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "report = pd.DataFrame(classification_report(y_test, preds, output_dict=True))\n",
        "report"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "e375c536-f07c-42f3-b5e9-06013a89d363",
        "id": "9F-Xr5b6qwhj"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning:\n",
            "\n",
            "Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning:\n",
            "\n",
            "Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning:\n",
            "\n",
            "Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                    0     1  accuracy   macro avg  weighted avg\n",
              "precision    0.953064   0.0  0.953064    0.476532      0.908331\n",
              "recall       1.000000   0.0  0.953064    0.500000      0.953064\n",
              "f1-score     0.975968   0.0  0.953064    0.487984      0.930160\n",
              "support    731.000000  36.0  0.953064  767.000000    767.000000"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-98df342b-f131-4f8e-b84f-97b86dd62ecc\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>macro avg</th>\n",
              "      <th>weighted avg</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>precision</th>\n",
              "      <td>0.953064</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.953064</td>\n",
              "      <td>0.476532</td>\n",
              "      <td>0.908331</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>recall</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.953064</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.953064</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>f1-score</th>\n",
              "      <td>0.975968</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.953064</td>\n",
              "      <td>0.487984</td>\n",
              "      <td>0.930160</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>support</th>\n",
              "      <td>731.000000</td>\n",
              "      <td>36.0</td>\n",
              "      <td>0.953064</td>\n",
              "      <td>767.000000</td>\n",
              "      <td>767.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-98df342b-f131-4f8e-b84f-97b86dd62ecc')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-98df342b-f131-4f8e-b84f-97b86dd62ecc button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-98df342b-f131-4f8e-b84f-97b86dd62ecc');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "thrsvalue=threshold(XG,0.1,0.9)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d862a224-e2a4-488d-cba1-8e6879ad525b",
        "id": "KMgQ4okH7AWO"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---Optimum Threshold --- 0.2 --ROC-- 0.6880025918221192\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = XG.predict_proba(x_test)"
      ],
      "metadata": {
        "id": "-YiCv5-q7AWP"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = y_pred[:, 1]"
      ],
      "metadata": {
        "id": "Pvj15bWk7AWQ"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ans=[]"
      ],
      "metadata": {
        "id": "6wFwtJbt7AWQ"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(y_pred)):\n",
        "  if y_pred[i]>=thrsvalue:\n",
        "    ans.append(1)\n",
        "  else:\n",
        "    ans.append(0)"
      ],
      "metadata": {
        "id": "IsKiPdWO7AWQ"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "report = pd.DataFrame(classification_report(y_test, ans, output_dict=True))\n",
        "report"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "4c53a34a-638e-423b-e40f-a49ece350e53",
        "id": "vnb-pVmj7AWR"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                    0          1  accuracy   macro avg  weighted avg\n",
              "precision    0.962416   0.363636  0.945241    0.663026      0.934312\n",
              "recall       0.980848   0.222222  0.945241    0.601535      0.945241\n",
              "f1-score     0.971545   0.275862  0.945241    0.623703      0.938892\n",
              "support    731.000000  36.000000  0.945241  767.000000    767.000000"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-89e6fd83-f978-4e94-8183-7e3d8f01f8af\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>macro avg</th>\n",
              "      <th>weighted avg</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>precision</th>\n",
              "      <td>0.962416</td>\n",
              "      <td>0.363636</td>\n",
              "      <td>0.945241</td>\n",
              "      <td>0.663026</td>\n",
              "      <td>0.934312</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>recall</th>\n",
              "      <td>0.980848</td>\n",
              "      <td>0.222222</td>\n",
              "      <td>0.945241</td>\n",
              "      <td>0.601535</td>\n",
              "      <td>0.945241</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>f1-score</th>\n",
              "      <td>0.971545</td>\n",
              "      <td>0.275862</td>\n",
              "      <td>0.945241</td>\n",
              "      <td>0.623703</td>\n",
              "      <td>0.938892</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>support</th>\n",
              "      <td>731.000000</td>\n",
              "      <td>36.000000</td>\n",
              "      <td>0.945241</td>\n",
              "      <td>767.000000</td>\n",
              "      <td>767.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-89e6fd83-f978-4e94-8183-7e3d8f01f8af')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-89e6fd83-f978-4e94-8183-7e3d8f01f8af button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-89e6fd83-f978-4e94-8183-7e3d8f01f8af');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(XG.feature_importances_)\n",
        "# plot\n",
        "plt.bar(range(len(XG.feature_importances_)), XG.feature_importances_)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "SAvtozXQG6nU",
        "outputId": "d2a8f0ca-305c-490c-e072-6b063b588f07"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.06507859 0.03948203 0.10433896 0.06330757 0.08872642 0.3632443\n",
            " 0.07084225 0.1128995  0.09208034]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Undersampling\n"
      ],
      "metadata": {
        "id": "xKPbVb495EqZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "when minority class less than ~15-10% doing oversampling is pointless because minority portions is too low, and it considers as anomaly detection.\n",
        "If we apply smote for oversampling for this kind of problem, what happens is creating more samples but with lack of enough variance."
      ],
      "metadata": {
        "id": "2-3oZhLYBErG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset=[trainx,ytrain]\n",
        "df_train= pd.concat(dataset,axis=1)"
      ],
      "metadata": {
        "id": "adxGru9_j90i"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nonStroke = df_train[df_train['stroke'] == 0][0:220]\n",
        "Stroke = df_train[df_train['stroke'] == 1]"
      ],
      "metadata": {
        "id": "oxyYy9qtiRiD"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "newdf = pd.concat([nonStroke,Stroke],axis = 0)"
      ],
      "metadata": {
        "id": "NoWawygmjwAM"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "newdf"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "-zL5v1NGj0yf",
        "outputId": "e93894d6-a651-4e4c-b647-e19904c12b0b"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     gender  Residence_type  work_type  smoking_status  ever_married   age  \\\n",
              "249       1               0          4               0             0   3.0   \n",
              "250       1               1          2               2             1  58.0   \n",
              "251       0               1          2               0             0   8.0   \n",
              "252       0               0          2               1             1  70.0   \n",
              "253       1               0          1               0             0  14.0   \n",
              "..      ...             ...        ...             ...           ...   ...   \n",
              "244       1               0          2               0             1  57.0   \n",
              "245       0               0          4               0             0  14.0   \n",
              "246       0               0          3               1             1  75.0   \n",
              "247       1               0          3               0             1  71.0   \n",
              "248       0               0          2               0             1  78.0   \n",
              "\n",
              "     hypertension  heart_disease  avg_glucose_level  stroke  \n",
              "249             0              0              95.12       0  \n",
              "250             1              0              87.96       0  \n",
              "251             0              0             110.89       0  \n",
              "252             0              0              69.04       0  \n",
              "253             0              0             161.28       0  \n",
              "..            ...            ...                ...     ...  \n",
              "244             0              0              84.96       1  \n",
              "245             0              0              57.93       1  \n",
              "246             0              0              78.80       1  \n",
              "247             1              0              87.80       1  \n",
              "248             0              0              78.81       1  \n",
              "\n",
              "[469 rows x 10 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-20552eec-22c1-40a5-bad4-67b210cb5c7a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>gender</th>\n",
              "      <th>Residence_type</th>\n",
              "      <th>work_type</th>\n",
              "      <th>smoking_status</th>\n",
              "      <th>ever_married</th>\n",
              "      <th>age</th>\n",
              "      <th>hypertension</th>\n",
              "      <th>heart_disease</th>\n",
              "      <th>avg_glucose_level</th>\n",
              "      <th>stroke</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>249</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>95.12</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>250</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>58.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>87.96</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>251</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>110.89</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>252</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>70.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>69.04</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>253</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>161.28</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>244</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>57.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>84.96</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>245</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>57.93</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>246</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>75.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>78.80</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>247</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>71.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>87.80</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>248</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>78.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>78.81</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>469 rows × 10 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-20552eec-22c1-40a5-bad4-67b210cb5c7a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-20552eec-22c1-40a5-bad4-67b210cb5c7a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-20552eec-22c1-40a5-bad4-67b210cb5c7a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sns.countplot(x ='stroke', data = newdf)\n",
        "#data is balanced"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "id": "SV7fxzLdkCx_",
        "outputId": "ff67263d-2e62-4b4a-b378-5edc2ae82538"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f0369f696d0>"
            ]
          },
          "metadata": {},
          "execution_count": 74
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neural_network import MLPClassifier"
      ],
      "metadata": {
        "id": "c0K0GK_YkGN_"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Xtrain, Xtest, Ytrain, Ytest = train_test_split(newdf.iloc[:,:9], newdf['stroke'], stratify=newdf['stroke'],\n",
        "                                                    random_state=1,test_size=0.15)"
      ],
      "metadata": {
        "id": "Kt0oqsBxkSC3"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MLP = MLPClassifier(hidden_layer_sizes=(4,2),random_state=1, max_iter=3000).fit(Xtrain, Ytrain)"
      ],
      "metadata": {
        "id": "1gA3nEfekvjc"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Ypred=MLP.predict(Xtest)"
      ],
      "metadata": {
        "id": "5xy0SMOglAyE"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.DataFrame(classification_report(Ytest, Ypred, output_dict=True))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 174
        },
        "id": "ELeBhaxklIbQ",
        "outputId": "589ed997-817a-44f2-fd06-2af270f78a56"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                   0          1  accuracy  macro avg  weighted avg\n",
              "precision   0.724138   0.714286   0.71831   0.719212      0.718865\n",
              "recall      0.636364   0.789474   0.71831   0.712919      0.718310\n",
              "f1-score    0.677419   0.750000   0.71831   0.713710      0.716265\n",
              "support    33.000000  38.000000   0.71831  71.000000     71.000000"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-fdd4c77b-7c65-43fe-815a-7cf718c1168f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>macro avg</th>\n",
              "      <th>weighted avg</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>precision</th>\n",
              "      <td>0.724138</td>\n",
              "      <td>0.714286</td>\n",
              "      <td>0.71831</td>\n",
              "      <td>0.719212</td>\n",
              "      <td>0.718865</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>recall</th>\n",
              "      <td>0.636364</td>\n",
              "      <td>0.789474</td>\n",
              "      <td>0.71831</td>\n",
              "      <td>0.712919</td>\n",
              "      <td>0.718310</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>f1-score</th>\n",
              "      <td>0.677419</td>\n",
              "      <td>0.750000</td>\n",
              "      <td>0.71831</td>\n",
              "      <td>0.713710</td>\n",
              "      <td>0.716265</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>support</th>\n",
              "      <td>33.000000</td>\n",
              "      <td>38.000000</td>\n",
              "      <td>0.71831</td>\n",
              "      <td>71.000000</td>\n",
              "      <td>71.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fdd4c77b-7c65-43fe-815a-7cf718c1168f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-fdd4c77b-7c65-43fe-815a-7cf718c1168f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-fdd4c77b-7c65-43fe-815a-7cf718c1168f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from flaml import AutoML\n",
        "automl = AutoML()\n",
        "automl.fit(Xtrain, Ytrain, task=\"classification\",estimator_list=[ \"xgboost\", \"rf\",'extra_tree','lrl1'],time_budget=200)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gLkbDdnCljzc",
        "outputId": "2817cea2-8a14-4e20-fe44-94e6f5782bad"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[flaml.automl: 05-02 17:25:10] {2105} INFO - task = classification\n",
            "INFO:flaml.automl:task = classification\n",
            "[flaml.automl: 05-02 17:25:10] {2107} INFO - Data split method: stratified\n",
            "INFO:flaml.automl:Data split method: stratified\n",
            "[flaml.automl: 05-02 17:25:10] {2111} INFO - Evaluation method: cv\n",
            "INFO:flaml.automl:Evaluation method: cv\n",
            "[flaml.automl: 05-02 17:25:10] {2188} INFO - Minimizing error metric: 1-roc_auc\n",
            "INFO:flaml.automl:Minimizing error metric: 1-roc_auc\n",
            "[flaml.automl: 05-02 17:25:10] {2281} INFO - List of ML learners in AutoML Run: ['xgboost', 'rf', 'extra_tree', 'lrl1']\n",
            "INFO:flaml.automl:List of ML learners in AutoML Run: ['xgboost', 'rf', 'extra_tree', 'lrl1']\n",
            "[flaml.automl: 05-02 17:25:10] {2567} INFO - iteration 0, current learner xgboost\n",
            "INFO:flaml.automl:iteration 0, current learner xgboost\n",
            "[flaml.automl: 05-02 17:25:10] {2698} INFO - Estimated sufficient time budget=1162s. Estimated necessary time budget=12s.\n",
            "INFO:flaml.automl:Estimated sufficient time budget=1162s. Estimated necessary time budget=12s.\n",
            "[flaml.automl: 05-02 17:25:10] {2750} INFO -  at 0.2s,\testimator xgboost's best error=0.1905,\tbest estimator xgboost's best error=0.1905\n",
            "INFO:flaml.automl: at 0.2s,\testimator xgboost's best error=0.1905,\tbest estimator xgboost's best error=0.1905\n",
            "[flaml.automl: 05-02 17:25:10] {2567} INFO - iteration 1, current learner xgboost\n",
            "INFO:flaml.automl:iteration 1, current learner xgboost\n",
            "[flaml.automl: 05-02 17:25:11] {2750} INFO -  at 0.3s,\testimator xgboost's best error=0.1858,\tbest estimator xgboost's best error=0.1858\n",
            "INFO:flaml.automl: at 0.3s,\testimator xgboost's best error=0.1858,\tbest estimator xgboost's best error=0.1858\n",
            "[flaml.automl: 05-02 17:25:11] {2567} INFO - iteration 2, current learner xgboost\n",
            "INFO:flaml.automl:iteration 2, current learner xgboost\n",
            "[flaml.automl: 05-02 17:25:11] {2750} INFO -  at 0.3s,\testimator xgboost's best error=0.1830,\tbest estimator xgboost's best error=0.1830\n",
            "INFO:flaml.automl: at 0.3s,\testimator xgboost's best error=0.1830,\tbest estimator xgboost's best error=0.1830\n",
            "[flaml.automl: 05-02 17:25:11] {2567} INFO - iteration 3, current learner xgboost\n",
            "INFO:flaml.automl:iteration 3, current learner xgboost\n",
            "[flaml.automl: 05-02 17:25:11] {2750} INFO -  at 0.4s,\testimator xgboost's best error=0.1830,\tbest estimator xgboost's best error=0.1830\n",
            "INFO:flaml.automl: at 0.4s,\testimator xgboost's best error=0.1830,\tbest estimator xgboost's best error=0.1830\n",
            "[flaml.automl: 05-02 17:25:11] {2567} INFO - iteration 4, current learner xgboost\n",
            "INFO:flaml.automl:iteration 4, current learner xgboost\n",
            "[flaml.automl: 05-02 17:25:11] {2750} INFO -  at 0.4s,\testimator xgboost's best error=0.1830,\tbest estimator xgboost's best error=0.1830\n",
            "INFO:flaml.automl: at 0.4s,\testimator xgboost's best error=0.1830,\tbest estimator xgboost's best error=0.1830\n",
            "[flaml.automl: 05-02 17:25:11] {2567} INFO - iteration 5, current learner xgboost\n",
            "INFO:flaml.automl:iteration 5, current learner xgboost\n",
            "[flaml.automl: 05-02 17:25:11] {2750} INFO -  at 0.5s,\testimator xgboost's best error=0.1830,\tbest estimator xgboost's best error=0.1830\n",
            "INFO:flaml.automl: at 0.5s,\testimator xgboost's best error=0.1830,\tbest estimator xgboost's best error=0.1830\n",
            "[flaml.automl: 05-02 17:25:11] {2567} INFO - iteration 6, current learner extra_tree\n",
            "INFO:flaml.automl:iteration 6, current learner extra_tree\n",
            "[flaml.automl: 05-02 17:25:12] {2750} INFO -  at 1.7s,\testimator extra_tree's best error=0.2076,\tbest estimator xgboost's best error=0.1830\n",
            "INFO:flaml.automl: at 1.7s,\testimator extra_tree's best error=0.2076,\tbest estimator xgboost's best error=0.1830\n",
            "[flaml.automl: 05-02 17:25:12] {2567} INFO - iteration 7, current learner rf\n",
            "INFO:flaml.automl:iteration 7, current learner rf\n",
            "[flaml.automl: 05-02 17:25:13] {2750} INFO -  at 2.9s,\testimator rf's best error=0.2257,\tbest estimator xgboost's best error=0.1830\n",
            "INFO:flaml.automl: at 2.9s,\testimator rf's best error=0.2257,\tbest estimator xgboost's best error=0.1830\n",
            "[flaml.automl: 05-02 17:25:13] {2567} INFO - iteration 8, current learner xgboost\n",
            "INFO:flaml.automl:iteration 8, current learner xgboost\n",
            "[flaml.automl: 05-02 17:25:13] {2750} INFO -  at 3.1s,\testimator xgboost's best error=0.1830,\tbest estimator xgboost's best error=0.1830\n",
            "INFO:flaml.automl: at 3.1s,\testimator xgboost's best error=0.1830,\tbest estimator xgboost's best error=0.1830\n",
            "[flaml.automl: 05-02 17:25:13] {2567} INFO - iteration 9, current learner xgboost\n",
            "INFO:flaml.automl:iteration 9, current learner xgboost\n",
            "[flaml.automl: 05-02 17:25:14] {2750} INFO -  at 3.2s,\testimator xgboost's best error=0.1830,\tbest estimator xgboost's best error=0.1830\n",
            "INFO:flaml.automl: at 3.2s,\testimator xgboost's best error=0.1830,\tbest estimator xgboost's best error=0.1830\n",
            "[flaml.automl: 05-02 17:25:14] {2567} INFO - iteration 10, current learner xgboost\n",
            "INFO:flaml.automl:iteration 10, current learner xgboost\n",
            "[flaml.automl: 05-02 17:25:14] {2750} INFO -  at 3.3s,\testimator xgboost's best error=0.1830,\tbest estimator xgboost's best error=0.1830\n",
            "INFO:flaml.automl: at 3.3s,\testimator xgboost's best error=0.1830,\tbest estimator xgboost's best error=0.1830\n",
            "[flaml.automl: 05-02 17:25:14] {2567} INFO - iteration 11, current learner xgboost\n",
            "INFO:flaml.automl:iteration 11, current learner xgboost\n",
            "[flaml.automl: 05-02 17:25:14] {2750} INFO -  at 3.4s,\testimator xgboost's best error=0.1830,\tbest estimator xgboost's best error=0.1830\n",
            "INFO:flaml.automl: at 3.4s,\testimator xgboost's best error=0.1830,\tbest estimator xgboost's best error=0.1830\n",
            "[flaml.automl: 05-02 17:25:14] {2567} INFO - iteration 12, current learner rf\n",
            "INFO:flaml.automl:iteration 12, current learner rf\n",
            "[flaml.automl: 05-02 17:25:14] {2750} INFO -  at 3.5s,\testimator rf's best error=0.2074,\tbest estimator xgboost's best error=0.1830\n",
            "INFO:flaml.automl: at 3.5s,\testimator rf's best error=0.2074,\tbest estimator xgboost's best error=0.1830\n",
            "[flaml.automl: 05-02 17:25:14] {2567} INFO - iteration 13, current learner rf\n",
            "INFO:flaml.automl:iteration 13, current learner rf\n",
            "[flaml.automl: 05-02 17:25:14] {2750} INFO -  at 3.6s,\testimator rf's best error=0.2074,\tbest estimator xgboost's best error=0.1830\n",
            "INFO:flaml.automl: at 3.6s,\testimator rf's best error=0.2074,\tbest estimator xgboost's best error=0.1830\n",
            "[flaml.automl: 05-02 17:25:14] {2567} INFO - iteration 14, current learner rf\n",
            "INFO:flaml.automl:iteration 14, current learner rf\n",
            "[flaml.automl: 05-02 17:25:15] {2750} INFO -  at 5.1s,\testimator rf's best error=0.2041,\tbest estimator xgboost's best error=0.1830\n",
            "INFO:flaml.automl: at 5.1s,\testimator rf's best error=0.2041,\tbest estimator xgboost's best error=0.1830\n",
            "[flaml.automl: 05-02 17:25:15] {2567} INFO - iteration 15, current learner xgboost\n",
            "INFO:flaml.automl:iteration 15, current learner xgboost\n",
            "[flaml.automl: 05-02 17:25:15] {2750} INFO -  at 5.2s,\testimator xgboost's best error=0.1790,\tbest estimator xgboost's best error=0.1790\n",
            "INFO:flaml.automl: at 5.2s,\testimator xgboost's best error=0.1790,\tbest estimator xgboost's best error=0.1790\n",
            "[flaml.automl: 05-02 17:25:15] {2567} INFO - iteration 16, current learner extra_tree\n",
            "INFO:flaml.automl:iteration 16, current learner extra_tree\n",
            "[flaml.automl: 05-02 17:25:17] {2750} INFO -  at 6.5s,\testimator extra_tree's best error=0.2076,\tbest estimator xgboost's best error=0.1790\n",
            "INFO:flaml.automl: at 6.5s,\testimator extra_tree's best error=0.2076,\tbest estimator xgboost's best error=0.1790\n",
            "[flaml.automl: 05-02 17:25:17] {2567} INFO - iteration 17, current learner xgboost\n",
            "INFO:flaml.automl:iteration 17, current learner xgboost\n",
            "[flaml.automl: 05-02 17:25:17] {2750} INFO -  at 6.6s,\testimator xgboost's best error=0.1790,\tbest estimator xgboost's best error=0.1790\n",
            "INFO:flaml.automl: at 6.6s,\testimator xgboost's best error=0.1790,\tbest estimator xgboost's best error=0.1790\n",
            "[flaml.automl: 05-02 17:25:17] {2567} INFO - iteration 18, current learner rf\n",
            "INFO:flaml.automl:iteration 18, current learner rf\n",
            "[flaml.automl: 05-02 17:25:18] {2750} INFO -  at 8.1s,\testimator rf's best error=0.2041,\tbest estimator xgboost's best error=0.1790\n",
            "INFO:flaml.automl: at 8.1s,\testimator rf's best error=0.2041,\tbest estimator xgboost's best error=0.1790\n",
            "[flaml.automl: 05-02 17:25:18] {2567} INFO - iteration 19, current learner xgboost\n",
            "INFO:flaml.automl:iteration 19, current learner xgboost\n",
            "[flaml.automl: 05-02 17:25:19] {2750} INFO -  at 8.2s,\testimator xgboost's best error=0.1790,\tbest estimator xgboost's best error=0.1790\n",
            "INFO:flaml.automl: at 8.2s,\testimator xgboost's best error=0.1790,\tbest estimator xgboost's best error=0.1790\n",
            "[flaml.automl: 05-02 17:25:19] {2567} INFO - iteration 20, current learner xgboost\n",
            "INFO:flaml.automl:iteration 20, current learner xgboost\n",
            "[flaml.automl: 05-02 17:25:19] {2750} INFO -  at 8.3s,\testimator xgboost's best error=0.1790,\tbest estimator xgboost's best error=0.1790\n",
            "INFO:flaml.automl: at 8.3s,\testimator xgboost's best error=0.1790,\tbest estimator xgboost's best error=0.1790\n",
            "[flaml.automl: 05-02 17:25:19] {2567} INFO - iteration 21, current learner xgboost\n",
            "INFO:flaml.automl:iteration 21, current learner xgboost\n",
            "[flaml.automl: 05-02 17:25:19] {2750} INFO -  at 8.5s,\testimator xgboost's best error=0.1790,\tbest estimator xgboost's best error=0.1790\n",
            "INFO:flaml.automl: at 8.5s,\testimator xgboost's best error=0.1790,\tbest estimator xgboost's best error=0.1790\n",
            "[flaml.automl: 05-02 17:25:19] {2567} INFO - iteration 22, current learner xgboost\n",
            "INFO:flaml.automl:iteration 22, current learner xgboost\n",
            "[flaml.automl: 05-02 17:25:19] {2750} INFO -  at 8.5s,\testimator xgboost's best error=0.1790,\tbest estimator xgboost's best error=0.1790\n",
            "INFO:flaml.automl: at 8.5s,\testimator xgboost's best error=0.1790,\tbest estimator xgboost's best error=0.1790\n",
            "[flaml.automl: 05-02 17:25:19] {2567} INFO - iteration 23, current learner extra_tree\n",
            "INFO:flaml.automl:iteration 23, current learner extra_tree\n",
            "[flaml.automl: 05-02 17:25:20] {2750} INFO -  at 9.8s,\testimator extra_tree's best error=0.2076,\tbest estimator xgboost's best error=0.1790\n",
            "INFO:flaml.automl: at 9.8s,\testimator extra_tree's best error=0.2076,\tbest estimator xgboost's best error=0.1790\n",
            "[flaml.automl: 05-02 17:25:20] {2567} INFO - iteration 24, current learner extra_tree\n",
            "INFO:flaml.automl:iteration 24, current learner extra_tree\n",
            "[flaml.automl: 05-02 17:25:22] {2750} INFO -  at 11.3s,\testimator extra_tree's best error=0.2076,\tbest estimator xgboost's best error=0.1790\n",
            "INFO:flaml.automl: at 11.3s,\testimator extra_tree's best error=0.2076,\tbest estimator xgboost's best error=0.1790\n",
            "[flaml.automl: 05-02 17:25:22] {2567} INFO - iteration 25, current learner xgboost\n",
            "INFO:flaml.automl:iteration 25, current learner xgboost\n",
            "[flaml.automl: 05-02 17:25:22] {2750} INFO -  at 11.4s,\testimator xgboost's best error=0.1790,\tbest estimator xgboost's best error=0.1790\n",
            "INFO:flaml.automl: at 11.4s,\testimator xgboost's best error=0.1790,\tbest estimator xgboost's best error=0.1790\n",
            "[flaml.automl: 05-02 17:25:22] {2567} INFO - iteration 26, current learner xgboost\n",
            "INFO:flaml.automl:iteration 26, current learner xgboost\n",
            "[flaml.automl: 05-02 17:25:22] {2750} INFO -  at 11.5s,\testimator xgboost's best error=0.1790,\tbest estimator xgboost's best error=0.1790\n",
            "INFO:flaml.automl: at 11.5s,\testimator xgboost's best error=0.1790,\tbest estimator xgboost's best error=0.1790\n",
            "[flaml.automl: 05-02 17:25:22] {2567} INFO - iteration 27, current learner extra_tree\n",
            "INFO:flaml.automl:iteration 27, current learner extra_tree\n",
            "[flaml.automl: 05-02 17:25:23] {2750} INFO -  at 12.9s,\testimator extra_tree's best error=0.2076,\tbest estimator xgboost's best error=0.1790\n",
            "INFO:flaml.automl: at 12.9s,\testimator extra_tree's best error=0.2076,\tbest estimator xgboost's best error=0.1790\n",
            "[flaml.automl: 05-02 17:25:23] {2567} INFO - iteration 28, current learner extra_tree\n",
            "INFO:flaml.automl:iteration 28, current learner extra_tree\n",
            "[flaml.automl: 05-02 17:25:25] {2750} INFO -  at 14.5s,\testimator extra_tree's best error=0.2076,\tbest estimator xgboost's best error=0.1790\n",
            "INFO:flaml.automl: at 14.5s,\testimator extra_tree's best error=0.2076,\tbest estimator xgboost's best error=0.1790\n",
            "[flaml.automl: 05-02 17:25:25] {2567} INFO - iteration 29, current learner xgboost\n",
            "INFO:flaml.automl:iteration 29, current learner xgboost\n",
            "[flaml.automl: 05-02 17:25:25] {2750} INFO -  at 14.7s,\testimator xgboost's best error=0.1790,\tbest estimator xgboost's best error=0.1790\n",
            "INFO:flaml.automl: at 14.7s,\testimator xgboost's best error=0.1790,\tbest estimator xgboost's best error=0.1790\n",
            "[flaml.automl: 05-02 17:25:25] {2567} INFO - iteration 30, current learner xgboost\n",
            "INFO:flaml.automl:iteration 30, current learner xgboost\n",
            "[flaml.automl: 05-02 17:25:25] {2750} INFO -  at 14.8s,\testimator xgboost's best error=0.1790,\tbest estimator xgboost's best error=0.1790\n",
            "INFO:flaml.automl: at 14.8s,\testimator xgboost's best error=0.1790,\tbest estimator xgboost's best error=0.1790\n",
            "[flaml.automl: 05-02 17:25:25] {2567} INFO - iteration 31, current learner xgboost\n",
            "INFO:flaml.automl:iteration 31, current learner xgboost\n",
            "[flaml.automl: 05-02 17:25:25] {2750} INFO -  at 14.9s,\testimator xgboost's best error=0.1790,\tbest estimator xgboost's best error=0.1790\n",
            "INFO:flaml.automl: at 14.9s,\testimator xgboost's best error=0.1790,\tbest estimator xgboost's best error=0.1790\n",
            "[flaml.automl: 05-02 17:25:25] {2567} INFO - iteration 32, current learner extra_tree\n",
            "INFO:flaml.automl:iteration 32, current learner extra_tree\n",
            "[flaml.automl: 05-02 17:25:27] {2750} INFO -  at 16.4s,\testimator extra_tree's best error=0.2076,\tbest estimator xgboost's best error=0.1790\n",
            "INFO:flaml.automl: at 16.4s,\testimator extra_tree's best error=0.2076,\tbest estimator xgboost's best error=0.1790\n",
            "[flaml.automl: 05-02 17:25:27] {2567} INFO - iteration 33, current learner xgboost\n",
            "INFO:flaml.automl:iteration 33, current learner xgboost\n",
            "[flaml.automl: 05-02 17:25:27] {2750} INFO -  at 16.5s,\testimator xgboost's best error=0.1790,\tbest estimator xgboost's best error=0.1790\n",
            "INFO:flaml.automl: at 16.5s,\testimator xgboost's best error=0.1790,\tbest estimator xgboost's best error=0.1790\n",
            "[flaml.automl: 05-02 17:25:27] {2567} INFO - iteration 34, current learner xgboost\n",
            "INFO:flaml.automl:iteration 34, current learner xgboost\n",
            "[flaml.automl: 05-02 17:25:27] {2750} INFO -  at 16.6s,\testimator xgboost's best error=0.1790,\tbest estimator xgboost's best error=0.1790\n",
            "INFO:flaml.automl: at 16.6s,\testimator xgboost's best error=0.1790,\tbest estimator xgboost's best error=0.1790\n",
            "[flaml.automl: 05-02 17:25:27] {2567} INFO - iteration 35, current learner extra_tree\n",
            "INFO:flaml.automl:iteration 35, current learner extra_tree\n",
            "[flaml.automl: 05-02 17:25:29] {2750} INFO -  at 18.3s,\testimator extra_tree's best error=0.2076,\tbest estimator xgboost's best error=0.1790\n",
            "INFO:flaml.automl: at 18.3s,\testimator extra_tree's best error=0.2076,\tbest estimator xgboost's best error=0.1790\n",
            "[flaml.automl: 05-02 17:25:29] {2567} INFO - iteration 36, current learner xgboost\n",
            "INFO:flaml.automl:iteration 36, current learner xgboost\n",
            "[flaml.automl: 05-02 17:25:29] {2750} INFO -  at 18.5s,\testimator xgboost's best error=0.1790,\tbest estimator xgboost's best error=0.1790\n",
            "INFO:flaml.automl: at 18.5s,\testimator xgboost's best error=0.1790,\tbest estimator xgboost's best error=0.1790\n",
            "[flaml.automl: 05-02 17:25:29] {2567} INFO - iteration 37, current learner xgboost\n",
            "INFO:flaml.automl:iteration 37, current learner xgboost\n",
            "[flaml.automl: 05-02 17:25:29] {2750} INFO -  at 18.7s,\testimator xgboost's best error=0.1790,\tbest estimator xgboost's best error=0.1790\n",
            "INFO:flaml.automl: at 18.7s,\testimator xgboost's best error=0.1790,\tbest estimator xgboost's best error=0.1790\n",
            "[flaml.automl: 05-02 17:25:29] {2567} INFO - iteration 38, current learner xgboost\n",
            "INFO:flaml.automl:iteration 38, current learner xgboost\n",
            "[flaml.automl: 05-02 17:25:29] {2750} INFO -  at 18.8s,\testimator xgboost's best error=0.1790,\tbest estimator xgboost's best error=0.1790\n",
            "INFO:flaml.automl: at 18.8s,\testimator xgboost's best error=0.1790,\tbest estimator xgboost's best error=0.1790\n",
            "[flaml.automl: 05-02 17:25:29] {2567} INFO - iteration 39, current learner xgboost\n",
            "INFO:flaml.automl:iteration 39, current learner xgboost\n",
            "[flaml.automl: 05-02 17:25:29] {2750} INFO -  at 19.0s,\testimator xgboost's best error=0.1790,\tbest estimator xgboost's best error=0.1790\n",
            "INFO:flaml.automl: at 19.0s,\testimator xgboost's best error=0.1790,\tbest estimator xgboost's best error=0.1790\n",
            "[flaml.automl: 05-02 17:25:29] {2567} INFO - iteration 40, current learner rf\n",
            "INFO:flaml.automl:iteration 40, current learner rf\n",
            "[flaml.automl: 05-02 17:25:31] {2750} INFO -  at 20.5s,\testimator rf's best error=0.2041,\tbest estimator xgboost's best error=0.1790\n",
            "INFO:flaml.automl: at 20.5s,\testimator rf's best error=0.2041,\tbest estimator xgboost's best error=0.1790\n",
            "[flaml.automl: 05-02 17:25:31] {2567} INFO - iteration 41, current learner xgboost\n",
            "INFO:flaml.automl:iteration 41, current learner xgboost\n",
            "[flaml.automl: 05-02 17:25:31] {2750} INFO -  at 20.6s,\testimator xgboost's best error=0.1790,\tbest estimator xgboost's best error=0.1790\n",
            "INFO:flaml.automl: at 20.6s,\testimator xgboost's best error=0.1790,\tbest estimator xgboost's best error=0.1790\n",
            "[flaml.automl: 05-02 17:25:31] {2567} INFO - iteration 42, current learner xgboost\n",
            "INFO:flaml.automl:iteration 42, current learner xgboost\n",
            "[flaml.automl: 05-02 17:25:31] {2750} INFO -  at 20.7s,\testimator xgboost's best error=0.1790,\tbest estimator xgboost's best error=0.1790\n",
            "INFO:flaml.automl: at 20.7s,\testimator xgboost's best error=0.1790,\tbest estimator xgboost's best error=0.1790\n",
            "[flaml.automl: 05-02 17:25:31] {2567} INFO - iteration 43, current learner extra_tree\n",
            "INFO:flaml.automl:iteration 43, current learner extra_tree\n",
            "[flaml.automl: 05-02 17:25:33] {2750} INFO -  at 22.2s,\testimator extra_tree's best error=0.2076,\tbest estimator xgboost's best error=0.1790\n",
            "INFO:flaml.automl: at 22.2s,\testimator extra_tree's best error=0.2076,\tbest estimator xgboost's best error=0.1790\n",
            "[flaml.automl: 05-02 17:25:33] {2567} INFO - iteration 44, current learner xgboost\n",
            "INFO:flaml.automl:iteration 44, current learner xgboost\n",
            "[flaml.automl: 05-02 17:25:33] {2750} INFO -  at 22.4s,\testimator xgboost's best error=0.1790,\tbest estimator xgboost's best error=0.1790\n",
            "INFO:flaml.automl: at 22.4s,\testimator xgboost's best error=0.1790,\tbest estimator xgboost's best error=0.1790\n",
            "[flaml.automl: 05-02 17:25:33] {2567} INFO - iteration 45, current learner xgboost\n",
            "INFO:flaml.automl:iteration 45, current learner xgboost\n",
            "[flaml.automl: 05-02 17:25:33] {2750} INFO -  at 22.5s,\testimator xgboost's best error=0.1790,\tbest estimator xgboost's best error=0.1790\n",
            "INFO:flaml.automl: at 22.5s,\testimator xgboost's best error=0.1790,\tbest estimator xgboost's best error=0.1790\n",
            "[flaml.automl: 05-02 17:25:33] {2567} INFO - iteration 46, current learner xgboost\n",
            "INFO:flaml.automl:iteration 46, current learner xgboost\n",
            "[flaml.automl: 05-02 17:25:33] {2750} INFO -  at 22.6s,\testimator xgboost's best error=0.1790,\tbest estimator xgboost's best error=0.1790\n",
            "INFO:flaml.automl: at 22.6s,\testimator xgboost's best error=0.1790,\tbest estimator xgboost's best error=0.1790\n",
            "[flaml.automl: 05-02 17:25:33] {2567} INFO - iteration 47, current learner xgboost\n",
            "INFO:flaml.automl:iteration 47, current learner xgboost\n",
            "[flaml.automl: 05-02 17:25:33] {2750} INFO -  at 22.7s,\testimator xgboost's best error=0.1790,\tbest estimator xgboost's best error=0.1790\n",
            "INFO:flaml.automl: at 22.7s,\testimator xgboost's best error=0.1790,\tbest estimator xgboost's best error=0.1790\n",
            "[flaml.automl: 05-02 17:25:33] {2567} INFO - iteration 48, current learner xgboost\n",
            "INFO:flaml.automl:iteration 48, current learner xgboost\n",
            "[flaml.automl: 05-02 17:25:33] {2750} INFO -  at 22.8s,\testimator xgboost's best error=0.1790,\tbest estimator xgboost's best error=0.1790\n",
            "INFO:flaml.automl: at 22.8s,\testimator xgboost's best error=0.1790,\tbest estimator xgboost's best error=0.1790\n",
            "[flaml.automl: 05-02 17:25:33] {2567} INFO - iteration 49, current learner extra_tree\n",
            "INFO:flaml.automl:iteration 49, current learner extra_tree\n",
            "[flaml.automl: 05-02 17:25:34] {2750} INFO -  at 24.1s,\testimator extra_tree's best error=0.2076,\tbest estimator xgboost's best error=0.1790\n",
            "INFO:flaml.automl: at 24.1s,\testimator extra_tree's best error=0.2076,\tbest estimator xgboost's best error=0.1790\n",
            "[flaml.automl: 05-02 17:25:34] {2567} INFO - iteration 50, current learner xgboost\n",
            "INFO:flaml.automl:iteration 50, current learner xgboost\n",
            "[flaml.automl: 05-02 17:25:35] {2750} INFO -  at 24.3s,\testimator xgboost's best error=0.1790,\tbest estimator xgboost's best error=0.1790\n",
            "INFO:flaml.automl: at 24.3s,\testimator xgboost's best error=0.1790,\tbest estimator xgboost's best error=0.1790\n",
            "[flaml.automl: 05-02 17:25:35] {2567} INFO - iteration 51, current learner xgboost\n",
            "INFO:flaml.automl:iteration 51, current learner xgboost\n",
            "[flaml.automl: 05-02 17:25:35] {2750} INFO -  at 24.5s,\testimator xgboost's best error=0.1790,\tbest estimator xgboost's best error=0.1790\n",
            "INFO:flaml.automl: at 24.5s,\testimator xgboost's best error=0.1790,\tbest estimator xgboost's best error=0.1790\n",
            "[flaml.automl: 05-02 17:25:35] {2567} INFO - iteration 52, current learner xgboost\n",
            "INFO:flaml.automl:iteration 52, current learner xgboost\n",
            "[flaml.automl: 05-02 17:25:35] {2750} INFO -  at 24.6s,\testimator xgboost's best error=0.1790,\tbest estimator xgboost's best error=0.1790\n",
            "INFO:flaml.automl: at 24.6s,\testimator xgboost's best error=0.1790,\tbest estimator xgboost's best error=0.1790\n",
            "[flaml.automl: 05-02 17:25:35] {2567} INFO - iteration 53, current learner xgboost\n",
            "INFO:flaml.automl:iteration 53, current learner xgboost\n",
            "[flaml.automl: 05-02 17:25:35] {2750} INFO -  at 24.7s,\testimator xgboost's best error=0.1790,\tbest estimator xgboost's best error=0.1790\n",
            "INFO:flaml.automl: at 24.7s,\testimator xgboost's best error=0.1790,\tbest estimator xgboost's best error=0.1790\n",
            "[flaml.automl: 05-02 17:25:35] {2567} INFO - iteration 54, current learner xgboost\n",
            "INFO:flaml.automl:iteration 54, current learner xgboost\n",
            "[flaml.automl: 05-02 17:25:35] {2750} INFO -  at 24.8s,\testimator xgboost's best error=0.1790,\tbest estimator xgboost's best error=0.1790\n",
            "INFO:flaml.automl: at 24.8s,\testimator xgboost's best error=0.1790,\tbest estimator xgboost's best error=0.1790\n",
            "[flaml.automl: 05-02 17:25:35] {2567} INFO - iteration 55, current learner xgboost\n",
            "INFO:flaml.automl:iteration 55, current learner xgboost\n",
            "[flaml.automl: 05-02 17:25:35] {2750} INFO -  at 24.9s,\testimator xgboost's best error=0.1790,\tbest estimator xgboost's best error=0.1790\n",
            "INFO:flaml.automl: at 24.9s,\testimator xgboost's best error=0.1790,\tbest estimator xgboost's best error=0.1790\n",
            "[flaml.automl: 05-02 17:25:35] {2567} INFO - iteration 56, current learner xgboost\n",
            "INFO:flaml.automl:iteration 56, current learner xgboost\n",
            "[flaml.automl: 05-02 17:25:35] {2750} INFO -  at 25.0s,\testimator xgboost's best error=0.1790,\tbest estimator xgboost's best error=0.1790\n",
            "INFO:flaml.automl: at 25.0s,\testimator xgboost's best error=0.1790,\tbest estimator xgboost's best error=0.1790\n",
            "[flaml.automl: 05-02 17:25:35] {2567} INFO - iteration 57, current learner xgboost\n",
            "INFO:flaml.automl:iteration 57, current learner xgboost\n",
            "[flaml.automl: 05-02 17:25:35] {2750} INFO -  at 25.1s,\testimator xgboost's best error=0.1790,\tbest estimator xgboost's best error=0.1790\n",
            "INFO:flaml.automl: at 25.1s,\testimator xgboost's best error=0.1790,\tbest estimator xgboost's best error=0.1790\n",
            "[flaml.automl: 05-02 17:25:35] {2567} INFO - iteration 58, current learner xgboost\n",
            "INFO:flaml.automl:iteration 58, current learner xgboost\n",
            "[flaml.automl: 05-02 17:25:36] {2750} INFO -  at 25.3s,\testimator xgboost's best error=0.1790,\tbest estimator xgboost's best error=0.1790\n",
            "INFO:flaml.automl: at 25.3s,\testimator xgboost's best error=0.1790,\tbest estimator xgboost's best error=0.1790\n",
            "[flaml.automl: 05-02 17:25:36] {2567} INFO - iteration 59, current learner xgboost\n",
            "INFO:flaml.automl:iteration 59, current learner xgboost\n",
            "[flaml.automl: 05-02 17:25:36] {2750} INFO -  at 25.4s,\testimator xgboost's best error=0.1790,\tbest estimator xgboost's best error=0.1790\n",
            "INFO:flaml.automl: at 25.4s,\testimator xgboost's best error=0.1790,\tbest estimator xgboost's best error=0.1790\n",
            "[flaml.automl: 05-02 17:25:36] {2567} INFO - iteration 60, current learner xgboost\n",
            "INFO:flaml.automl:iteration 60, current learner xgboost\n",
            "[flaml.automl: 05-02 17:25:36] {2750} INFO -  at 25.5s,\testimator xgboost's best error=0.1790,\tbest estimator xgboost's best error=0.1790\n",
            "INFO:flaml.automl: at 25.5s,\testimator xgboost's best error=0.1790,\tbest estimator xgboost's best error=0.1790\n",
            "[flaml.automl: 05-02 17:25:36] {2567} INFO - iteration 61, current learner xgboost\n",
            "INFO:flaml.automl:iteration 61, current learner xgboost\n",
            "[flaml.automl: 05-02 17:25:36] {2750} INFO -  at 25.8s,\testimator xgboost's best error=0.1790,\tbest estimator xgboost's best error=0.1790\n",
            "INFO:flaml.automl: at 25.8s,\testimator xgboost's best error=0.1790,\tbest estimator xgboost's best error=0.1790\n",
            "[flaml.automl: 05-02 17:25:36] {2567} INFO - iteration 62, current learner xgboost\n",
            "INFO:flaml.automl:iteration 62, current learner xgboost\n",
            "[flaml.automl: 05-02 17:25:36] {2750} INFO -  at 26.0s,\testimator xgboost's best error=0.1790,\tbest estimator xgboost's best error=0.1790\n",
            "INFO:flaml.automl: at 26.0s,\testimator xgboost's best error=0.1790,\tbest estimator xgboost's best error=0.1790\n",
            "[flaml.automl: 05-02 17:25:36] {2567} INFO - iteration 63, current learner xgboost\n",
            "INFO:flaml.automl:iteration 63, current learner xgboost\n",
            "[flaml.automl: 05-02 17:25:36] {2750} INFO -  at 26.1s,\testimator xgboost's best error=0.1790,\tbest estimator xgboost's best error=0.1790\n",
            "INFO:flaml.automl: at 26.1s,\testimator xgboost's best error=0.1790,\tbest estimator xgboost's best error=0.1790\n",
            "[flaml.automl: 05-02 17:25:36] {2567} INFO - iteration 64, current learner xgboost\n",
            "INFO:flaml.automl:iteration 64, current learner xgboost\n",
            "[flaml.automl: 05-02 17:25:36] {2750} INFO -  at 26.2s,\testimator xgboost's best error=0.1790,\tbest estimator xgboost's best error=0.1790\n",
            "INFO:flaml.automl: at 26.2s,\testimator xgboost's best error=0.1790,\tbest estimator xgboost's best error=0.1790\n",
            "[flaml.automl: 05-02 17:25:36] {2567} INFO - iteration 65, current learner xgboost\n",
            "INFO:flaml.automl:iteration 65, current learner xgboost\n",
            "[flaml.automl: 05-02 17:25:37] {2750} INFO -  at 26.3s,\testimator xgboost's best error=0.1790,\tbest estimator xgboost's best error=0.1790\n",
            "INFO:flaml.automl: at 26.3s,\testimator xgboost's best error=0.1790,\tbest estimator xgboost's best error=0.1790\n",
            "[flaml.automl: 05-02 17:25:37] {2567} INFO - iteration 66, current learner xgboost\n",
            "INFO:flaml.automl:iteration 66, current learner xgboost\n",
            "[flaml.automl: 05-02 17:25:37] {2750} INFO -  at 26.4s,\testimator xgboost's best error=0.1790,\tbest estimator xgboost's best error=0.1790\n",
            "INFO:flaml.automl: at 26.4s,\testimator xgboost's best error=0.1790,\tbest estimator xgboost's best error=0.1790\n",
            "[flaml.automl: 05-02 17:25:37] {2567} INFO - iteration 67, current learner xgboost\n",
            "INFO:flaml.automl:iteration 67, current learner xgboost\n",
            "[flaml.automl: 05-02 17:25:37] {2750} INFO -  at 26.5s,\testimator xgboost's best error=0.1790,\tbest estimator xgboost's best error=0.1790\n",
            "INFO:flaml.automl: at 26.5s,\testimator xgboost's best error=0.1790,\tbest estimator xgboost's best error=0.1790\n",
            "[flaml.automl: 05-02 17:25:37] {2567} INFO - iteration 68, current learner xgboost\n",
            "INFO:flaml.automl:iteration 68, current learner xgboost\n",
            "[flaml.automl: 05-02 17:25:37] {2750} INFO -  at 26.6s,\testimator xgboost's best error=0.1790,\tbest estimator xgboost's best error=0.1790\n",
            "INFO:flaml.automl: at 26.6s,\testimator xgboost's best error=0.1790,\tbest estimator xgboost's best error=0.1790\n",
            "[flaml.automl: 05-02 17:25:37] {2567} INFO - iteration 69, current learner xgboost\n",
            "INFO:flaml.automl:iteration 69, current learner xgboost\n",
            "[flaml.automl: 05-02 17:25:37] {2750} INFO -  at 26.7s,\testimator xgboost's best error=0.1790,\tbest estimator xgboost's best error=0.1790\n",
            "INFO:flaml.automl: at 26.7s,\testimator xgboost's best error=0.1790,\tbest estimator xgboost's best error=0.1790\n",
            "[flaml.automl: 05-02 17:25:37] {2567} INFO - iteration 70, current learner xgboost\n",
            "INFO:flaml.automl:iteration 70, current learner xgboost\n",
            "[flaml.automl: 05-02 17:25:37] {2750} INFO -  at 26.8s,\testimator xgboost's best error=0.1790,\tbest estimator xgboost's best error=0.1790\n",
            "INFO:flaml.automl: at 26.8s,\testimator xgboost's best error=0.1790,\tbest estimator xgboost's best error=0.1790\n",
            "[flaml.automl: 05-02 17:25:37] {2567} INFO - iteration 71, current learner extra_tree\n",
            "INFO:flaml.automl:iteration 71, current learner extra_tree\n",
            "[flaml.automl: 05-02 17:25:38] {2750} INFO -  at 28.1s,\testimator extra_tree's best error=0.2076,\tbest estimator xgboost's best error=0.1790\n",
            "INFO:flaml.automl: at 28.1s,\testimator extra_tree's best error=0.2076,\tbest estimator xgboost's best error=0.1790\n",
            "[flaml.automl: 05-02 17:25:38] {2567} INFO - iteration 72, current learner xgboost\n",
            "INFO:flaml.automl:iteration 72, current learner xgboost\n",
            "[flaml.automl: 05-02 17:25:39] {2750} INFO -  at 28.3s,\testimator xgboost's best error=0.1790,\tbest estimator xgboost's best error=0.1790\n",
            "INFO:flaml.automl: at 28.3s,\testimator xgboost's best error=0.1790,\tbest estimator xgboost's best error=0.1790\n",
            "[flaml.automl: 05-02 17:25:39] {2567} INFO - iteration 73, current learner extra_tree\n",
            "INFO:flaml.automl:iteration 73, current learner extra_tree\n",
            "[flaml.automl: 05-02 17:25:40] {2750} INFO -  at 29.6s,\testimator extra_tree's best error=0.2076,\tbest estimator xgboost's best error=0.1790\n",
            "INFO:flaml.automl: at 29.6s,\testimator extra_tree's best error=0.2076,\tbest estimator xgboost's best error=0.1790\n",
            "[flaml.automl: 05-02 17:25:40] {2567} INFO - iteration 74, current learner xgboost\n",
            "INFO:flaml.automl:iteration 74, current learner xgboost\n",
            "[flaml.automl: 05-02 17:25:40] {2750} INFO -  at 29.7s,\testimator xgboost's best error=0.1790,\tbest estimator xgboost's best error=0.1790\n",
            "INFO:flaml.automl: at 29.7s,\testimator xgboost's best error=0.1790,\tbest estimator xgboost's best error=0.1790\n",
            "[flaml.automl: 05-02 17:25:40] {2567} INFO - iteration 75, current learner xgboost\n",
            "INFO:flaml.automl:iteration 75, current learner xgboost\n",
            "[flaml.automl: 05-02 17:25:40] {2750} INFO -  at 29.9s,\testimator xgboost's best error=0.1790,\tbest estimator xgboost's best error=0.1790\n",
            "INFO:flaml.automl: at 29.9s,\testimator xgboost's best error=0.1790,\tbest estimator xgboost's best error=0.1790\n",
            "[flaml.automl: 05-02 17:25:40] {2567} INFO - iteration 76, current learner extra_tree\n",
            "INFO:flaml.automl:iteration 76, current learner extra_tree\n",
            "[flaml.automl: 05-02 17:25:42] {2750} INFO -  at 31.4s,\testimator extra_tree's best error=0.2076,\tbest estimator xgboost's best error=0.1790\n",
            "INFO:flaml.automl: at 31.4s,\testimator extra_tree's best error=0.2076,\tbest estimator xgboost's best error=0.1790\n",
            "[flaml.automl: 05-02 17:25:42] {2567} INFO - iteration 77, current learner xgboost\n",
            "INFO:flaml.automl:iteration 77, current learner xgboost\n",
            "[flaml.automl: 05-02 17:25:42] {2750} INFO -  at 31.5s,\testimator xgboost's best error=0.1790,\tbest estimator xgboost's best error=0.1790\n",
            "INFO:flaml.automl: at 31.5s,\testimator xgboost's best error=0.1790,\tbest estimator xgboost's best error=0.1790\n",
            "[flaml.automl: 05-02 17:25:42] {2567} INFO - iteration 78, current learner xgboost\n",
            "INFO:flaml.automl:iteration 78, current learner xgboost\n",
            "[flaml.automl: 05-02 17:25:42] {2750} INFO -  at 31.6s,\testimator xgboost's best error=0.1790,\tbest estimator xgboost's best error=0.1790\n",
            "INFO:flaml.automl: at 31.6s,\testimator xgboost's best error=0.1790,\tbest estimator xgboost's best error=0.1790\n",
            "[flaml.automl: 05-02 17:25:42] {2567} INFO - iteration 79, current learner extra_tree\n",
            "INFO:flaml.automl:iteration 79, current learner extra_tree\n",
            "[flaml.automl: 05-02 17:25:43] {2750} INFO -  at 32.9s,\testimator extra_tree's best error=0.2076,\tbest estimator xgboost's best error=0.1790\n",
            "INFO:flaml.automl: at 32.9s,\testimator extra_tree's best error=0.2076,\tbest estimator xgboost's best error=0.1790\n",
            "[flaml.automl: 05-02 17:25:43] {2567} INFO - iteration 80, current learner xgboost\n",
            "INFO:flaml.automl:iteration 80, current learner xgboost\n",
            "[flaml.automl: 05-02 17:25:43] {2750} INFO -  at 33.0s,\testimator xgboost's best error=0.1790,\tbest estimator xgboost's best error=0.1790\n",
            "INFO:flaml.automl: at 33.0s,\testimator xgboost's best error=0.1790,\tbest estimator xgboost's best error=0.1790\n",
            "[flaml.automl: 05-02 17:25:43] {2567} INFO - iteration 81, current learner rf\n",
            "INFO:flaml.automl:iteration 81, current learner rf\n",
            "[flaml.automl: 05-02 17:25:43] {2750} INFO -  at 33.1s,\testimator rf's best error=0.2041,\tbest estimator xgboost's best error=0.1790\n",
            "INFO:flaml.automl: at 33.1s,\testimator rf's best error=0.2041,\tbest estimator xgboost's best error=0.1790\n",
            "[flaml.automl: 05-02 17:25:43] {2567} INFO - iteration 82, current learner rf\n",
            "INFO:flaml.automl:iteration 82, current learner rf\n",
            "[flaml.automl: 05-02 17:25:44] {2750} INFO -  at 33.3s,\testimator rf's best error=0.2041,\tbest estimator xgboost's best error=0.1790\n",
            "INFO:flaml.automl: at 33.3s,\testimator rf's best error=0.2041,\tbest estimator xgboost's best error=0.1790\n",
            "[flaml.automl: 05-02 17:25:44] {2567} INFO - iteration 83, current learner extra_tree\n",
            "INFO:flaml.automl:iteration 83, current learner extra_tree\n",
            "[flaml.automl: 05-02 17:25:45] {2750} INFO -  at 34.8s,\testimator extra_tree's best error=0.2076,\tbest estimator xgboost's best error=0.1790\n",
            "INFO:flaml.automl: at 34.8s,\testimator extra_tree's best error=0.2076,\tbest estimator xgboost's best error=0.1790\n",
            "[flaml.automl: 05-02 17:25:45] {2567} INFO - iteration 84, current learner xgboost\n",
            "INFO:flaml.automl:iteration 84, current learner xgboost\n",
            "[flaml.automl: 05-02 17:25:45] {2750} INFO -  at 35.0s,\testimator xgboost's best error=0.1790,\tbest estimator xgboost's best error=0.1790\n",
            "INFO:flaml.automl: at 35.0s,\testimator xgboost's best error=0.1790,\tbest estimator xgboost's best error=0.1790\n",
            "[flaml.automl: 05-02 17:25:45] {2567} INFO - iteration 85, current learner rf\n",
            "INFO:flaml.automl:iteration 85, current learner rf\n",
            "[flaml.automl: 05-02 17:25:47] {2750} INFO -  at 36.4s,\testimator rf's best error=0.2041,\tbest estimator xgboost's best error=0.1790\n",
            "INFO:flaml.automl: at 36.4s,\testimator rf's best error=0.2041,\tbest estimator xgboost's best error=0.1790\n",
            "[flaml.automl: 05-02 17:25:47] {2567} INFO - iteration 86, current learner xgboost\n",
            "INFO:flaml.automl:iteration 86, current learner xgboost\n",
            "[flaml.automl: 05-02 17:25:47] {2750} INFO -  at 36.5s,\testimator xgboost's best error=0.1790,\tbest estimator xgboost's best error=0.1790\n",
            "INFO:flaml.automl: at 36.5s,\testimator xgboost's best error=0.1790,\tbest estimator xgboost's best error=0.1790\n",
            "[flaml.automl: 05-02 17:25:47] {2567} INFO - iteration 87, current learner xgboost\n",
            "INFO:flaml.automl:iteration 87, current learner xgboost\n",
            "[flaml.automl: 05-02 17:25:47] {2750} INFO -  at 36.6s,\testimator xgboost's best error=0.1790,\tbest estimator xgboost's best error=0.1790\n",
            "INFO:flaml.automl: at 36.6s,\testimator xgboost's best error=0.1790,\tbest estimator xgboost's best error=0.1790\n",
            "[flaml.automl: 05-02 17:25:47] {2567} INFO - iteration 88, current learner extra_tree\n",
            "INFO:flaml.automl:iteration 88, current learner extra_tree\n",
            "[flaml.automl: 05-02 17:25:48] {2750} INFO -  at 37.8s,\testimator extra_tree's best error=0.2069,\tbest estimator xgboost's best error=0.1790\n",
            "INFO:flaml.automl: at 37.8s,\testimator extra_tree's best error=0.2069,\tbest estimator xgboost's best error=0.1790\n",
            "[flaml.automl: 05-02 17:25:48] {2567} INFO - iteration 89, current learner xgboost\n",
            "INFO:flaml.automl:iteration 89, current learner xgboost\n",
            "[flaml.automl: 05-02 17:25:48] {2750} INFO -  at 37.9s,\testimator xgboost's best error=0.1790,\tbest estimator xgboost's best error=0.1790\n",
            "INFO:flaml.automl: at 37.9s,\testimator xgboost's best error=0.1790,\tbest estimator xgboost's best error=0.1790\n",
            "[flaml.automl: 05-02 17:25:48] {2567} INFO - iteration 90, current learner rf\n",
            "INFO:flaml.automl:iteration 90, current learner rf\n",
            "[flaml.automl: 05-02 17:25:50] {2750} INFO -  at 39.4s,\testimator rf's best error=0.2041,\tbest estimator xgboost's best error=0.1790\n",
            "INFO:flaml.automl: at 39.4s,\testimator rf's best error=0.2041,\tbest estimator xgboost's best error=0.1790\n",
            "[flaml.automl: 05-02 17:25:50] {2567} INFO - iteration 91, current learner xgboost\n",
            "INFO:flaml.automl:iteration 91, current learner xgboost\n",
            "[flaml.automl: 05-02 17:25:50] {2750} INFO -  at 39.5s,\testimator xgboost's best error=0.1790,\tbest estimator xgboost's best error=0.1790\n",
            "INFO:flaml.automl: at 39.5s,\testimator xgboost's best error=0.1790,\tbest estimator xgboost's best error=0.1790\n",
            "[flaml.automl: 05-02 17:25:50] {2567} INFO - iteration 92, current learner xgboost\n",
            "INFO:flaml.automl:iteration 92, current learner xgboost\n",
            "[flaml.automl: 05-02 17:25:50] {2750} INFO -  at 39.5s,\testimator xgboost's best error=0.1790,\tbest estimator xgboost's best error=0.1790\n",
            "INFO:flaml.automl: at 39.5s,\testimator xgboost's best error=0.1790,\tbest estimator xgboost's best error=0.1790\n",
            "[flaml.automl: 05-02 17:25:50] {2567} INFO - iteration 93, current learner xgboost\n",
            "INFO:flaml.automl:iteration 93, current learner xgboost\n",
            "[flaml.automl: 05-02 17:25:50] {2750} INFO -  at 39.6s,\testimator xgboost's best error=0.1790,\tbest estimator xgboost's best error=0.1790\n",
            "INFO:flaml.automl: at 39.6s,\testimator xgboost's best error=0.1790,\tbest estimator xgboost's best error=0.1790\n",
            "[flaml.automl: 05-02 17:25:50] {2567} INFO - iteration 94, current learner rf\n",
            "INFO:flaml.automl:iteration 94, current learner rf\n",
            "[flaml.automl: 05-02 17:25:50] {2750} INFO -  at 39.7s,\testimator rf's best error=0.2041,\tbest estimator xgboost's best error=0.1790\n",
            "INFO:flaml.automl: at 39.7s,\testimator rf's best error=0.2041,\tbest estimator xgboost's best error=0.1790\n",
            "[flaml.automl: 05-02 17:25:50] {2567} INFO - iteration 95, current learner xgboost\n",
            "INFO:flaml.automl:iteration 95, current learner xgboost\n",
            "[flaml.automl: 05-02 17:25:50] {2750} INFO -  at 39.7s,\testimator xgboost's best error=0.1790,\tbest estimator xgboost's best error=0.1790\n",
            "INFO:flaml.automl: at 39.7s,\testimator xgboost's best error=0.1790,\tbest estimator xgboost's best error=0.1790\n",
            "[flaml.automl: 05-02 17:25:50] {2567} INFO - iteration 96, current learner xgboost\n",
            "INFO:flaml.automl:iteration 96, current learner xgboost\n",
            "[flaml.automl: 05-02 17:25:50] {2750} INFO -  at 39.8s,\testimator xgboost's best error=0.1790,\tbest estimator xgboost's best error=0.1790\n",
            "INFO:flaml.automl: at 39.8s,\testimator xgboost's best error=0.1790,\tbest estimator xgboost's best error=0.1790\n",
            "[flaml.automl: 05-02 17:25:50] {2567} INFO - iteration 97, current learner xgboost\n",
            "INFO:flaml.automl:iteration 97, current learner xgboost\n",
            "[flaml.automl: 05-02 17:25:50] {2750} INFO -  at 39.9s,\testimator xgboost's best error=0.1790,\tbest estimator xgboost's best error=0.1790\n",
            "INFO:flaml.automl: at 39.9s,\testimator xgboost's best error=0.1790,\tbest estimator xgboost's best error=0.1790\n",
            "[flaml.automl: 05-02 17:25:50] {2567} INFO - iteration 98, current learner xgboost\n",
            "INFO:flaml.automl:iteration 98, current learner xgboost\n",
            "[flaml.automl: 05-02 17:25:50] {2750} INFO -  at 39.9s,\testimator xgboost's best error=0.1790,\tbest estimator xgboost's best error=0.1790\n",
            "INFO:flaml.automl: at 39.9s,\testimator xgboost's best error=0.1790,\tbest estimator xgboost's best error=0.1790\n",
            "[flaml.automl: 05-02 17:25:50] {2567} INFO - iteration 99, current learner xgboost\n",
            "INFO:flaml.automl:iteration 99, current learner xgboost\n",
            "[flaml.automl: 05-02 17:25:50] {2750} INFO -  at 40.0s,\testimator xgboost's best error=0.1790,\tbest estimator xgboost's best error=0.1790\n",
            "INFO:flaml.automl: at 40.0s,\testimator xgboost's best error=0.1790,\tbest estimator xgboost's best error=0.1790\n",
            "[flaml.automl: 05-02 17:25:50] {2567} INFO - iteration 100, current learner xgboost\n",
            "INFO:flaml.automl:iteration 100, current learner xgboost\n",
            "[flaml.automl: 05-02 17:25:50] {2750} INFO -  at 40.1s,\testimator xgboost's best error=0.1790,\tbest estimator xgboost's best error=0.1790\n",
            "INFO:flaml.automl: at 40.1s,\testimator xgboost's best error=0.1790,\tbest estimator xgboost's best error=0.1790\n",
            "[flaml.automl: 05-02 17:25:50] {2567} INFO - iteration 101, current learner xgboost\n",
            "INFO:flaml.automl:iteration 101, current learner xgboost\n",
            "[flaml.automl: 05-02 17:25:50] {2750} INFO -  at 40.1s,\testimator xgboost's best error=0.1790,\tbest estimator xgboost's best error=0.1790\n",
            "INFO:flaml.automl: at 40.1s,\testimator xgboost's best error=0.1790,\tbest estimator xgboost's best error=0.1790\n",
            "[flaml.automl: 05-02 17:25:50] {2567} INFO - iteration 102, current learner xgboost\n",
            "INFO:flaml.automl:iteration 102, current learner xgboost\n",
            "[flaml.automl: 05-02 17:25:51] {2750} INFO -  at 40.2s,\testimator xgboost's best error=0.1790,\tbest estimator xgboost's best error=0.1790\n",
            "INFO:flaml.automl: at 40.2s,\testimator xgboost's best error=0.1790,\tbest estimator xgboost's best error=0.1790\n",
            "[flaml.automl: 05-02 17:25:51] {2567} INFO - iteration 103, current learner xgboost\n",
            "INFO:flaml.automl:iteration 103, current learner xgboost\n",
            "[flaml.automl: 05-02 17:25:51] {2750} INFO -  at 40.3s,\testimator xgboost's best error=0.1790,\tbest estimator xgboost's best error=0.1790\n",
            "INFO:flaml.automl: at 40.3s,\testimator xgboost's best error=0.1790,\tbest estimator xgboost's best error=0.1790\n",
            "[flaml.automl: 05-02 17:25:51] {2567} INFO - iteration 104, current learner xgboost\n",
            "INFO:flaml.automl:iteration 104, current learner xgboost\n",
            "[flaml.automl: 05-02 17:25:51] {2750} INFO -  at 40.4s,\testimator xgboost's best error=0.1790,\tbest estimator xgboost's best error=0.1790\n",
            "INFO:flaml.automl: at 40.4s,\testimator xgboost's best error=0.1790,\tbest estimator xgboost's best error=0.1790\n",
            "[flaml.automl: 05-02 17:25:51] {2567} INFO - iteration 105, current learner xgboost\n",
            "INFO:flaml.automl:iteration 105, current learner xgboost\n",
            "[flaml.automl: 05-02 17:25:51] {2750} INFO -  at 40.4s,\testimator xgboost's best error=0.1790,\tbest estimator xgboost's best error=0.1790\n",
            "INFO:flaml.automl: at 40.4s,\testimator xgboost's best error=0.1790,\tbest estimator xgboost's best error=0.1790\n",
            "[flaml.automl: 05-02 17:25:51] {2567} INFO - iteration 106, current learner xgboost\n",
            "INFO:flaml.automl:iteration 106, current learner xgboost\n",
            "[flaml.automl: 05-02 17:25:51] {2750} INFO -  at 40.5s,\testimator xgboost's best error=0.1790,\tbest estimator xgboost's best error=0.1790\n",
            "INFO:flaml.automl: at 40.5s,\testimator xgboost's best error=0.1790,\tbest estimator xgboost's best error=0.1790\n",
            "[flaml.automl: 05-02 17:25:51] {2567} INFO - iteration 107, current learner xgboost\n",
            "INFO:flaml.automl:iteration 107, current learner xgboost\n",
            "[flaml.automl: 05-02 17:25:51] {2750} INFO -  at 40.6s,\testimator xgboost's best error=0.1790,\tbest estimator xgboost's best error=0.1790\n",
            "INFO:flaml.automl: at 40.6s,\testimator xgboost's best error=0.1790,\tbest estimator xgboost's best error=0.1790\n",
            "[flaml.automl: 05-02 17:25:51] {2567} INFO - iteration 108, current learner xgboost\n",
            "INFO:flaml.automl:iteration 108, current learner xgboost\n",
            "[flaml.automl: 05-02 17:25:51] {2750} INFO -  at 40.6s,\testimator xgboost's best error=0.1790,\tbest estimator xgboost's best error=0.1790\n",
            "INFO:flaml.automl: at 40.6s,\testimator xgboost's best error=0.1790,\tbest estimator xgboost's best error=0.1790\n",
            "[flaml.automl: 05-02 17:25:51] {2567} INFO - iteration 109, current learner xgboost\n",
            "INFO:flaml.automl:iteration 109, current learner xgboost\n",
            "[flaml.automl: 05-02 17:25:51] {2750} INFO -  at 40.7s,\testimator xgboost's best error=0.1790,\tbest estimator xgboost's best error=0.1790\n",
            "INFO:flaml.automl: at 40.7s,\testimator xgboost's best error=0.1790,\tbest estimator xgboost's best error=0.1790\n",
            "[flaml.automl: 05-02 17:25:51] {2567} INFO - iteration 110, current learner xgboost\n",
            "INFO:flaml.automl:iteration 110, current learner xgboost\n",
            "[flaml.automl: 05-02 17:25:51] {2750} INFO -  at 40.8s,\testimator xgboost's best error=0.1790,\tbest estimator xgboost's best error=0.1790\n",
            "INFO:flaml.automl: at 40.8s,\testimator xgboost's best error=0.1790,\tbest estimator xgboost's best error=0.1790\n",
            "[flaml.automl: 05-02 17:25:51] {2567} INFO - iteration 111, current learner xgboost\n",
            "INFO:flaml.automl:iteration 111, current learner xgboost\n",
            "[flaml.automl: 05-02 17:25:51] {2750} INFO -  at 40.9s,\testimator xgboost's best error=0.1790,\tbest estimator xgboost's best error=0.1790\n",
            "INFO:flaml.automl: at 40.9s,\testimator xgboost's best error=0.1790,\tbest estimator xgboost's best error=0.1790\n",
            "[flaml.automl: 05-02 17:25:51] {2567} INFO - iteration 112, current learner extra_tree\n",
            "INFO:flaml.automl:iteration 112, current learner extra_tree\n",
            "[flaml.automl: 05-02 17:25:52] {2750} INFO -  at 42.2s,\testimator extra_tree's best error=0.2069,\tbest estimator xgboost's best error=0.1790\n",
            "INFO:flaml.automl: at 42.2s,\testimator extra_tree's best error=0.2069,\tbest estimator xgboost's best error=0.1790\n",
            "[flaml.automl: 05-02 17:25:52] {2567} INFO - iteration 113, current learner xgboost\n",
            "INFO:flaml.automl:iteration 113, current learner xgboost\n",
            "[flaml.automl: 05-02 17:25:53] {2750} INFO -  at 42.2s,\testimator xgboost's best error=0.1790,\tbest estimator xgboost's best error=0.1790\n",
            "INFO:flaml.automl: at 42.2s,\testimator xgboost's best error=0.1790,\tbest estimator xgboost's best error=0.1790\n",
            "[flaml.automl: 05-02 17:25:53] {2567} INFO - iteration 114, current learner xgboost\n",
            "INFO:flaml.automl:iteration 114, current learner xgboost\n",
            "[flaml.automl: 05-02 17:25:53] {2750} INFO -  at 42.3s,\testimator xgboost's best error=0.1790,\tbest estimator xgboost's best error=0.1790\n",
            "INFO:flaml.automl: at 42.3s,\testimator xgboost's best error=0.1790,\tbest estimator xgboost's best error=0.1790\n",
            "[flaml.automl: 05-02 17:25:53] {2567} INFO - iteration 115, current learner xgboost\n",
            "INFO:flaml.automl:iteration 115, current learner xgboost\n",
            "[flaml.automl: 05-02 17:25:53] {2750} INFO -  at 42.3s,\testimator xgboost's best error=0.1790,\tbest estimator xgboost's best error=0.1790\n",
            "INFO:flaml.automl: at 42.3s,\testimator xgboost's best error=0.1790,\tbest estimator xgboost's best error=0.1790\n",
            "[flaml.automl: 05-02 17:25:53] {2567} INFO - iteration 116, current learner xgboost\n",
            "INFO:flaml.automl:iteration 116, current learner xgboost\n",
            "[flaml.automl: 05-02 17:25:53] {2750} INFO -  at 42.4s,\testimator xgboost's best error=0.1790,\tbest estimator xgboost's best error=0.1790\n",
            "INFO:flaml.automl: at 42.4s,\testimator xgboost's best error=0.1790,\tbest estimator xgboost's best error=0.1790\n",
            "[flaml.automl: 05-02 17:25:53] {2567} INFO - iteration 117, current learner xgboost\n",
            "INFO:flaml.automl:iteration 117, current learner xgboost\n",
            "[flaml.automl: 05-02 17:25:53] {2750} INFO -  at 42.5s,\testimator xgboost's best error=0.1790,\tbest estimator xgboost's best error=0.1790\n",
            "INFO:flaml.automl: at 42.5s,\testimator xgboost's best error=0.1790,\tbest estimator xgboost's best error=0.1790\n",
            "[flaml.automl: 05-02 17:25:53] {2567} INFO - iteration 118, current learner xgboost\n",
            "INFO:flaml.automl:iteration 118, current learner xgboost\n",
            "[flaml.automl: 05-02 17:25:53] {2750} INFO -  at 42.5s,\testimator xgboost's best error=0.1790,\tbest estimator xgboost's best error=0.1790\n",
            "INFO:flaml.automl: at 42.5s,\testimator xgboost's best error=0.1790,\tbest estimator xgboost's best error=0.1790\n",
            "[flaml.automl: 05-02 17:25:53] {2567} INFO - iteration 119, current learner xgboost\n",
            "INFO:flaml.automl:iteration 119, current learner xgboost\n",
            "[flaml.automl: 05-02 17:25:53] {2750} INFO -  at 42.6s,\testimator xgboost's best error=0.1790,\tbest estimator xgboost's best error=0.1790\n",
            "INFO:flaml.automl: at 42.6s,\testimator xgboost's best error=0.1790,\tbest estimator xgboost's best error=0.1790\n",
            "[flaml.automl: 05-02 17:25:53] {2567} INFO - iteration 120, current learner xgboost\n",
            "INFO:flaml.automl:iteration 120, current learner xgboost\n",
            "[flaml.automl: 05-02 17:25:53] {2750} INFO -  at 42.7s,\testimator xgboost's best error=0.1790,\tbest estimator xgboost's best error=0.1790\n",
            "INFO:flaml.automl: at 42.7s,\testimator xgboost's best error=0.1790,\tbest estimator xgboost's best error=0.1790\n",
            "[flaml.automl: 05-02 17:25:53] {2567} INFO - iteration 121, current learner xgboost\n",
            "INFO:flaml.automl:iteration 121, current learner xgboost\n",
            "[flaml.automl: 05-02 17:25:53] {2750} INFO -  at 42.7s,\testimator xgboost's best error=0.1790,\tbest estimator xgboost's best error=0.1790\n",
            "INFO:flaml.automl: at 42.7s,\testimator xgboost's best error=0.1790,\tbest estimator xgboost's best error=0.1790\n",
            "[flaml.automl: 05-02 17:25:53] {2567} INFO - iteration 122, current learner xgboost\n",
            "INFO:flaml.automl:iteration 122, current learner xgboost\n",
            "[flaml.automl: 05-02 17:25:53] {2750} INFO -  at 42.8s,\testimator xgboost's best error=0.1790,\tbest estimator xgboost's best error=0.1790\n",
            "INFO:flaml.automl: at 42.8s,\testimator xgboost's best error=0.1790,\tbest estimator xgboost's best error=0.1790\n",
            "[flaml.automl: 05-02 17:25:53] {2567} INFO - iteration 123, current learner xgboost\n",
            "INFO:flaml.automl:iteration 123, current learner xgboost\n",
            "[flaml.automl: 05-02 17:25:53] {2750} INFO -  at 42.9s,\testimator xgboost's best error=0.1790,\tbest estimator xgboost's best error=0.1790\n",
            "INFO:flaml.automl: at 42.9s,\testimator xgboost's best error=0.1790,\tbest estimator xgboost's best error=0.1790\n",
            "[flaml.automl: 05-02 17:25:53] {2567} INFO - iteration 124, current learner xgboost\n",
            "INFO:flaml.automl:iteration 124, current learner xgboost\n",
            "[flaml.automl: 05-02 17:25:53] {2750} INFO -  at 43.0s,\testimator xgboost's best error=0.1790,\tbest estimator xgboost's best error=0.1790\n",
            "INFO:flaml.automl: at 43.0s,\testimator xgboost's best error=0.1790,\tbest estimator xgboost's best error=0.1790\n",
            "[flaml.automl: 05-02 17:25:53] {2567} INFO - iteration 125, current learner xgboost\n",
            "INFO:flaml.automl:iteration 125, current learner xgboost\n",
            "[flaml.automl: 05-02 17:25:53] {2750} INFO -  at 43.0s,\testimator xgboost's best error=0.1790,\tbest estimator xgboost's best error=0.1790\n",
            "INFO:flaml.automl: at 43.0s,\testimator xgboost's best error=0.1790,\tbest estimator xgboost's best error=0.1790\n",
            "[flaml.automl: 05-02 17:25:53] {2567} INFO - iteration 126, current learner xgboost\n",
            "INFO:flaml.automl:iteration 126, current learner xgboost\n",
            "[flaml.automl: 05-02 17:25:53] {2750} INFO -  at 43.1s,\testimator xgboost's best error=0.1790,\tbest estimator xgboost's best error=0.1790\n",
            "INFO:flaml.automl: at 43.1s,\testimator xgboost's best error=0.1790,\tbest estimator xgboost's best error=0.1790\n",
            "[flaml.automl: 05-02 17:25:53] {2567} INFO - iteration 127, current learner xgboost\n",
            "INFO:flaml.automl:iteration 127, current learner xgboost\n",
            "[flaml.automl: 05-02 17:25:53] {2750} INFO -  at 43.2s,\testimator xgboost's best error=0.1790,\tbest estimator xgboost's best error=0.1790\n",
            "INFO:flaml.automl: at 43.2s,\testimator xgboost's best error=0.1790,\tbest estimator xgboost's best error=0.1790\n",
            "[flaml.automl: 05-02 17:25:53] {2567} INFO - iteration 128, current learner xgboost\n",
            "INFO:flaml.automl:iteration 128, current learner xgboost\n",
            "[flaml.automl: 05-02 17:25:54] {2750} INFO -  at 43.2s,\testimator xgboost's best error=0.1790,\tbest estimator xgboost's best error=0.1790\n",
            "INFO:flaml.automl: at 43.2s,\testimator xgboost's best error=0.1790,\tbest estimator xgboost's best error=0.1790\n",
            "[flaml.automl: 05-02 17:25:54] {2567} INFO - iteration 129, current learner xgboost\n",
            "INFO:flaml.automl:iteration 129, current learner xgboost\n",
            "[flaml.automl: 05-02 17:25:54] {2750} INFO -  at 43.3s,\testimator xgboost's best error=0.1769,\tbest estimator xgboost's best error=0.1769\n",
            "INFO:flaml.automl: at 43.3s,\testimator xgboost's best error=0.1769,\tbest estimator xgboost's best error=0.1769\n",
            "[flaml.automl: 05-02 17:25:54] {2567} INFO - iteration 130, current learner xgboost\n",
            "INFO:flaml.automl:iteration 130, current learner xgboost\n",
            "[flaml.automl: 05-02 17:25:54] {2750} INFO -  at 43.4s,\testimator xgboost's best error=0.1769,\tbest estimator xgboost's best error=0.1769\n",
            "INFO:flaml.automl: at 43.4s,\testimator xgboost's best error=0.1769,\tbest estimator xgboost's best error=0.1769\n",
            "[flaml.automl: 05-02 17:25:54] {2567} INFO - iteration 131, current learner xgboost\n",
            "INFO:flaml.automl:iteration 131, current learner xgboost\n",
            "[flaml.automl: 05-02 17:25:54] {2750} INFO -  at 43.5s,\testimator xgboost's best error=0.1769,\tbest estimator xgboost's best error=0.1769\n",
            "INFO:flaml.automl: at 43.5s,\testimator xgboost's best error=0.1769,\tbest estimator xgboost's best error=0.1769\n",
            "[flaml.automl: 05-02 17:25:54] {2567} INFO - iteration 132, current learner xgboost\n",
            "INFO:flaml.automl:iteration 132, current learner xgboost\n",
            "[flaml.automl: 05-02 17:25:54] {2750} INFO -  at 43.6s,\testimator xgboost's best error=0.1769,\tbest estimator xgboost's best error=0.1769\n",
            "INFO:flaml.automl: at 43.6s,\testimator xgboost's best error=0.1769,\tbest estimator xgboost's best error=0.1769\n",
            "[flaml.automl: 05-02 17:25:54] {2567} INFO - iteration 133, current learner xgboost\n",
            "INFO:flaml.automl:iteration 133, current learner xgboost\n",
            "[flaml.automl: 05-02 17:25:54] {2750} INFO -  at 43.6s,\testimator xgboost's best error=0.1769,\tbest estimator xgboost's best error=0.1769\n",
            "INFO:flaml.automl: at 43.6s,\testimator xgboost's best error=0.1769,\tbest estimator xgboost's best error=0.1769\n",
            "[flaml.automl: 05-02 17:25:54] {2567} INFO - iteration 134, current learner rf\n",
            "INFO:flaml.automl:iteration 134, current learner rf\n",
            "[flaml.automl: 05-02 17:25:54] {2750} INFO -  at 43.7s,\testimator rf's best error=0.2041,\tbest estimator xgboost's best error=0.1769\n",
            "INFO:flaml.automl: at 43.7s,\testimator rf's best error=0.2041,\tbest estimator xgboost's best error=0.1769\n",
            "[flaml.automl: 05-02 17:25:54] {2567} INFO - iteration 135, current learner xgboost\n",
            "INFO:flaml.automl:iteration 135, current learner xgboost\n",
            "[flaml.automl: 05-02 17:25:54] {2750} INFO -  at 43.8s,\testimator xgboost's best error=0.1769,\tbest estimator xgboost's best error=0.1769\n",
            "INFO:flaml.automl: at 43.8s,\testimator xgboost's best error=0.1769,\tbest estimator xgboost's best error=0.1769\n",
            "[flaml.automl: 05-02 17:25:54] {2567} INFO - iteration 136, current learner xgboost\n",
            "INFO:flaml.automl:iteration 136, current learner xgboost\n",
            "[flaml.automl: 05-02 17:25:54] {2750} INFO -  at 43.9s,\testimator xgboost's best error=0.1769,\tbest estimator xgboost's best error=0.1769\n",
            "INFO:flaml.automl: at 43.9s,\testimator xgboost's best error=0.1769,\tbest estimator xgboost's best error=0.1769\n",
            "[flaml.automl: 05-02 17:25:54] {2567} INFO - iteration 137, current learner xgboost\n",
            "INFO:flaml.automl:iteration 137, current learner xgboost\n",
            "[flaml.automl: 05-02 17:25:54] {2750} INFO -  at 43.9s,\testimator xgboost's best error=0.1769,\tbest estimator xgboost's best error=0.1769\n",
            "INFO:flaml.automl: at 43.9s,\testimator xgboost's best error=0.1769,\tbest estimator xgboost's best error=0.1769\n",
            "[flaml.automl: 05-02 17:25:54] {2567} INFO - iteration 138, current learner xgboost\n",
            "INFO:flaml.automl:iteration 138, current learner xgboost\n",
            "[flaml.automl: 05-02 17:25:54] {2750} INFO -  at 44.0s,\testimator xgboost's best error=0.1769,\tbest estimator xgboost's best error=0.1769\n",
            "INFO:flaml.automl: at 44.0s,\testimator xgboost's best error=0.1769,\tbest estimator xgboost's best error=0.1769\n",
            "[flaml.automl: 05-02 17:25:54] {2567} INFO - iteration 139, current learner xgboost\n",
            "INFO:flaml.automl:iteration 139, current learner xgboost\n",
            "[flaml.automl: 05-02 17:25:54] {2750} INFO -  at 44.1s,\testimator xgboost's best error=0.1769,\tbest estimator xgboost's best error=0.1769\n",
            "INFO:flaml.automl: at 44.1s,\testimator xgboost's best error=0.1769,\tbest estimator xgboost's best error=0.1769\n",
            "[flaml.automl: 05-02 17:25:54] {2567} INFO - iteration 140, current learner xgboost\n",
            "INFO:flaml.automl:iteration 140, current learner xgboost\n",
            "[flaml.automl: 05-02 17:25:54] {2750} INFO -  at 44.2s,\testimator xgboost's best error=0.1769,\tbest estimator xgboost's best error=0.1769\n",
            "INFO:flaml.automl: at 44.2s,\testimator xgboost's best error=0.1769,\tbest estimator xgboost's best error=0.1769\n",
            "[flaml.automl: 05-02 17:25:54] {2567} INFO - iteration 141, current learner xgboost\n",
            "INFO:flaml.automl:iteration 141, current learner xgboost\n",
            "[flaml.automl: 05-02 17:25:55] {2750} INFO -  at 44.3s,\testimator xgboost's best error=0.1769,\tbest estimator xgboost's best error=0.1769\n",
            "INFO:flaml.automl: at 44.3s,\testimator xgboost's best error=0.1769,\tbest estimator xgboost's best error=0.1769\n",
            "[flaml.automl: 05-02 17:25:55] {2567} INFO - iteration 142, current learner xgboost\n",
            "INFO:flaml.automl:iteration 142, current learner xgboost\n",
            "[flaml.automl: 05-02 17:25:55] {2750} INFO -  at 44.3s,\testimator xgboost's best error=0.1769,\tbest estimator xgboost's best error=0.1769\n",
            "INFO:flaml.automl: at 44.3s,\testimator xgboost's best error=0.1769,\tbest estimator xgboost's best error=0.1769\n",
            "[flaml.automl: 05-02 17:25:55] {2567} INFO - iteration 143, current learner xgboost\n",
            "INFO:flaml.automl:iteration 143, current learner xgboost\n",
            "[flaml.automl: 05-02 17:25:55] {2750} INFO -  at 44.4s,\testimator xgboost's best error=0.1769,\tbest estimator xgboost's best error=0.1769\n",
            "INFO:flaml.automl: at 44.4s,\testimator xgboost's best error=0.1769,\tbest estimator xgboost's best error=0.1769\n",
            "[flaml.automl: 05-02 17:25:55] {2567} INFO - iteration 144, current learner xgboost\n",
            "INFO:flaml.automl:iteration 144, current learner xgboost\n",
            "[flaml.automl: 05-02 17:25:55] {2750} INFO -  at 44.5s,\testimator xgboost's best error=0.1769,\tbest estimator xgboost's best error=0.1769\n",
            "INFO:flaml.automl: at 44.5s,\testimator xgboost's best error=0.1769,\tbest estimator xgboost's best error=0.1769\n",
            "[flaml.automl: 05-02 17:25:55] {2567} INFO - iteration 145, current learner xgboost\n",
            "INFO:flaml.automl:iteration 145, current learner xgboost\n",
            "[flaml.automl: 05-02 17:25:55] {2750} INFO -  at 44.6s,\testimator xgboost's best error=0.1769,\tbest estimator xgboost's best error=0.1769\n",
            "INFO:flaml.automl: at 44.6s,\testimator xgboost's best error=0.1769,\tbest estimator xgboost's best error=0.1769\n",
            "[flaml.automl: 05-02 17:25:55] {2567} INFO - iteration 146, current learner xgboost\n",
            "INFO:flaml.automl:iteration 146, current learner xgboost\n",
            "[flaml.automl: 05-02 17:25:55] {2750} INFO -  at 44.6s,\testimator xgboost's best error=0.1769,\tbest estimator xgboost's best error=0.1769\n",
            "INFO:flaml.automl: at 44.6s,\testimator xgboost's best error=0.1769,\tbest estimator xgboost's best error=0.1769\n",
            "[flaml.automl: 05-02 17:25:55] {2567} INFO - iteration 147, current learner xgboost\n",
            "INFO:flaml.automl:iteration 147, current learner xgboost\n",
            "[flaml.automl: 05-02 17:25:55] {2750} INFO -  at 44.7s,\testimator xgboost's best error=0.1769,\tbest estimator xgboost's best error=0.1769\n",
            "INFO:flaml.automl: at 44.7s,\testimator xgboost's best error=0.1769,\tbest estimator xgboost's best error=0.1769\n",
            "[flaml.automl: 05-02 17:25:55] {2567} INFO - iteration 148, current learner xgboost\n",
            "INFO:flaml.automl:iteration 148, current learner xgboost\n",
            "[flaml.automl: 05-02 17:25:55] {2750} INFO -  at 44.8s,\testimator xgboost's best error=0.1769,\tbest estimator xgboost's best error=0.1769\n",
            "INFO:flaml.automl: at 44.8s,\testimator xgboost's best error=0.1769,\tbest estimator xgboost's best error=0.1769\n",
            "[flaml.automl: 05-02 17:25:55] {2567} INFO - iteration 149, current learner xgboost\n",
            "INFO:flaml.automl:iteration 149, current learner xgboost\n",
            "[flaml.automl: 05-02 17:25:55] {2750} INFO -  at 44.9s,\testimator xgboost's best error=0.1769,\tbest estimator xgboost's best error=0.1769\n",
            "INFO:flaml.automl: at 44.9s,\testimator xgboost's best error=0.1769,\tbest estimator xgboost's best error=0.1769\n",
            "[flaml.automl: 05-02 17:25:55] {2567} INFO - iteration 150, current learner xgboost\n",
            "INFO:flaml.automl:iteration 150, current learner xgboost\n",
            "[flaml.automl: 05-02 17:25:55] {2750} INFO -  at 45.0s,\testimator xgboost's best error=0.1769,\tbest estimator xgboost's best error=0.1769\n",
            "INFO:flaml.automl: at 45.0s,\testimator xgboost's best error=0.1769,\tbest estimator xgboost's best error=0.1769\n",
            "[flaml.automl: 05-02 17:25:55] {2567} INFO - iteration 151, current learner xgboost\n",
            "INFO:flaml.automl:iteration 151, current learner xgboost\n",
            "[flaml.automl: 05-02 17:25:55] {2750} INFO -  at 45.0s,\testimator xgboost's best error=0.1769,\tbest estimator xgboost's best error=0.1769\n",
            "INFO:flaml.automl: at 45.0s,\testimator xgboost's best error=0.1769,\tbest estimator xgboost's best error=0.1769\n",
            "[flaml.automl: 05-02 17:25:55] {2567} INFO - iteration 152, current learner xgboost\n",
            "INFO:flaml.automl:iteration 152, current learner xgboost\n",
            "[flaml.automl: 05-02 17:25:55] {2750} INFO -  at 45.1s,\testimator xgboost's best error=0.1769,\tbest estimator xgboost's best error=0.1769\n",
            "INFO:flaml.automl: at 45.1s,\testimator xgboost's best error=0.1769,\tbest estimator xgboost's best error=0.1769\n",
            "[flaml.automl: 05-02 17:25:55] {2567} INFO - iteration 153, current learner xgboost\n",
            "INFO:flaml.automl:iteration 153, current learner xgboost\n",
            "[flaml.automl: 05-02 17:25:55] {2750} INFO -  at 45.2s,\testimator xgboost's best error=0.1769,\tbest estimator xgboost's best error=0.1769\n",
            "INFO:flaml.automl: at 45.2s,\testimator xgboost's best error=0.1769,\tbest estimator xgboost's best error=0.1769\n",
            "[flaml.automl: 05-02 17:25:55] {2567} INFO - iteration 154, current learner rf\n",
            "INFO:flaml.automl:iteration 154, current learner rf\n",
            "[flaml.automl: 05-02 17:25:57] {2750} INFO -  at 46.5s,\testimator rf's best error=0.2041,\tbest estimator xgboost's best error=0.1769\n",
            "INFO:flaml.automl: at 46.5s,\testimator rf's best error=0.2041,\tbest estimator xgboost's best error=0.1769\n",
            "[flaml.automl: 05-02 17:25:57] {2567} INFO - iteration 155, current learner xgboost\n",
            "INFO:flaml.automl:iteration 155, current learner xgboost\n",
            "[flaml.automl: 05-02 17:25:57] {2750} INFO -  at 46.6s,\testimator xgboost's best error=0.1769,\tbest estimator xgboost's best error=0.1769\n",
            "INFO:flaml.automl: at 46.6s,\testimator xgboost's best error=0.1769,\tbest estimator xgboost's best error=0.1769\n",
            "[flaml.automl: 05-02 17:25:57] {2567} INFO - iteration 156, current learner xgboost\n",
            "INFO:flaml.automl:iteration 156, current learner xgboost\n",
            "[flaml.automl: 05-02 17:25:57] {2750} INFO -  at 46.7s,\testimator xgboost's best error=0.1769,\tbest estimator xgboost's best error=0.1769\n",
            "INFO:flaml.automl: at 46.7s,\testimator xgboost's best error=0.1769,\tbest estimator xgboost's best error=0.1769\n",
            "[flaml.automl: 05-02 17:25:57] {2567} INFO - iteration 157, current learner xgboost\n",
            "INFO:flaml.automl:iteration 157, current learner xgboost\n",
            "[flaml.automl: 05-02 17:25:57] {2750} INFO -  at 46.7s,\testimator xgboost's best error=0.1769,\tbest estimator xgboost's best error=0.1769\n",
            "INFO:flaml.automl: at 46.7s,\testimator xgboost's best error=0.1769,\tbest estimator xgboost's best error=0.1769\n",
            "[flaml.automl: 05-02 17:25:57] {2567} INFO - iteration 158, current learner xgboost\n",
            "INFO:flaml.automl:iteration 158, current learner xgboost\n",
            "[flaml.automl: 05-02 17:25:57] {2750} INFO -  at 46.8s,\testimator xgboost's best error=0.1769,\tbest estimator xgboost's best error=0.1769\n",
            "INFO:flaml.automl: at 46.8s,\testimator xgboost's best error=0.1769,\tbest estimator xgboost's best error=0.1769\n",
            "[flaml.automl: 05-02 17:25:57] {2567} INFO - iteration 159, current learner xgboost\n",
            "INFO:flaml.automl:iteration 159, current learner xgboost\n",
            "[flaml.automl: 05-02 17:25:57] {2750} INFO -  at 46.9s,\testimator xgboost's best error=0.1769,\tbest estimator xgboost's best error=0.1769\n",
            "INFO:flaml.automl: at 46.9s,\testimator xgboost's best error=0.1769,\tbest estimator xgboost's best error=0.1769\n",
            "[flaml.automl: 05-02 17:25:57] {2567} INFO - iteration 160, current learner xgboost\n",
            "INFO:flaml.automl:iteration 160, current learner xgboost\n",
            "[flaml.automl: 05-02 17:25:57] {2750} INFO -  at 47.0s,\testimator xgboost's best error=0.1769,\tbest estimator xgboost's best error=0.1769\n",
            "INFO:flaml.automl: at 47.0s,\testimator xgboost's best error=0.1769,\tbest estimator xgboost's best error=0.1769\n",
            "[flaml.automl: 05-02 17:25:57] {2567} INFO - iteration 161, current learner rf\n",
            "INFO:flaml.automl:iteration 161, current learner rf\n",
            "[flaml.automl: 05-02 17:25:58] {2750} INFO -  at 48.2s,\testimator rf's best error=0.2041,\tbest estimator xgboost's best error=0.1769\n",
            "INFO:flaml.automl: at 48.2s,\testimator rf's best error=0.2041,\tbest estimator xgboost's best error=0.1769\n",
            "[flaml.automl: 05-02 17:25:58] {2567} INFO - iteration 162, current learner xgboost\n",
            "INFO:flaml.automl:iteration 162, current learner xgboost\n",
            "[flaml.automl: 05-02 17:25:59] {2750} INFO -  at 48.2s,\testimator xgboost's best error=0.1769,\tbest estimator xgboost's best error=0.1769\n",
            "INFO:flaml.automl: at 48.2s,\testimator xgboost's best error=0.1769,\tbest estimator xgboost's best error=0.1769\n",
            "[flaml.automl: 05-02 17:25:59] {2567} INFO - iteration 163, current learner xgboost\n",
            "INFO:flaml.automl:iteration 163, current learner xgboost\n",
            "[flaml.automl: 05-02 17:25:59] {2750} INFO -  at 48.3s,\testimator xgboost's best error=0.1769,\tbest estimator xgboost's best error=0.1769\n",
            "INFO:flaml.automl: at 48.3s,\testimator xgboost's best error=0.1769,\tbest estimator xgboost's best error=0.1769\n",
            "[flaml.automl: 05-02 17:25:59] {2567} INFO - iteration 164, current learner xgboost\n",
            "INFO:flaml.automl:iteration 164, current learner xgboost\n",
            "[flaml.automl: 05-02 17:25:59] {2750} INFO -  at 48.4s,\testimator xgboost's best error=0.1769,\tbest estimator xgboost's best error=0.1769\n",
            "INFO:flaml.automl: at 48.4s,\testimator xgboost's best error=0.1769,\tbest estimator xgboost's best error=0.1769\n",
            "[flaml.automl: 05-02 17:25:59] {2567} INFO - iteration 165, current learner xgboost\n",
            "INFO:flaml.automl:iteration 165, current learner xgboost\n",
            "[flaml.automl: 05-02 17:25:59] {2750} INFO -  at 48.4s,\testimator xgboost's best error=0.1769,\tbest estimator xgboost's best error=0.1769\n",
            "INFO:flaml.automl: at 48.4s,\testimator xgboost's best error=0.1769,\tbest estimator xgboost's best error=0.1769\n",
            "[flaml.automl: 05-02 17:25:59] {2567} INFO - iteration 166, current learner xgboost\n",
            "INFO:flaml.automl:iteration 166, current learner xgboost\n",
            "[flaml.automl: 05-02 17:25:59] {2750} INFO -  at 48.5s,\testimator xgboost's best error=0.1769,\tbest estimator xgboost's best error=0.1769\n",
            "INFO:flaml.automl: at 48.5s,\testimator xgboost's best error=0.1769,\tbest estimator xgboost's best error=0.1769\n",
            "[flaml.automl: 05-02 17:25:59] {2567} INFO - iteration 167, current learner xgboost\n",
            "INFO:flaml.automl:iteration 167, current learner xgboost\n",
            "[flaml.automl: 05-02 17:25:59] {2750} INFO -  at 48.6s,\testimator xgboost's best error=0.1769,\tbest estimator xgboost's best error=0.1769\n",
            "INFO:flaml.automl: at 48.6s,\testimator xgboost's best error=0.1769,\tbest estimator xgboost's best error=0.1769\n",
            "[flaml.automl: 05-02 17:25:59] {2567} INFO - iteration 168, current learner xgboost\n",
            "INFO:flaml.automl:iteration 168, current learner xgboost\n",
            "[flaml.automl: 05-02 17:25:59] {2750} INFO -  at 48.7s,\testimator xgboost's best error=0.1769,\tbest estimator xgboost's best error=0.1769\n",
            "INFO:flaml.automl: at 48.7s,\testimator xgboost's best error=0.1769,\tbest estimator xgboost's best error=0.1769\n",
            "[flaml.automl: 05-02 17:25:59] {2567} INFO - iteration 169, current learner xgboost\n",
            "INFO:flaml.automl:iteration 169, current learner xgboost\n",
            "[flaml.automl: 05-02 17:25:59] {2750} INFO -  at 48.7s,\testimator xgboost's best error=0.1769,\tbest estimator xgboost's best error=0.1769\n",
            "INFO:flaml.automl: at 48.7s,\testimator xgboost's best error=0.1769,\tbest estimator xgboost's best error=0.1769\n",
            "[flaml.automl: 05-02 17:25:59] {2567} INFO - iteration 170, current learner xgboost\n",
            "INFO:flaml.automl:iteration 170, current learner xgboost\n",
            "[flaml.automl: 05-02 17:25:59] {2750} INFO -  at 48.8s,\testimator xgboost's best error=0.1727,\tbest estimator xgboost's best error=0.1727\n",
            "INFO:flaml.automl: at 48.8s,\testimator xgboost's best error=0.1727,\tbest estimator xgboost's best error=0.1727\n",
            "[flaml.automl: 05-02 17:25:59] {2567} INFO - iteration 171, current learner xgboost\n",
            "INFO:flaml.automl:iteration 171, current learner xgboost\n",
            "[flaml.automl: 05-02 17:25:59] {2750} INFO -  at 48.9s,\testimator xgboost's best error=0.1727,\tbest estimator xgboost's best error=0.1727\n",
            "INFO:flaml.automl: at 48.9s,\testimator xgboost's best error=0.1727,\tbest estimator xgboost's best error=0.1727\n",
            "[flaml.automl: 05-02 17:25:59] {2567} INFO - iteration 172, current learner xgboost\n",
            "INFO:flaml.automl:iteration 172, current learner xgboost\n",
            "[flaml.automl: 05-02 17:25:59] {2750} INFO -  at 49.0s,\testimator xgboost's best error=0.1727,\tbest estimator xgboost's best error=0.1727\n",
            "INFO:flaml.automl: at 49.0s,\testimator xgboost's best error=0.1727,\tbest estimator xgboost's best error=0.1727\n",
            "[flaml.automl: 05-02 17:25:59] {2567} INFO - iteration 173, current learner xgboost\n",
            "INFO:flaml.automl:iteration 173, current learner xgboost\n",
            "[flaml.automl: 05-02 17:25:59] {2750} INFO -  at 49.1s,\testimator xgboost's best error=0.1727,\tbest estimator xgboost's best error=0.1727\n",
            "INFO:flaml.automl: at 49.1s,\testimator xgboost's best error=0.1727,\tbest estimator xgboost's best error=0.1727\n",
            "[flaml.automl: 05-02 17:25:59] {2567} INFO - iteration 174, current learner rf\n",
            "INFO:flaml.automl:iteration 174, current learner rf\n",
            "[flaml.automl: 05-02 17:25:59] {2750} INFO -  at 49.1s,\testimator rf's best error=0.2041,\tbest estimator xgboost's best error=0.1727\n",
            "INFO:flaml.automl: at 49.1s,\testimator rf's best error=0.2041,\tbest estimator xgboost's best error=0.1727\n",
            "[flaml.automl: 05-02 17:25:59] {2567} INFO - iteration 175, current learner xgboost\n",
            "INFO:flaml.automl:iteration 175, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:00] {2750} INFO -  at 49.2s,\testimator xgboost's best error=0.1727,\tbest estimator xgboost's best error=0.1727\n",
            "INFO:flaml.automl: at 49.2s,\testimator xgboost's best error=0.1727,\tbest estimator xgboost's best error=0.1727\n",
            "[flaml.automl: 05-02 17:26:00] {2567} INFO - iteration 176, current learner xgboost\n",
            "INFO:flaml.automl:iteration 176, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:00] {2750} INFO -  at 49.3s,\testimator xgboost's best error=0.1727,\tbest estimator xgboost's best error=0.1727\n",
            "INFO:flaml.automl: at 49.3s,\testimator xgboost's best error=0.1727,\tbest estimator xgboost's best error=0.1727\n",
            "[flaml.automl: 05-02 17:26:00] {2567} INFO - iteration 177, current learner xgboost\n",
            "INFO:flaml.automl:iteration 177, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:00] {2750} INFO -  at 49.4s,\testimator xgboost's best error=0.1727,\tbest estimator xgboost's best error=0.1727\n",
            "INFO:flaml.automl: at 49.4s,\testimator xgboost's best error=0.1727,\tbest estimator xgboost's best error=0.1727\n",
            "[flaml.automl: 05-02 17:26:00] {2567} INFO - iteration 178, current learner xgboost\n",
            "INFO:flaml.automl:iteration 178, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:00] {2750} INFO -  at 49.4s,\testimator xgboost's best error=0.1727,\tbest estimator xgboost's best error=0.1727\n",
            "INFO:flaml.automl: at 49.4s,\testimator xgboost's best error=0.1727,\tbest estimator xgboost's best error=0.1727\n",
            "[flaml.automl: 05-02 17:26:00] {2567} INFO - iteration 179, current learner xgboost\n",
            "INFO:flaml.automl:iteration 179, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:00] {2750} INFO -  at 49.5s,\testimator xgboost's best error=0.1727,\tbest estimator xgboost's best error=0.1727\n",
            "INFO:flaml.automl: at 49.5s,\testimator xgboost's best error=0.1727,\tbest estimator xgboost's best error=0.1727\n",
            "[flaml.automl: 05-02 17:26:00] {2567} INFO - iteration 180, current learner xgboost\n",
            "INFO:flaml.automl:iteration 180, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:00] {2750} INFO -  at 49.6s,\testimator xgboost's best error=0.1727,\tbest estimator xgboost's best error=0.1727\n",
            "INFO:flaml.automl: at 49.6s,\testimator xgboost's best error=0.1727,\tbest estimator xgboost's best error=0.1727\n",
            "[flaml.automl: 05-02 17:26:00] {2567} INFO - iteration 181, current learner xgboost\n",
            "INFO:flaml.automl:iteration 181, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:00] {2750} INFO -  at 49.6s,\testimator xgboost's best error=0.1727,\tbest estimator xgboost's best error=0.1727\n",
            "INFO:flaml.automl: at 49.6s,\testimator xgboost's best error=0.1727,\tbest estimator xgboost's best error=0.1727\n",
            "[flaml.automl: 05-02 17:26:00] {2567} INFO - iteration 182, current learner xgboost\n",
            "INFO:flaml.automl:iteration 182, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:00] {2750} INFO -  at 49.7s,\testimator xgboost's best error=0.1727,\tbest estimator xgboost's best error=0.1727\n",
            "INFO:flaml.automl: at 49.7s,\testimator xgboost's best error=0.1727,\tbest estimator xgboost's best error=0.1727\n",
            "[flaml.automl: 05-02 17:26:00] {2567} INFO - iteration 183, current learner xgboost\n",
            "INFO:flaml.automl:iteration 183, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:00] {2750} INFO -  at 49.8s,\testimator xgboost's best error=0.1727,\tbest estimator xgboost's best error=0.1727\n",
            "INFO:flaml.automl: at 49.8s,\testimator xgboost's best error=0.1727,\tbest estimator xgboost's best error=0.1727\n",
            "[flaml.automl: 05-02 17:26:00] {2567} INFO - iteration 184, current learner xgboost\n",
            "INFO:flaml.automl:iteration 184, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:00] {2750} INFO -  at 49.8s,\testimator xgboost's best error=0.1727,\tbest estimator xgboost's best error=0.1727\n",
            "INFO:flaml.automl: at 49.8s,\testimator xgboost's best error=0.1727,\tbest estimator xgboost's best error=0.1727\n",
            "[flaml.automl: 05-02 17:26:00] {2567} INFO - iteration 185, current learner xgboost\n",
            "INFO:flaml.automl:iteration 185, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:00] {2750} INFO -  at 49.9s,\testimator xgboost's best error=0.1727,\tbest estimator xgboost's best error=0.1727\n",
            "INFO:flaml.automl: at 49.9s,\testimator xgboost's best error=0.1727,\tbest estimator xgboost's best error=0.1727\n",
            "[flaml.automl: 05-02 17:26:00] {2567} INFO - iteration 186, current learner xgboost\n",
            "INFO:flaml.automl:iteration 186, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:00] {2750} INFO -  at 50.0s,\testimator xgboost's best error=0.1727,\tbest estimator xgboost's best error=0.1727\n",
            "INFO:flaml.automl: at 50.0s,\testimator xgboost's best error=0.1727,\tbest estimator xgboost's best error=0.1727\n",
            "[flaml.automl: 05-02 17:26:00] {2567} INFO - iteration 187, current learner xgboost\n",
            "INFO:flaml.automl:iteration 187, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:00] {2750} INFO -  at 50.1s,\testimator xgboost's best error=0.1727,\tbest estimator xgboost's best error=0.1727\n",
            "INFO:flaml.automl: at 50.1s,\testimator xgboost's best error=0.1727,\tbest estimator xgboost's best error=0.1727\n",
            "[flaml.automl: 05-02 17:26:00] {2567} INFO - iteration 188, current learner xgboost\n",
            "INFO:flaml.automl:iteration 188, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:00] {2750} INFO -  at 50.1s,\testimator xgboost's best error=0.1727,\tbest estimator xgboost's best error=0.1727\n",
            "INFO:flaml.automl: at 50.1s,\testimator xgboost's best error=0.1727,\tbest estimator xgboost's best error=0.1727\n",
            "[flaml.automl: 05-02 17:26:00] {2567} INFO - iteration 189, current learner xgboost\n",
            "INFO:flaml.automl:iteration 189, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:01] {2750} INFO -  at 50.2s,\testimator xgboost's best error=0.1727,\tbest estimator xgboost's best error=0.1727\n",
            "INFO:flaml.automl: at 50.2s,\testimator xgboost's best error=0.1727,\tbest estimator xgboost's best error=0.1727\n",
            "[flaml.automl: 05-02 17:26:01] {2567} INFO - iteration 190, current learner xgboost\n",
            "INFO:flaml.automl:iteration 190, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:01] {2750} INFO -  at 50.3s,\testimator xgboost's best error=0.1724,\tbest estimator xgboost's best error=0.1724\n",
            "INFO:flaml.automl: at 50.3s,\testimator xgboost's best error=0.1724,\tbest estimator xgboost's best error=0.1724\n",
            "[flaml.automl: 05-02 17:26:01] {2567} INFO - iteration 191, current learner xgboost\n",
            "INFO:flaml.automl:iteration 191, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:01] {2750} INFO -  at 50.4s,\testimator xgboost's best error=0.1724,\tbest estimator xgboost's best error=0.1724\n",
            "INFO:flaml.automl: at 50.4s,\testimator xgboost's best error=0.1724,\tbest estimator xgboost's best error=0.1724\n",
            "[flaml.automl: 05-02 17:26:01] {2567} INFO - iteration 192, current learner xgboost\n",
            "INFO:flaml.automl:iteration 192, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:01] {2750} INFO -  at 50.4s,\testimator xgboost's best error=0.1724,\tbest estimator xgboost's best error=0.1724\n",
            "INFO:flaml.automl: at 50.4s,\testimator xgboost's best error=0.1724,\tbest estimator xgboost's best error=0.1724\n",
            "[flaml.automl: 05-02 17:26:01] {2567} INFO - iteration 193, current learner xgboost\n",
            "INFO:flaml.automl:iteration 193, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:01] {2750} INFO -  at 50.5s,\testimator xgboost's best error=0.1724,\tbest estimator xgboost's best error=0.1724\n",
            "INFO:flaml.automl: at 50.5s,\testimator xgboost's best error=0.1724,\tbest estimator xgboost's best error=0.1724\n",
            "[flaml.automl: 05-02 17:26:01] {2567} INFO - iteration 194, current learner xgboost\n",
            "INFO:flaml.automl:iteration 194, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:01] {2750} INFO -  at 50.6s,\testimator xgboost's best error=0.1724,\tbest estimator xgboost's best error=0.1724\n",
            "INFO:flaml.automl: at 50.6s,\testimator xgboost's best error=0.1724,\tbest estimator xgboost's best error=0.1724\n",
            "[flaml.automl: 05-02 17:26:01] {2567} INFO - iteration 195, current learner xgboost\n",
            "INFO:flaml.automl:iteration 195, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:01] {2750} INFO -  at 50.7s,\testimator xgboost's best error=0.1724,\tbest estimator xgboost's best error=0.1724\n",
            "INFO:flaml.automl: at 50.7s,\testimator xgboost's best error=0.1724,\tbest estimator xgboost's best error=0.1724\n",
            "[flaml.automl: 05-02 17:26:01] {2567} INFO - iteration 196, current learner xgboost\n",
            "INFO:flaml.automl:iteration 196, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:01] {2750} INFO -  at 50.7s,\testimator xgboost's best error=0.1724,\tbest estimator xgboost's best error=0.1724\n",
            "INFO:flaml.automl: at 50.7s,\testimator xgboost's best error=0.1724,\tbest estimator xgboost's best error=0.1724\n",
            "[flaml.automl: 05-02 17:26:01] {2567} INFO - iteration 197, current learner xgboost\n",
            "INFO:flaml.automl:iteration 197, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:01] {2750} INFO -  at 50.8s,\testimator xgboost's best error=0.1724,\tbest estimator xgboost's best error=0.1724\n",
            "INFO:flaml.automl: at 50.8s,\testimator xgboost's best error=0.1724,\tbest estimator xgboost's best error=0.1724\n",
            "[flaml.automl: 05-02 17:26:01] {2567} INFO - iteration 198, current learner xgboost\n",
            "INFO:flaml.automl:iteration 198, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:01] {2750} INFO -  at 50.9s,\testimator xgboost's best error=0.1724,\tbest estimator xgboost's best error=0.1724\n",
            "INFO:flaml.automl: at 50.9s,\testimator xgboost's best error=0.1724,\tbest estimator xgboost's best error=0.1724\n",
            "[flaml.automl: 05-02 17:26:01] {2567} INFO - iteration 199, current learner xgboost\n",
            "INFO:flaml.automl:iteration 199, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:01] {2750} INFO -  at 50.9s,\testimator xgboost's best error=0.1724,\tbest estimator xgboost's best error=0.1724\n",
            "INFO:flaml.automl: at 50.9s,\testimator xgboost's best error=0.1724,\tbest estimator xgboost's best error=0.1724\n",
            "[flaml.automl: 05-02 17:26:01] {2567} INFO - iteration 200, current learner xgboost\n",
            "INFO:flaml.automl:iteration 200, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:01] {2750} INFO -  at 51.0s,\testimator xgboost's best error=0.1724,\tbest estimator xgboost's best error=0.1724\n",
            "INFO:flaml.automl: at 51.0s,\testimator xgboost's best error=0.1724,\tbest estimator xgboost's best error=0.1724\n",
            "[flaml.automl: 05-02 17:26:01] {2567} INFO - iteration 201, current learner xgboost\n",
            "INFO:flaml.automl:iteration 201, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:01] {2750} INFO -  at 51.1s,\testimator xgboost's best error=0.1724,\tbest estimator xgboost's best error=0.1724\n",
            "INFO:flaml.automl: at 51.1s,\testimator xgboost's best error=0.1724,\tbest estimator xgboost's best error=0.1724\n",
            "[flaml.automl: 05-02 17:26:01] {2567} INFO - iteration 202, current learner xgboost\n",
            "INFO:flaml.automl:iteration 202, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:01] {2750} INFO -  at 51.2s,\testimator xgboost's best error=0.1724,\tbest estimator xgboost's best error=0.1724\n",
            "INFO:flaml.automl: at 51.2s,\testimator xgboost's best error=0.1724,\tbest estimator xgboost's best error=0.1724\n",
            "[flaml.automl: 05-02 17:26:01] {2567} INFO - iteration 203, current learner xgboost\n",
            "INFO:flaml.automl:iteration 203, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:02] {2750} INFO -  at 51.2s,\testimator xgboost's best error=0.1724,\tbest estimator xgboost's best error=0.1724\n",
            "INFO:flaml.automl: at 51.2s,\testimator xgboost's best error=0.1724,\tbest estimator xgboost's best error=0.1724\n",
            "[flaml.automl: 05-02 17:26:02] {2567} INFO - iteration 204, current learner xgboost\n",
            "INFO:flaml.automl:iteration 204, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:02] {2750} INFO -  at 51.3s,\testimator xgboost's best error=0.1724,\tbest estimator xgboost's best error=0.1724\n",
            "INFO:flaml.automl: at 51.3s,\testimator xgboost's best error=0.1724,\tbest estimator xgboost's best error=0.1724\n",
            "[flaml.automl: 05-02 17:26:02] {2567} INFO - iteration 205, current learner xgboost\n",
            "INFO:flaml.automl:iteration 205, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:02] {2750} INFO -  at 51.4s,\testimator xgboost's best error=0.1724,\tbest estimator xgboost's best error=0.1724\n",
            "INFO:flaml.automl: at 51.4s,\testimator xgboost's best error=0.1724,\tbest estimator xgboost's best error=0.1724\n",
            "[flaml.automl: 05-02 17:26:02] {2567} INFO - iteration 206, current learner xgboost\n",
            "INFO:flaml.automl:iteration 206, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:02] {2750} INFO -  at 51.5s,\testimator xgboost's best error=0.1724,\tbest estimator xgboost's best error=0.1724\n",
            "INFO:flaml.automl: at 51.5s,\testimator xgboost's best error=0.1724,\tbest estimator xgboost's best error=0.1724\n",
            "[flaml.automl: 05-02 17:26:02] {2567} INFO - iteration 207, current learner xgboost\n",
            "INFO:flaml.automl:iteration 207, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:02] {2750} INFO -  at 51.5s,\testimator xgboost's best error=0.1724,\tbest estimator xgboost's best error=0.1724\n",
            "INFO:flaml.automl: at 51.5s,\testimator xgboost's best error=0.1724,\tbest estimator xgboost's best error=0.1724\n",
            "[flaml.automl: 05-02 17:26:02] {2567} INFO - iteration 208, current learner xgboost\n",
            "INFO:flaml.automl:iteration 208, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:02] {2750} INFO -  at 51.6s,\testimator xgboost's best error=0.1724,\tbest estimator xgboost's best error=0.1724\n",
            "INFO:flaml.automl: at 51.6s,\testimator xgboost's best error=0.1724,\tbest estimator xgboost's best error=0.1724\n",
            "[flaml.automl: 05-02 17:26:02] {2567} INFO - iteration 209, current learner xgboost\n",
            "INFO:flaml.automl:iteration 209, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:02] {2750} INFO -  at 51.7s,\testimator xgboost's best error=0.1724,\tbest estimator xgboost's best error=0.1724\n",
            "INFO:flaml.automl: at 51.7s,\testimator xgboost's best error=0.1724,\tbest estimator xgboost's best error=0.1724\n",
            "[flaml.automl: 05-02 17:26:02] {2567} INFO - iteration 210, current learner xgboost\n",
            "INFO:flaml.automl:iteration 210, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:02] {2750} INFO -  at 51.8s,\testimator xgboost's best error=0.1724,\tbest estimator xgboost's best error=0.1724\n",
            "INFO:flaml.automl: at 51.8s,\testimator xgboost's best error=0.1724,\tbest estimator xgboost's best error=0.1724\n",
            "[flaml.automl: 05-02 17:26:02] {2567} INFO - iteration 211, current learner xgboost\n",
            "INFO:flaml.automl:iteration 211, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:02] {2750} INFO -  at 51.8s,\testimator xgboost's best error=0.1724,\tbest estimator xgboost's best error=0.1724\n",
            "INFO:flaml.automl: at 51.8s,\testimator xgboost's best error=0.1724,\tbest estimator xgboost's best error=0.1724\n",
            "[flaml.automl: 05-02 17:26:02] {2567} INFO - iteration 212, current learner xgboost\n",
            "INFO:flaml.automl:iteration 212, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:02] {2750} INFO -  at 51.9s,\testimator xgboost's best error=0.1724,\tbest estimator xgboost's best error=0.1724\n",
            "INFO:flaml.automl: at 51.9s,\testimator xgboost's best error=0.1724,\tbest estimator xgboost's best error=0.1724\n",
            "[flaml.automl: 05-02 17:26:02] {2567} INFO - iteration 213, current learner xgboost\n",
            "INFO:flaml.automl:iteration 213, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:02] {2750} INFO -  at 52.0s,\testimator xgboost's best error=0.1724,\tbest estimator xgboost's best error=0.1724\n",
            "INFO:flaml.automl: at 52.0s,\testimator xgboost's best error=0.1724,\tbest estimator xgboost's best error=0.1724\n",
            "[flaml.automl: 05-02 17:26:02] {2567} INFO - iteration 214, current learner xgboost\n",
            "INFO:flaml.automl:iteration 214, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:02] {2750} INFO -  at 52.0s,\testimator xgboost's best error=0.1724,\tbest estimator xgboost's best error=0.1724\n",
            "INFO:flaml.automl: at 52.0s,\testimator xgboost's best error=0.1724,\tbest estimator xgboost's best error=0.1724\n",
            "[flaml.automl: 05-02 17:26:02] {2567} INFO - iteration 215, current learner xgboost\n",
            "INFO:flaml.automl:iteration 215, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:02] {2750} INFO -  at 52.1s,\testimator xgboost's best error=0.1724,\tbest estimator xgboost's best error=0.1724\n",
            "INFO:flaml.automl: at 52.1s,\testimator xgboost's best error=0.1724,\tbest estimator xgboost's best error=0.1724\n",
            "[flaml.automl: 05-02 17:26:02] {2567} INFO - iteration 216, current learner xgboost\n",
            "INFO:flaml.automl:iteration 216, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:02] {2750} INFO -  at 52.2s,\testimator xgboost's best error=0.1724,\tbest estimator xgboost's best error=0.1724\n",
            "INFO:flaml.automl: at 52.2s,\testimator xgboost's best error=0.1724,\tbest estimator xgboost's best error=0.1724\n",
            "[flaml.automl: 05-02 17:26:02] {2567} INFO - iteration 217, current learner xgboost\n",
            "INFO:flaml.automl:iteration 217, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:03] {2750} INFO -  at 52.3s,\testimator xgboost's best error=0.1724,\tbest estimator xgboost's best error=0.1724\n",
            "INFO:flaml.automl: at 52.3s,\testimator xgboost's best error=0.1724,\tbest estimator xgboost's best error=0.1724\n",
            "[flaml.automl: 05-02 17:26:03] {2567} INFO - iteration 218, current learner xgboost\n",
            "INFO:flaml.automl:iteration 218, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:03] {2750} INFO -  at 52.4s,\testimator xgboost's best error=0.1724,\tbest estimator xgboost's best error=0.1724\n",
            "INFO:flaml.automl: at 52.4s,\testimator xgboost's best error=0.1724,\tbest estimator xgboost's best error=0.1724\n",
            "[flaml.automl: 05-02 17:26:03] {2567} INFO - iteration 219, current learner xgboost\n",
            "INFO:flaml.automl:iteration 219, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:03] {2750} INFO -  at 52.4s,\testimator xgboost's best error=0.1724,\tbest estimator xgboost's best error=0.1724\n",
            "INFO:flaml.automl: at 52.4s,\testimator xgboost's best error=0.1724,\tbest estimator xgboost's best error=0.1724\n",
            "[flaml.automl: 05-02 17:26:03] {2567} INFO - iteration 220, current learner xgboost\n",
            "INFO:flaml.automl:iteration 220, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:03] {2750} INFO -  at 52.5s,\testimator xgboost's best error=0.1724,\tbest estimator xgboost's best error=0.1724\n",
            "INFO:flaml.automl: at 52.5s,\testimator xgboost's best error=0.1724,\tbest estimator xgboost's best error=0.1724\n",
            "[flaml.automl: 05-02 17:26:03] {2567} INFO - iteration 221, current learner xgboost\n",
            "INFO:flaml.automl:iteration 221, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:03] {2750} INFO -  at 52.6s,\testimator xgboost's best error=0.1724,\tbest estimator xgboost's best error=0.1724\n",
            "INFO:flaml.automl: at 52.6s,\testimator xgboost's best error=0.1724,\tbest estimator xgboost's best error=0.1724\n",
            "[flaml.automl: 05-02 17:26:03] {2567} INFO - iteration 222, current learner xgboost\n",
            "INFO:flaml.automl:iteration 222, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:03] {2750} INFO -  at 52.6s,\testimator xgboost's best error=0.1724,\tbest estimator xgboost's best error=0.1724\n",
            "INFO:flaml.automl: at 52.6s,\testimator xgboost's best error=0.1724,\tbest estimator xgboost's best error=0.1724\n",
            "[flaml.automl: 05-02 17:26:03] {2567} INFO - iteration 223, current learner xgboost\n",
            "INFO:flaml.automl:iteration 223, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:03] {2750} INFO -  at 52.7s,\testimator xgboost's best error=0.1724,\tbest estimator xgboost's best error=0.1724\n",
            "INFO:flaml.automl: at 52.7s,\testimator xgboost's best error=0.1724,\tbest estimator xgboost's best error=0.1724\n",
            "[flaml.automl: 05-02 17:26:03] {2567} INFO - iteration 224, current learner xgboost\n",
            "INFO:flaml.automl:iteration 224, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:03] {2750} INFO -  at 52.8s,\testimator xgboost's best error=0.1724,\tbest estimator xgboost's best error=0.1724\n",
            "INFO:flaml.automl: at 52.8s,\testimator xgboost's best error=0.1724,\tbest estimator xgboost's best error=0.1724\n",
            "[flaml.automl: 05-02 17:26:03] {2567} INFO - iteration 225, current learner xgboost\n",
            "INFO:flaml.automl:iteration 225, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:03] {2750} INFO -  at 52.8s,\testimator xgboost's best error=0.1724,\tbest estimator xgboost's best error=0.1724\n",
            "INFO:flaml.automl: at 52.8s,\testimator xgboost's best error=0.1724,\tbest estimator xgboost's best error=0.1724\n",
            "[flaml.automl: 05-02 17:26:03] {2567} INFO - iteration 226, current learner xgboost\n",
            "INFO:flaml.automl:iteration 226, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:03] {2750} INFO -  at 52.9s,\testimator xgboost's best error=0.1724,\tbest estimator xgboost's best error=0.1724\n",
            "INFO:flaml.automl: at 52.9s,\testimator xgboost's best error=0.1724,\tbest estimator xgboost's best error=0.1724\n",
            "[flaml.automl: 05-02 17:26:03] {2567} INFO - iteration 227, current learner xgboost\n",
            "INFO:flaml.automl:iteration 227, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:03] {2750} INFO -  at 53.0s,\testimator xgboost's best error=0.1724,\tbest estimator xgboost's best error=0.1724\n",
            "INFO:flaml.automl: at 53.0s,\testimator xgboost's best error=0.1724,\tbest estimator xgboost's best error=0.1724\n",
            "[flaml.automl: 05-02 17:26:03] {2567} INFO - iteration 228, current learner xgboost\n",
            "INFO:flaml.automl:iteration 228, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:03] {2750} INFO -  at 53.1s,\testimator xgboost's best error=0.1724,\tbest estimator xgboost's best error=0.1724\n",
            "INFO:flaml.automl: at 53.1s,\testimator xgboost's best error=0.1724,\tbest estimator xgboost's best error=0.1724\n",
            "[flaml.automl: 05-02 17:26:03] {2567} INFO - iteration 229, current learner xgboost\n",
            "INFO:flaml.automl:iteration 229, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:03] {2750} INFO -  at 53.1s,\testimator xgboost's best error=0.1724,\tbest estimator xgboost's best error=0.1724\n",
            "INFO:flaml.automl: at 53.1s,\testimator xgboost's best error=0.1724,\tbest estimator xgboost's best error=0.1724\n",
            "[flaml.automl: 05-02 17:26:03] {2567} INFO - iteration 230, current learner xgboost\n",
            "INFO:flaml.automl:iteration 230, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:04] {2750} INFO -  at 53.2s,\testimator xgboost's best error=0.1724,\tbest estimator xgboost's best error=0.1724\n",
            "INFO:flaml.automl: at 53.2s,\testimator xgboost's best error=0.1724,\tbest estimator xgboost's best error=0.1724\n",
            "[flaml.automl: 05-02 17:26:04] {2567} INFO - iteration 231, current learner xgboost\n",
            "INFO:flaml.automl:iteration 231, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:04] {2750} INFO -  at 53.3s,\testimator xgboost's best error=0.1724,\tbest estimator xgboost's best error=0.1724\n",
            "INFO:flaml.automl: at 53.3s,\testimator xgboost's best error=0.1724,\tbest estimator xgboost's best error=0.1724\n",
            "[flaml.automl: 05-02 17:26:04] {2567} INFO - iteration 232, current learner xgboost\n",
            "INFO:flaml.automl:iteration 232, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:04] {2750} INFO -  at 53.4s,\testimator xgboost's best error=0.1724,\tbest estimator xgboost's best error=0.1724\n",
            "INFO:flaml.automl: at 53.4s,\testimator xgboost's best error=0.1724,\tbest estimator xgboost's best error=0.1724\n",
            "[flaml.automl: 05-02 17:26:04] {2567} INFO - iteration 233, current learner xgboost\n",
            "INFO:flaml.automl:iteration 233, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:04] {2750} INFO -  at 53.4s,\testimator xgboost's best error=0.1724,\tbest estimator xgboost's best error=0.1724\n",
            "INFO:flaml.automl: at 53.4s,\testimator xgboost's best error=0.1724,\tbest estimator xgboost's best error=0.1724\n",
            "[flaml.automl: 05-02 17:26:04] {2567} INFO - iteration 234, current learner xgboost\n",
            "INFO:flaml.automl:iteration 234, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:04] {2750} INFO -  at 53.5s,\testimator xgboost's best error=0.1724,\tbest estimator xgboost's best error=0.1724\n",
            "INFO:flaml.automl: at 53.5s,\testimator xgboost's best error=0.1724,\tbest estimator xgboost's best error=0.1724\n",
            "[flaml.automl: 05-02 17:26:04] {2567} INFO - iteration 235, current learner xgboost\n",
            "INFO:flaml.automl:iteration 235, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:04] {2750} INFO -  at 53.6s,\testimator xgboost's best error=0.1724,\tbest estimator xgboost's best error=0.1724\n",
            "INFO:flaml.automl: at 53.6s,\testimator xgboost's best error=0.1724,\tbest estimator xgboost's best error=0.1724\n",
            "[flaml.automl: 05-02 17:26:04] {2567} INFO - iteration 236, current learner xgboost\n",
            "INFO:flaml.automl:iteration 236, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:04] {2750} INFO -  at 53.6s,\testimator xgboost's best error=0.1724,\tbest estimator xgboost's best error=0.1724\n",
            "INFO:flaml.automl: at 53.6s,\testimator xgboost's best error=0.1724,\tbest estimator xgboost's best error=0.1724\n",
            "[flaml.automl: 05-02 17:26:04] {2567} INFO - iteration 237, current learner xgboost\n",
            "INFO:flaml.automl:iteration 237, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:04] {2750} INFO -  at 53.7s,\testimator xgboost's best error=0.1724,\tbest estimator xgboost's best error=0.1724\n",
            "INFO:flaml.automl: at 53.7s,\testimator xgboost's best error=0.1724,\tbest estimator xgboost's best error=0.1724\n",
            "[flaml.automl: 05-02 17:26:04] {2567} INFO - iteration 238, current learner xgboost\n",
            "INFO:flaml.automl:iteration 238, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:04] {2750} INFO -  at 53.8s,\testimator xgboost's best error=0.1724,\tbest estimator xgboost's best error=0.1724\n",
            "INFO:flaml.automl: at 53.8s,\testimator xgboost's best error=0.1724,\tbest estimator xgboost's best error=0.1724\n",
            "[flaml.automl: 05-02 17:26:04] {2567} INFO - iteration 239, current learner xgboost\n",
            "INFO:flaml.automl:iteration 239, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:04] {2750} INFO -  at 53.8s,\testimator xgboost's best error=0.1724,\tbest estimator xgboost's best error=0.1724\n",
            "INFO:flaml.automl: at 53.8s,\testimator xgboost's best error=0.1724,\tbest estimator xgboost's best error=0.1724\n",
            "[flaml.automl: 05-02 17:26:04] {2567} INFO - iteration 240, current learner xgboost\n",
            "INFO:flaml.automl:iteration 240, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:04] {2750} INFO -  at 53.9s,\testimator xgboost's best error=0.1724,\tbest estimator xgboost's best error=0.1724\n",
            "INFO:flaml.automl: at 53.9s,\testimator xgboost's best error=0.1724,\tbest estimator xgboost's best error=0.1724\n",
            "[flaml.automl: 05-02 17:26:04] {2567} INFO - iteration 241, current learner xgboost\n",
            "INFO:flaml.automl:iteration 241, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:04] {2750} INFO -  at 54.0s,\testimator xgboost's best error=0.1724,\tbest estimator xgboost's best error=0.1724\n",
            "INFO:flaml.automl: at 54.0s,\testimator xgboost's best error=0.1724,\tbest estimator xgboost's best error=0.1724\n",
            "[flaml.automl: 05-02 17:26:04] {2567} INFO - iteration 242, current learner xgboost\n",
            "INFO:flaml.automl:iteration 242, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:04] {2750} INFO -  at 54.1s,\testimator xgboost's best error=0.1724,\tbest estimator xgboost's best error=0.1724\n",
            "INFO:flaml.automl: at 54.1s,\testimator xgboost's best error=0.1724,\tbest estimator xgboost's best error=0.1724\n",
            "[flaml.automl: 05-02 17:26:04] {2567} INFO - iteration 243, current learner xgboost\n",
            "INFO:flaml.automl:iteration 243, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:04] {2750} INFO -  at 54.1s,\testimator xgboost's best error=0.1724,\tbest estimator xgboost's best error=0.1724\n",
            "INFO:flaml.automl: at 54.1s,\testimator xgboost's best error=0.1724,\tbest estimator xgboost's best error=0.1724\n",
            "[flaml.automl: 05-02 17:26:04] {2567} INFO - iteration 244, current learner xgboost\n",
            "INFO:flaml.automl:iteration 244, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:05] {2750} INFO -  at 54.2s,\testimator xgboost's best error=0.1724,\tbest estimator xgboost's best error=0.1724\n",
            "INFO:flaml.automl: at 54.2s,\testimator xgboost's best error=0.1724,\tbest estimator xgboost's best error=0.1724\n",
            "[flaml.automl: 05-02 17:26:05] {2567} INFO - iteration 245, current learner xgboost\n",
            "INFO:flaml.automl:iteration 245, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:05] {2750} INFO -  at 54.3s,\testimator xgboost's best error=0.1724,\tbest estimator xgboost's best error=0.1724\n",
            "INFO:flaml.automl: at 54.3s,\testimator xgboost's best error=0.1724,\tbest estimator xgboost's best error=0.1724\n",
            "[flaml.automl: 05-02 17:26:05] {2567} INFO - iteration 246, current learner xgboost\n",
            "INFO:flaml.automl:iteration 246, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:05] {2750} INFO -  at 54.4s,\testimator xgboost's best error=0.1724,\tbest estimator xgboost's best error=0.1724\n",
            "INFO:flaml.automl: at 54.4s,\testimator xgboost's best error=0.1724,\tbest estimator xgboost's best error=0.1724\n",
            "[flaml.automl: 05-02 17:26:05] {2567} INFO - iteration 247, current learner xgboost\n",
            "INFO:flaml.automl:iteration 247, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:05] {2750} INFO -  at 54.5s,\testimator xgboost's best error=0.1724,\tbest estimator xgboost's best error=0.1724\n",
            "INFO:flaml.automl: at 54.5s,\testimator xgboost's best error=0.1724,\tbest estimator xgboost's best error=0.1724\n",
            "[flaml.automl: 05-02 17:26:05] {2567} INFO - iteration 248, current learner xgboost\n",
            "INFO:flaml.automl:iteration 248, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:05] {2750} INFO -  at 54.5s,\testimator xgboost's best error=0.1724,\tbest estimator xgboost's best error=0.1724\n",
            "INFO:flaml.automl: at 54.5s,\testimator xgboost's best error=0.1724,\tbest estimator xgboost's best error=0.1724\n",
            "[flaml.automl: 05-02 17:26:05] {2567} INFO - iteration 249, current learner xgboost\n",
            "INFO:flaml.automl:iteration 249, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:05] {2750} INFO -  at 54.6s,\testimator xgboost's best error=0.1724,\tbest estimator xgboost's best error=0.1724\n",
            "INFO:flaml.automl: at 54.6s,\testimator xgboost's best error=0.1724,\tbest estimator xgboost's best error=0.1724\n",
            "[flaml.automl: 05-02 17:26:05] {2567} INFO - iteration 250, current learner xgboost\n",
            "INFO:flaml.automl:iteration 250, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:05] {2750} INFO -  at 54.7s,\testimator xgboost's best error=0.1724,\tbest estimator xgboost's best error=0.1724\n",
            "INFO:flaml.automl: at 54.7s,\testimator xgboost's best error=0.1724,\tbest estimator xgboost's best error=0.1724\n",
            "[flaml.automl: 05-02 17:26:05] {2567} INFO - iteration 251, current learner xgboost\n",
            "INFO:flaml.automl:iteration 251, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:05] {2750} INFO -  at 54.7s,\testimator xgboost's best error=0.1724,\tbest estimator xgboost's best error=0.1724\n",
            "INFO:flaml.automl: at 54.7s,\testimator xgboost's best error=0.1724,\tbest estimator xgboost's best error=0.1724\n",
            "[flaml.automl: 05-02 17:26:05] {2567} INFO - iteration 252, current learner xgboost\n",
            "INFO:flaml.automl:iteration 252, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:05] {2750} INFO -  at 54.8s,\testimator xgboost's best error=0.1724,\tbest estimator xgboost's best error=0.1724\n",
            "INFO:flaml.automl: at 54.8s,\testimator xgboost's best error=0.1724,\tbest estimator xgboost's best error=0.1724\n",
            "[flaml.automl: 05-02 17:26:05] {2567} INFO - iteration 253, current learner xgboost\n",
            "INFO:flaml.automl:iteration 253, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:05] {2750} INFO -  at 54.9s,\testimator xgboost's best error=0.1724,\tbest estimator xgboost's best error=0.1724\n",
            "INFO:flaml.automl: at 54.9s,\testimator xgboost's best error=0.1724,\tbest estimator xgboost's best error=0.1724\n",
            "[flaml.automl: 05-02 17:26:05] {2567} INFO - iteration 254, current learner xgboost\n",
            "INFO:flaml.automl:iteration 254, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:05] {2750} INFO -  at 55.0s,\testimator xgboost's best error=0.1724,\tbest estimator xgboost's best error=0.1724\n",
            "INFO:flaml.automl: at 55.0s,\testimator xgboost's best error=0.1724,\tbest estimator xgboost's best error=0.1724\n",
            "[flaml.automl: 05-02 17:26:05] {2567} INFO - iteration 255, current learner xgboost\n",
            "INFO:flaml.automl:iteration 255, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:05] {2750} INFO -  at 55.0s,\testimator xgboost's best error=0.1724,\tbest estimator xgboost's best error=0.1724\n",
            "INFO:flaml.automl: at 55.0s,\testimator xgboost's best error=0.1724,\tbest estimator xgboost's best error=0.1724\n",
            "[flaml.automl: 05-02 17:26:05] {2567} INFO - iteration 256, current learner xgboost\n",
            "INFO:flaml.automl:iteration 256, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:05] {2750} INFO -  at 55.1s,\testimator xgboost's best error=0.1724,\tbest estimator xgboost's best error=0.1724\n",
            "INFO:flaml.automl: at 55.1s,\testimator xgboost's best error=0.1724,\tbest estimator xgboost's best error=0.1724\n",
            "[flaml.automl: 05-02 17:26:05] {2567} INFO - iteration 257, current learner xgboost\n",
            "INFO:flaml.automl:iteration 257, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:05] {2750} INFO -  at 55.2s,\testimator xgboost's best error=0.1724,\tbest estimator xgboost's best error=0.1724\n",
            "INFO:flaml.automl: at 55.2s,\testimator xgboost's best error=0.1724,\tbest estimator xgboost's best error=0.1724\n",
            "[flaml.automl: 05-02 17:26:05] {2567} INFO - iteration 258, current learner xgboost\n",
            "INFO:flaml.automl:iteration 258, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:06] {2750} INFO -  at 55.3s,\testimator xgboost's best error=0.1724,\tbest estimator xgboost's best error=0.1724\n",
            "INFO:flaml.automl: at 55.3s,\testimator xgboost's best error=0.1724,\tbest estimator xgboost's best error=0.1724\n",
            "[flaml.automl: 05-02 17:26:06] {2567} INFO - iteration 259, current learner xgboost\n",
            "INFO:flaml.automl:iteration 259, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:06] {2750} INFO -  at 55.3s,\testimator xgboost's best error=0.1724,\tbest estimator xgboost's best error=0.1724\n",
            "INFO:flaml.automl: at 55.3s,\testimator xgboost's best error=0.1724,\tbest estimator xgboost's best error=0.1724\n",
            "[flaml.automl: 05-02 17:26:06] {2567} INFO - iteration 260, current learner xgboost\n",
            "INFO:flaml.automl:iteration 260, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:06] {2750} INFO -  at 55.4s,\testimator xgboost's best error=0.1724,\tbest estimator xgboost's best error=0.1724\n",
            "INFO:flaml.automl: at 55.4s,\testimator xgboost's best error=0.1724,\tbest estimator xgboost's best error=0.1724\n",
            "[flaml.automl: 05-02 17:26:06] {2567} INFO - iteration 261, current learner xgboost\n",
            "INFO:flaml.automl:iteration 261, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:06] {2750} INFO -  at 55.5s,\testimator xgboost's best error=0.1724,\tbest estimator xgboost's best error=0.1724\n",
            "INFO:flaml.automl: at 55.5s,\testimator xgboost's best error=0.1724,\tbest estimator xgboost's best error=0.1724\n",
            "[flaml.automl: 05-02 17:26:06] {2567} INFO - iteration 262, current learner xgboost\n",
            "INFO:flaml.automl:iteration 262, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:06] {2750} INFO -  at 55.6s,\testimator xgboost's best error=0.1724,\tbest estimator xgboost's best error=0.1724\n",
            "INFO:flaml.automl: at 55.6s,\testimator xgboost's best error=0.1724,\tbest estimator xgboost's best error=0.1724\n",
            "[flaml.automl: 05-02 17:26:06] {2567} INFO - iteration 263, current learner xgboost\n",
            "INFO:flaml.automl:iteration 263, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:06] {2750} INFO -  at 55.6s,\testimator xgboost's best error=0.1724,\tbest estimator xgboost's best error=0.1724\n",
            "INFO:flaml.automl: at 55.6s,\testimator xgboost's best error=0.1724,\tbest estimator xgboost's best error=0.1724\n",
            "[flaml.automl: 05-02 17:26:06] {2567} INFO - iteration 264, current learner xgboost\n",
            "INFO:flaml.automl:iteration 264, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:06] {2750} INFO -  at 55.7s,\testimator xgboost's best error=0.1724,\tbest estimator xgboost's best error=0.1724\n",
            "INFO:flaml.automl: at 55.7s,\testimator xgboost's best error=0.1724,\tbest estimator xgboost's best error=0.1724\n",
            "[flaml.automl: 05-02 17:26:06] {2567} INFO - iteration 265, current learner xgboost\n",
            "INFO:flaml.automl:iteration 265, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:06] {2750} INFO -  at 55.8s,\testimator xgboost's best error=0.1724,\tbest estimator xgboost's best error=0.1724\n",
            "INFO:flaml.automl: at 55.8s,\testimator xgboost's best error=0.1724,\tbest estimator xgboost's best error=0.1724\n",
            "[flaml.automl: 05-02 17:26:06] {2567} INFO - iteration 266, current learner xgboost\n",
            "INFO:flaml.automl:iteration 266, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:06] {2750} INFO -  at 55.8s,\testimator xgboost's best error=0.1724,\tbest estimator xgboost's best error=0.1724\n",
            "INFO:flaml.automl: at 55.8s,\testimator xgboost's best error=0.1724,\tbest estimator xgboost's best error=0.1724\n",
            "[flaml.automl: 05-02 17:26:06] {2567} INFO - iteration 267, current learner xgboost\n",
            "INFO:flaml.automl:iteration 267, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:06] {2750} INFO -  at 55.9s,\testimator xgboost's best error=0.1724,\tbest estimator xgboost's best error=0.1724\n",
            "INFO:flaml.automl: at 55.9s,\testimator xgboost's best error=0.1724,\tbest estimator xgboost's best error=0.1724\n",
            "[flaml.automl: 05-02 17:26:06] {2567} INFO - iteration 268, current learner xgboost\n",
            "INFO:flaml.automl:iteration 268, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:06] {2750} INFO -  at 56.0s,\testimator xgboost's best error=0.1724,\tbest estimator xgboost's best error=0.1724\n",
            "INFO:flaml.automl: at 56.0s,\testimator xgboost's best error=0.1724,\tbest estimator xgboost's best error=0.1724\n",
            "[flaml.automl: 05-02 17:26:06] {2567} INFO - iteration 269, current learner xgboost\n",
            "INFO:flaml.automl:iteration 269, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:06] {2750} INFO -  at 56.0s,\testimator xgboost's best error=0.1724,\tbest estimator xgboost's best error=0.1724\n",
            "INFO:flaml.automl: at 56.0s,\testimator xgboost's best error=0.1724,\tbest estimator xgboost's best error=0.1724\n",
            "[flaml.automl: 05-02 17:26:06] {2567} INFO - iteration 270, current learner xgboost\n",
            "INFO:flaml.automl:iteration 270, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:06] {2750} INFO -  at 56.1s,\testimator xgboost's best error=0.1724,\tbest estimator xgboost's best error=0.1724\n",
            "INFO:flaml.automl: at 56.1s,\testimator xgboost's best error=0.1724,\tbest estimator xgboost's best error=0.1724\n",
            "[flaml.automl: 05-02 17:26:06] {2567} INFO - iteration 271, current learner xgboost\n",
            "INFO:flaml.automl:iteration 271, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:06] {2750} INFO -  at 56.2s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "INFO:flaml.automl: at 56.2s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "[flaml.automl: 05-02 17:26:06] {2567} INFO - iteration 272, current learner xgboost\n",
            "INFO:flaml.automl:iteration 272, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:07] {2750} INFO -  at 56.3s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "INFO:flaml.automl: at 56.3s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "[flaml.automl: 05-02 17:26:07] {2567} INFO - iteration 273, current learner xgboost\n",
            "INFO:flaml.automl:iteration 273, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:07] {2750} INFO -  at 56.3s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "INFO:flaml.automl: at 56.3s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "[flaml.automl: 05-02 17:26:07] {2567} INFO - iteration 274, current learner xgboost\n",
            "INFO:flaml.automl:iteration 274, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:07] {2750} INFO -  at 56.4s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "INFO:flaml.automl: at 56.4s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "[flaml.automl: 05-02 17:26:07] {2567} INFO - iteration 275, current learner xgboost\n",
            "INFO:flaml.automl:iteration 275, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:07] {2750} INFO -  at 56.5s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "INFO:flaml.automl: at 56.5s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "[flaml.automl: 05-02 17:26:07] {2567} INFO - iteration 276, current learner xgboost\n",
            "INFO:flaml.automl:iteration 276, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:07] {2750} INFO -  at 56.6s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "INFO:flaml.automl: at 56.6s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "[flaml.automl: 05-02 17:26:07] {2567} INFO - iteration 277, current learner xgboost\n",
            "INFO:flaml.automl:iteration 277, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:07] {2750} INFO -  at 56.6s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "INFO:flaml.automl: at 56.6s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "[flaml.automl: 05-02 17:26:07] {2567} INFO - iteration 278, current learner xgboost\n",
            "INFO:flaml.automl:iteration 278, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:07] {2750} INFO -  at 56.7s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "INFO:flaml.automl: at 56.7s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "[flaml.automl: 05-02 17:26:07] {2567} INFO - iteration 279, current learner xgboost\n",
            "INFO:flaml.automl:iteration 279, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:07] {2750} INFO -  at 56.8s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "INFO:flaml.automl: at 56.8s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "[flaml.automl: 05-02 17:26:07] {2567} INFO - iteration 280, current learner xgboost\n",
            "INFO:flaml.automl:iteration 280, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:07] {2750} INFO -  at 56.9s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "INFO:flaml.automl: at 56.9s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "[flaml.automl: 05-02 17:26:07] {2567} INFO - iteration 281, current learner xgboost\n",
            "INFO:flaml.automl:iteration 281, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:07] {2750} INFO -  at 56.9s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "INFO:flaml.automl: at 56.9s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "[flaml.automl: 05-02 17:26:07] {2567} INFO - iteration 282, current learner xgboost\n",
            "INFO:flaml.automl:iteration 282, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:07] {2750} INFO -  at 57.0s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "INFO:flaml.automl: at 57.0s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "[flaml.automl: 05-02 17:26:07] {2567} INFO - iteration 283, current learner xgboost\n",
            "INFO:flaml.automl:iteration 283, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:07] {2750} INFO -  at 57.1s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "INFO:flaml.automl: at 57.1s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "[flaml.automl: 05-02 17:26:07] {2567} INFO - iteration 284, current learner xgboost\n",
            "INFO:flaml.automl:iteration 284, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:07] {2750} INFO -  at 57.2s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "INFO:flaml.automl: at 57.2s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "[flaml.automl: 05-02 17:26:07] {2567} INFO - iteration 285, current learner xgboost\n",
            "INFO:flaml.automl:iteration 285, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:08] {2750} INFO -  at 57.2s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "INFO:flaml.automl: at 57.2s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "[flaml.automl: 05-02 17:26:08] {2567} INFO - iteration 286, current learner xgboost\n",
            "INFO:flaml.automl:iteration 286, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:08] {2750} INFO -  at 57.3s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "INFO:flaml.automl: at 57.3s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "[flaml.automl: 05-02 17:26:08] {2567} INFO - iteration 287, current learner xgboost\n",
            "INFO:flaml.automl:iteration 287, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:08] {2750} INFO -  at 57.4s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "INFO:flaml.automl: at 57.4s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "[flaml.automl: 05-02 17:26:08] {2567} INFO - iteration 288, current learner xgboost\n",
            "INFO:flaml.automl:iteration 288, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:08] {2750} INFO -  at 57.4s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "INFO:flaml.automl: at 57.4s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "[flaml.automl: 05-02 17:26:08] {2567} INFO - iteration 289, current learner xgboost\n",
            "INFO:flaml.automl:iteration 289, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:08] {2750} INFO -  at 57.5s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "INFO:flaml.automl: at 57.5s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "[flaml.automl: 05-02 17:26:08] {2567} INFO - iteration 290, current learner xgboost\n",
            "INFO:flaml.automl:iteration 290, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:08] {2750} INFO -  at 57.6s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "INFO:flaml.automl: at 57.6s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "[flaml.automl: 05-02 17:26:08] {2567} INFO - iteration 291, current learner xgboost\n",
            "INFO:flaml.automl:iteration 291, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:08] {2750} INFO -  at 57.7s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "INFO:flaml.automl: at 57.7s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "[flaml.automl: 05-02 17:26:08] {2567} INFO - iteration 292, current learner xgboost\n",
            "INFO:flaml.automl:iteration 292, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:08] {2750} INFO -  at 57.7s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "INFO:flaml.automl: at 57.7s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "[flaml.automl: 05-02 17:26:08] {2567} INFO - iteration 293, current learner xgboost\n",
            "INFO:flaml.automl:iteration 293, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:08] {2750} INFO -  at 57.8s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "INFO:flaml.automl: at 57.8s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "[flaml.automl: 05-02 17:26:08] {2567} INFO - iteration 294, current learner xgboost\n",
            "INFO:flaml.automl:iteration 294, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:08] {2750} INFO -  at 57.9s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "INFO:flaml.automl: at 57.9s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "[flaml.automl: 05-02 17:26:08] {2567} INFO - iteration 295, current learner xgboost\n",
            "INFO:flaml.automl:iteration 295, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:08] {2750} INFO -  at 57.9s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "INFO:flaml.automl: at 57.9s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "[flaml.automl: 05-02 17:26:08] {2567} INFO - iteration 296, current learner xgboost\n",
            "INFO:flaml.automl:iteration 296, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:08] {2750} INFO -  at 58.0s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "INFO:flaml.automl: at 58.0s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "[flaml.automl: 05-02 17:26:08] {2567} INFO - iteration 297, current learner xgboost\n",
            "INFO:flaml.automl:iteration 297, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:08] {2750} INFO -  at 58.1s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "INFO:flaml.automl: at 58.1s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "[flaml.automl: 05-02 17:26:08] {2567} INFO - iteration 298, current learner xgboost\n",
            "INFO:flaml.automl:iteration 298, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:08] {2750} INFO -  at 58.2s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "INFO:flaml.automl: at 58.2s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "[flaml.automl: 05-02 17:26:08] {2567} INFO - iteration 299, current learner xgboost\n",
            "INFO:flaml.automl:iteration 299, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:09] {2750} INFO -  at 58.2s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "INFO:flaml.automl: at 58.2s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "[flaml.automl: 05-02 17:26:09] {2567} INFO - iteration 300, current learner xgboost\n",
            "INFO:flaml.automl:iteration 300, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:09] {2750} INFO -  at 58.3s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "INFO:flaml.automl: at 58.3s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "[flaml.automl: 05-02 17:26:09] {2567} INFO - iteration 301, current learner rf\n",
            "INFO:flaml.automl:iteration 301, current learner rf\n",
            "[flaml.automl: 05-02 17:26:10] {2750} INFO -  at 59.8s,\testimator rf's best error=0.2041,\tbest estimator xgboost's best error=0.1691\n",
            "INFO:flaml.automl: at 59.8s,\testimator rf's best error=0.2041,\tbest estimator xgboost's best error=0.1691\n",
            "[flaml.automl: 05-02 17:26:10] {2567} INFO - iteration 302, current learner xgboost\n",
            "INFO:flaml.automl:iteration 302, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:10] {2750} INFO -  at 59.9s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "INFO:flaml.automl: at 59.9s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "[flaml.automl: 05-02 17:26:10] {2567} INFO - iteration 303, current learner xgboost\n",
            "INFO:flaml.automl:iteration 303, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:10] {2750} INFO -  at 60.0s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "INFO:flaml.automl: at 60.0s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "[flaml.automl: 05-02 17:26:10] {2567} INFO - iteration 304, current learner xgboost\n",
            "INFO:flaml.automl:iteration 304, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:10] {2750} INFO -  at 60.1s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "INFO:flaml.automl: at 60.1s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "[flaml.automl: 05-02 17:26:10] {2567} INFO - iteration 305, current learner xgboost\n",
            "INFO:flaml.automl:iteration 305, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:10] {2750} INFO -  at 60.1s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "INFO:flaml.automl: at 60.1s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "[flaml.automl: 05-02 17:26:10] {2567} INFO - iteration 306, current learner xgboost\n",
            "INFO:flaml.automl:iteration 306, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:11] {2750} INFO -  at 60.2s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "INFO:flaml.automl: at 60.2s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "[flaml.automl: 05-02 17:26:11] {2567} INFO - iteration 307, current learner xgboost\n",
            "INFO:flaml.automl:iteration 307, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:11] {2750} INFO -  at 60.3s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "INFO:flaml.automl: at 60.3s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "[flaml.automl: 05-02 17:26:11] {2567} INFO - iteration 308, current learner xgboost\n",
            "INFO:flaml.automl:iteration 308, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:11] {2750} INFO -  at 60.3s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "INFO:flaml.automl: at 60.3s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "[flaml.automl: 05-02 17:26:11] {2567} INFO - iteration 309, current learner xgboost\n",
            "INFO:flaml.automl:iteration 309, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:11] {2750} INFO -  at 60.4s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "INFO:flaml.automl: at 60.4s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "[flaml.automl: 05-02 17:26:11] {2567} INFO - iteration 310, current learner xgboost\n",
            "INFO:flaml.automl:iteration 310, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:11] {2750} INFO -  at 60.5s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "INFO:flaml.automl: at 60.5s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "[flaml.automl: 05-02 17:26:11] {2567} INFO - iteration 311, current learner xgboost\n",
            "INFO:flaml.automl:iteration 311, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:11] {2750} INFO -  at 60.5s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "INFO:flaml.automl: at 60.5s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "[flaml.automl: 05-02 17:26:11] {2567} INFO - iteration 312, current learner xgboost\n",
            "INFO:flaml.automl:iteration 312, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:11] {2750} INFO -  at 60.6s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "INFO:flaml.automl: at 60.6s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "[flaml.automl: 05-02 17:26:11] {2567} INFO - iteration 313, current learner xgboost\n",
            "INFO:flaml.automl:iteration 313, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:11] {2750} INFO -  at 60.7s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "INFO:flaml.automl: at 60.7s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "[flaml.automl: 05-02 17:26:11] {2567} INFO - iteration 314, current learner xgboost\n",
            "INFO:flaml.automl:iteration 314, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:11] {2750} INFO -  at 60.8s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "INFO:flaml.automl: at 60.8s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "[flaml.automl: 05-02 17:26:11] {2567} INFO - iteration 315, current learner xgboost\n",
            "INFO:flaml.automl:iteration 315, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:11] {2750} INFO -  at 60.8s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "INFO:flaml.automl: at 60.8s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "[flaml.automl: 05-02 17:26:11] {2567} INFO - iteration 316, current learner xgboost\n",
            "INFO:flaml.automl:iteration 316, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:11] {2750} INFO -  at 60.9s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "INFO:flaml.automl: at 60.9s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "[flaml.automl: 05-02 17:26:11] {2567} INFO - iteration 317, current learner xgboost\n",
            "INFO:flaml.automl:iteration 317, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:11] {2750} INFO -  at 61.0s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "INFO:flaml.automl: at 61.0s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "[flaml.automl: 05-02 17:26:11] {2567} INFO - iteration 318, current learner xgboost\n",
            "INFO:flaml.automl:iteration 318, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:11] {2750} INFO -  at 61.1s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "INFO:flaml.automl: at 61.1s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "[flaml.automl: 05-02 17:26:11] {2567} INFO - iteration 319, current learner xgboost\n",
            "INFO:flaml.automl:iteration 319, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:11] {2750} INFO -  at 61.1s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "INFO:flaml.automl: at 61.1s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "[flaml.automl: 05-02 17:26:11] {2567} INFO - iteration 320, current learner xgboost\n",
            "INFO:flaml.automl:iteration 320, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:12] {2750} INFO -  at 61.2s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "INFO:flaml.automl: at 61.2s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "[flaml.automl: 05-02 17:26:12] {2567} INFO - iteration 321, current learner xgboost\n",
            "INFO:flaml.automl:iteration 321, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:12] {2750} INFO -  at 61.3s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "INFO:flaml.automl: at 61.3s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "[flaml.automl: 05-02 17:26:12] {2567} INFO - iteration 322, current learner xgboost\n",
            "INFO:flaml.automl:iteration 322, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:12] {2750} INFO -  at 61.4s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "INFO:flaml.automl: at 61.4s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "[flaml.automl: 05-02 17:26:12] {2567} INFO - iteration 323, current learner xgboost\n",
            "INFO:flaml.automl:iteration 323, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:12] {2750} INFO -  at 61.4s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "INFO:flaml.automl: at 61.4s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "[flaml.automl: 05-02 17:26:12] {2567} INFO - iteration 324, current learner xgboost\n",
            "INFO:flaml.automl:iteration 324, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:12] {2750} INFO -  at 61.5s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "INFO:flaml.automl: at 61.5s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "[flaml.automl: 05-02 17:26:12] {2567} INFO - iteration 325, current learner xgboost\n",
            "INFO:flaml.automl:iteration 325, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:12] {2750} INFO -  at 61.6s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "INFO:flaml.automl: at 61.6s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "[flaml.automl: 05-02 17:26:12] {2567} INFO - iteration 326, current learner xgboost\n",
            "INFO:flaml.automl:iteration 326, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:12] {2750} INFO -  at 61.7s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "INFO:flaml.automl: at 61.7s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "[flaml.automl: 05-02 17:26:12] {2567} INFO - iteration 327, current learner xgboost\n",
            "INFO:flaml.automl:iteration 327, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:12] {2750} INFO -  at 61.8s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "INFO:flaml.automl: at 61.8s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "[flaml.automl: 05-02 17:26:12] {2567} INFO - iteration 328, current learner xgboost\n",
            "INFO:flaml.automl:iteration 328, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:12] {2750} INFO -  at 61.8s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "INFO:flaml.automl: at 61.8s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "[flaml.automl: 05-02 17:26:12] {2567} INFO - iteration 329, current learner xgboost\n",
            "INFO:flaml.automl:iteration 329, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:12] {2750} INFO -  at 61.9s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "INFO:flaml.automl: at 61.9s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "[flaml.automl: 05-02 17:26:12] {2567} INFO - iteration 330, current learner xgboost\n",
            "INFO:flaml.automl:iteration 330, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:12] {2750} INFO -  at 62.0s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "INFO:flaml.automl: at 62.0s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "[flaml.automl: 05-02 17:26:12] {2567} INFO - iteration 331, current learner xgboost\n",
            "INFO:flaml.automl:iteration 331, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:12] {2750} INFO -  at 62.1s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "INFO:flaml.automl: at 62.1s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "[flaml.automl: 05-02 17:26:12] {2567} INFO - iteration 332, current learner xgboost\n",
            "INFO:flaml.automl:iteration 332, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:12] {2750} INFO -  at 62.1s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "INFO:flaml.automl: at 62.1s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "[flaml.automl: 05-02 17:26:12] {2567} INFO - iteration 333, current learner xgboost\n",
            "INFO:flaml.automl:iteration 333, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:13] {2750} INFO -  at 62.2s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "INFO:flaml.automl: at 62.2s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "[flaml.automl: 05-02 17:26:13] {2567} INFO - iteration 334, current learner xgboost\n",
            "INFO:flaml.automl:iteration 334, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:13] {2750} INFO -  at 62.3s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "INFO:flaml.automl: at 62.3s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "[flaml.automl: 05-02 17:26:13] {2567} INFO - iteration 335, current learner xgboost\n",
            "INFO:flaml.automl:iteration 335, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:13] {2750} INFO -  at 62.4s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "INFO:flaml.automl: at 62.4s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "[flaml.automl: 05-02 17:26:13] {2567} INFO - iteration 336, current learner xgboost\n",
            "INFO:flaml.automl:iteration 336, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:13] {2750} INFO -  at 62.4s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "INFO:flaml.automl: at 62.4s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "[flaml.automl: 05-02 17:26:13] {2567} INFO - iteration 337, current learner xgboost\n",
            "INFO:flaml.automl:iteration 337, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:13] {2750} INFO -  at 62.5s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "INFO:flaml.automl: at 62.5s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "[flaml.automl: 05-02 17:26:13] {2567} INFO - iteration 338, current learner xgboost\n",
            "INFO:flaml.automl:iteration 338, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:13] {2750} INFO -  at 62.6s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "INFO:flaml.automl: at 62.6s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "[flaml.automl: 05-02 17:26:13] {2567} INFO - iteration 339, current learner xgboost\n",
            "INFO:flaml.automl:iteration 339, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:13] {2750} INFO -  at 62.7s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "INFO:flaml.automl: at 62.7s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "[flaml.automl: 05-02 17:26:13] {2567} INFO - iteration 340, current learner xgboost\n",
            "INFO:flaml.automl:iteration 340, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:13] {2750} INFO -  at 62.8s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "INFO:flaml.automl: at 62.8s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "[flaml.automl: 05-02 17:26:13] {2567} INFO - iteration 341, current learner xgboost\n",
            "INFO:flaml.automl:iteration 341, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:13] {2750} INFO -  at 62.8s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "INFO:flaml.automl: at 62.8s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "[flaml.automl: 05-02 17:26:13] {2567} INFO - iteration 342, current learner xgboost\n",
            "INFO:flaml.automl:iteration 342, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:13] {2750} INFO -  at 62.9s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "INFO:flaml.automl: at 62.9s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "[flaml.automl: 05-02 17:26:13] {2567} INFO - iteration 343, current learner xgboost\n",
            "INFO:flaml.automl:iteration 343, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:13] {2750} INFO -  at 63.0s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "INFO:flaml.automl: at 63.0s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "[flaml.automl: 05-02 17:26:13] {2567} INFO - iteration 344, current learner xgboost\n",
            "INFO:flaml.automl:iteration 344, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:13] {2750} INFO -  at 63.1s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "INFO:flaml.automl: at 63.1s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "[flaml.automl: 05-02 17:26:13] {2567} INFO - iteration 345, current learner xgboost\n",
            "INFO:flaml.automl:iteration 345, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:13] {2750} INFO -  at 63.1s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "INFO:flaml.automl: at 63.1s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "[flaml.automl: 05-02 17:26:13] {2567} INFO - iteration 346, current learner xgboost\n",
            "INFO:flaml.automl:iteration 346, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:14] {2750} INFO -  at 63.2s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "INFO:flaml.automl: at 63.2s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "[flaml.automl: 05-02 17:26:14] {2567} INFO - iteration 347, current learner xgboost\n",
            "INFO:flaml.automl:iteration 347, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:14] {2750} INFO -  at 63.3s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "INFO:flaml.automl: at 63.3s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "[flaml.automl: 05-02 17:26:14] {2567} INFO - iteration 348, current learner xgboost\n",
            "INFO:flaml.automl:iteration 348, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:14] {2750} INFO -  at 63.4s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "INFO:flaml.automl: at 63.4s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "[flaml.automl: 05-02 17:26:14] {2567} INFO - iteration 349, current learner xgboost\n",
            "INFO:flaml.automl:iteration 349, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:14] {2750} INFO -  at 63.4s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "INFO:flaml.automl: at 63.4s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "[flaml.automl: 05-02 17:26:14] {2567} INFO - iteration 350, current learner xgboost\n",
            "INFO:flaml.automl:iteration 350, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:14] {2750} INFO -  at 63.5s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "INFO:flaml.automl: at 63.5s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "[flaml.automl: 05-02 17:26:14] {2567} INFO - iteration 351, current learner xgboost\n",
            "INFO:flaml.automl:iteration 351, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:14] {2750} INFO -  at 63.6s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "INFO:flaml.automl: at 63.6s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "[flaml.automl: 05-02 17:26:14] {2567} INFO - iteration 352, current learner xgboost\n",
            "INFO:flaml.automl:iteration 352, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:14] {2750} INFO -  at 63.7s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "INFO:flaml.automl: at 63.7s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "[flaml.automl: 05-02 17:26:14] {2567} INFO - iteration 353, current learner xgboost\n",
            "INFO:flaml.automl:iteration 353, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:14] {2750} INFO -  at 63.7s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "INFO:flaml.automl: at 63.7s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "[flaml.automl: 05-02 17:26:14] {2567} INFO - iteration 354, current learner xgboost\n",
            "INFO:flaml.automl:iteration 354, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:14] {2750} INFO -  at 63.8s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "INFO:flaml.automl: at 63.8s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "[flaml.automl: 05-02 17:26:14] {2567} INFO - iteration 355, current learner xgboost\n",
            "INFO:flaml.automl:iteration 355, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:14] {2750} INFO -  at 63.9s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "INFO:flaml.automl: at 63.9s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "[flaml.automl: 05-02 17:26:14] {2567} INFO - iteration 356, current learner xgboost\n",
            "INFO:flaml.automl:iteration 356, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:14] {2750} INFO -  at 64.0s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "INFO:flaml.automl: at 64.0s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "[flaml.automl: 05-02 17:26:14] {2567} INFO - iteration 357, current learner xgboost\n",
            "INFO:flaml.automl:iteration 357, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:14] {2750} INFO -  at 64.1s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "INFO:flaml.automl: at 64.1s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "[flaml.automl: 05-02 17:26:14] {2567} INFO - iteration 358, current learner xgboost\n",
            "INFO:flaml.automl:iteration 358, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:14] {2750} INFO -  at 64.2s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "INFO:flaml.automl: at 64.2s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "[flaml.automl: 05-02 17:26:14] {2567} INFO - iteration 359, current learner xgboost\n",
            "INFO:flaml.automl:iteration 359, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:15] {2750} INFO -  at 64.2s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "INFO:flaml.automl: at 64.2s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "[flaml.automl: 05-02 17:26:15] {2567} INFO - iteration 360, current learner xgboost\n",
            "INFO:flaml.automl:iteration 360, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:15] {2750} INFO -  at 64.3s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "INFO:flaml.automl: at 64.3s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "[flaml.automl: 05-02 17:26:15] {2567} INFO - iteration 361, current learner xgboost\n",
            "INFO:flaml.automl:iteration 361, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:15] {2750} INFO -  at 64.4s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "INFO:flaml.automl: at 64.4s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "[flaml.automl: 05-02 17:26:15] {2567} INFO - iteration 362, current learner rf\n",
            "INFO:flaml.automl:iteration 362, current learner rf\n",
            "[flaml.automl: 05-02 17:26:15] {2750} INFO -  at 64.5s,\testimator rf's best error=0.2041,\tbest estimator xgboost's best error=0.1691\n",
            "INFO:flaml.automl: at 64.5s,\testimator rf's best error=0.2041,\tbest estimator xgboost's best error=0.1691\n",
            "[flaml.automl: 05-02 17:26:15] {2567} INFO - iteration 363, current learner xgboost\n",
            "INFO:flaml.automl:iteration 363, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:15] {2750} INFO -  at 64.5s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "INFO:flaml.automl: at 64.5s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "[flaml.automl: 05-02 17:26:15] {2567} INFO - iteration 364, current learner xgboost\n",
            "INFO:flaml.automl:iteration 364, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:15] {2750} INFO -  at 64.6s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "INFO:flaml.automl: at 64.6s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "[flaml.automl: 05-02 17:26:15] {2567} INFO - iteration 365, current learner xgboost\n",
            "INFO:flaml.automl:iteration 365, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:15] {2750} INFO -  at 64.7s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "INFO:flaml.automl: at 64.7s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "[flaml.automl: 05-02 17:26:15] {2567} INFO - iteration 366, current learner xgboost\n",
            "INFO:flaml.automl:iteration 366, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:15] {2750} INFO -  at 64.8s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "INFO:flaml.automl: at 64.8s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "[flaml.automl: 05-02 17:26:15] {2567} INFO - iteration 367, current learner rf\n",
            "INFO:flaml.automl:iteration 367, current learner rf\n",
            "[flaml.automl: 05-02 17:26:16] {2750} INFO -  at 66.0s,\testimator rf's best error=0.2041,\tbest estimator xgboost's best error=0.1691\n",
            "INFO:flaml.automl: at 66.0s,\testimator rf's best error=0.2041,\tbest estimator xgboost's best error=0.1691\n",
            "[flaml.automl: 05-02 17:26:16] {2567} INFO - iteration 368, current learner xgboost\n",
            "INFO:flaml.automl:iteration 368, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:16] {2750} INFO -  at 66.0s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "INFO:flaml.automl: at 66.0s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "[flaml.automl: 05-02 17:26:16] {2567} INFO - iteration 369, current learner rf\n",
            "INFO:flaml.automl:iteration 369, current learner rf\n",
            "[flaml.automl: 05-02 17:26:16] {2750} INFO -  at 66.1s,\testimator rf's best error=0.2041,\tbest estimator xgboost's best error=0.1691\n",
            "INFO:flaml.automl: at 66.1s,\testimator rf's best error=0.2041,\tbest estimator xgboost's best error=0.1691\n",
            "[flaml.automl: 05-02 17:26:16] {2567} INFO - iteration 370, current learner xgboost\n",
            "INFO:flaml.automl:iteration 370, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:17] {2750} INFO -  at 66.2s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "INFO:flaml.automl: at 66.2s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "[flaml.automl: 05-02 17:26:17] {2567} INFO - iteration 371, current learner xgboost\n",
            "INFO:flaml.automl:iteration 371, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:17] {2750} INFO -  at 66.3s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "INFO:flaml.automl: at 66.3s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "[flaml.automl: 05-02 17:26:17] {2567} INFO - iteration 372, current learner xgboost\n",
            "INFO:flaml.automl:iteration 372, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:17] {2750} INFO -  at 66.3s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "INFO:flaml.automl: at 66.3s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "[flaml.automl: 05-02 17:26:17] {2567} INFO - iteration 373, current learner xgboost\n",
            "INFO:flaml.automl:iteration 373, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:17] {2750} INFO -  at 66.4s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "INFO:flaml.automl: at 66.4s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "[flaml.automl: 05-02 17:26:17] {2567} INFO - iteration 374, current learner xgboost\n",
            "INFO:flaml.automl:iteration 374, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:17] {2750} INFO -  at 66.5s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "INFO:flaml.automl: at 66.5s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "[flaml.automl: 05-02 17:26:17] {2567} INFO - iteration 375, current learner xgboost\n",
            "INFO:flaml.automl:iteration 375, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:17] {2750} INFO -  at 66.6s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "INFO:flaml.automl: at 66.6s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "[flaml.automl: 05-02 17:26:17] {2567} INFO - iteration 376, current learner xgboost\n",
            "INFO:flaml.automl:iteration 376, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:17] {2750} INFO -  at 66.6s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "INFO:flaml.automl: at 66.6s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "[flaml.automl: 05-02 17:26:17] {2567} INFO - iteration 377, current learner xgboost\n",
            "INFO:flaml.automl:iteration 377, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:17] {2750} INFO -  at 66.7s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "INFO:flaml.automl: at 66.7s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "[flaml.automl: 05-02 17:26:17] {2567} INFO - iteration 378, current learner xgboost\n",
            "INFO:flaml.automl:iteration 378, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:17] {2750} INFO -  at 66.8s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "INFO:flaml.automl: at 66.8s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "[flaml.automl: 05-02 17:26:17] {2567} INFO - iteration 379, current learner xgboost\n",
            "INFO:flaml.automl:iteration 379, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:17] {2750} INFO -  at 66.8s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "INFO:flaml.automl: at 66.8s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "[flaml.automl: 05-02 17:26:17] {2567} INFO - iteration 380, current learner xgboost\n",
            "INFO:flaml.automl:iteration 380, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:17] {2750} INFO -  at 66.9s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "INFO:flaml.automl: at 66.9s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "[flaml.automl: 05-02 17:26:17] {2567} INFO - iteration 381, current learner xgboost\n",
            "INFO:flaml.automl:iteration 381, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:17] {2750} INFO -  at 67.0s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "INFO:flaml.automl: at 67.0s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "[flaml.automl: 05-02 17:26:17] {2567} INFO - iteration 382, current learner xgboost\n",
            "INFO:flaml.automl:iteration 382, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:17] {2750} INFO -  at 67.1s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "INFO:flaml.automl: at 67.1s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "[flaml.automl: 05-02 17:26:17] {2567} INFO - iteration 383, current learner xgboost\n",
            "INFO:flaml.automl:iteration 383, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:17] {2750} INFO -  at 67.2s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "INFO:flaml.automl: at 67.2s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "[flaml.automl: 05-02 17:26:17] {2567} INFO - iteration 384, current learner xgboost\n",
            "INFO:flaml.automl:iteration 384, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:18] {2750} INFO -  at 67.2s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "INFO:flaml.automl: at 67.2s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "[flaml.automl: 05-02 17:26:18] {2567} INFO - iteration 385, current learner rf\n",
            "INFO:flaml.automl:iteration 385, current learner rf\n",
            "[flaml.automl: 05-02 17:26:19] {2750} INFO -  at 68.9s,\testimator rf's best error=0.2041,\tbest estimator xgboost's best error=0.1691\n",
            "INFO:flaml.automl: at 68.9s,\testimator rf's best error=0.2041,\tbest estimator xgboost's best error=0.1691\n",
            "[flaml.automl: 05-02 17:26:19] {2567} INFO - iteration 386, current learner xgboost\n",
            "INFO:flaml.automl:iteration 386, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:19] {2750} INFO -  at 69.0s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "INFO:flaml.automl: at 69.0s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "[flaml.automl: 05-02 17:26:19] {2567} INFO - iteration 387, current learner xgboost\n",
            "INFO:flaml.automl:iteration 387, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:19] {2750} INFO -  at 69.1s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "INFO:flaml.automl: at 69.1s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "[flaml.automl: 05-02 17:26:19] {2567} INFO - iteration 388, current learner xgboost\n",
            "INFO:flaml.automl:iteration 388, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:20] {2750} INFO -  at 69.2s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "INFO:flaml.automl: at 69.2s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "[flaml.automl: 05-02 17:26:20] {2567} INFO - iteration 389, current learner xgboost\n",
            "INFO:flaml.automl:iteration 389, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:20] {2750} INFO -  at 69.3s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "INFO:flaml.automl: at 69.3s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "[flaml.automl: 05-02 17:26:20] {2567} INFO - iteration 390, current learner xgboost\n",
            "INFO:flaml.automl:iteration 390, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:20] {2750} INFO -  at 69.4s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "INFO:flaml.automl: at 69.4s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "[flaml.automl: 05-02 17:26:20] {2567} INFO - iteration 391, current learner xgboost\n",
            "INFO:flaml.automl:iteration 391, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:20] {2750} INFO -  at 69.4s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "INFO:flaml.automl: at 69.4s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "[flaml.automl: 05-02 17:26:20] {2567} INFO - iteration 392, current learner xgboost\n",
            "INFO:flaml.automl:iteration 392, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:20] {2750} INFO -  at 69.5s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "INFO:flaml.automl: at 69.5s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "[flaml.automl: 05-02 17:26:20] {2567} INFO - iteration 393, current learner xgboost\n",
            "INFO:flaml.automl:iteration 393, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:20] {2750} INFO -  at 69.6s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "INFO:flaml.automl: at 69.6s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "[flaml.automl: 05-02 17:26:20] {2567} INFO - iteration 394, current learner xgboost\n",
            "INFO:flaml.automl:iteration 394, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:20] {2750} INFO -  at 69.7s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "INFO:flaml.automl: at 69.7s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "[flaml.automl: 05-02 17:26:20] {2567} INFO - iteration 395, current learner xgboost\n",
            "INFO:flaml.automl:iteration 395, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:20] {2750} INFO -  at 69.7s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "INFO:flaml.automl: at 69.7s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "[flaml.automl: 05-02 17:26:20] {2567} INFO - iteration 396, current learner xgboost\n",
            "INFO:flaml.automl:iteration 396, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:20] {2750} INFO -  at 69.8s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "INFO:flaml.automl: at 69.8s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "[flaml.automl: 05-02 17:26:20] {2567} INFO - iteration 397, current learner xgboost\n",
            "INFO:flaml.automl:iteration 397, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:20] {2750} INFO -  at 69.9s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "INFO:flaml.automl: at 69.9s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "[flaml.automl: 05-02 17:26:20] {2567} INFO - iteration 398, current learner xgboost\n",
            "INFO:flaml.automl:iteration 398, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:20] {2750} INFO -  at 69.9s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "INFO:flaml.automl: at 69.9s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "[flaml.automl: 05-02 17:26:20] {2567} INFO - iteration 399, current learner xgboost\n",
            "INFO:flaml.automl:iteration 399, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:20] {2750} INFO -  at 70.0s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "INFO:flaml.automl: at 70.0s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "[flaml.automl: 05-02 17:26:20] {2567} INFO - iteration 400, current learner xgboost\n",
            "INFO:flaml.automl:iteration 400, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:20] {2750} INFO -  at 70.1s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "INFO:flaml.automl: at 70.1s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "[flaml.automl: 05-02 17:26:20] {2567} INFO - iteration 401, current learner xgboost\n",
            "INFO:flaml.automl:iteration 401, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:20] {2750} INFO -  at 70.2s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "INFO:flaml.automl: at 70.2s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "[flaml.automl: 05-02 17:26:20] {2567} INFO - iteration 402, current learner xgboost\n",
            "INFO:flaml.automl:iteration 402, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:21] {2750} INFO -  at 70.2s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "INFO:flaml.automl: at 70.2s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "[flaml.automl: 05-02 17:26:21] {2567} INFO - iteration 403, current learner xgboost\n",
            "INFO:flaml.automl:iteration 403, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:21] {2750} INFO -  at 70.3s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "INFO:flaml.automl: at 70.3s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "[flaml.automl: 05-02 17:26:21] {2567} INFO - iteration 404, current learner xgboost\n",
            "INFO:flaml.automl:iteration 404, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:21] {2750} INFO -  at 70.4s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "INFO:flaml.automl: at 70.4s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "[flaml.automl: 05-02 17:26:21] {2567} INFO - iteration 405, current learner xgboost\n",
            "INFO:flaml.automl:iteration 405, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:21] {2750} INFO -  at 70.5s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "INFO:flaml.automl: at 70.5s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "[flaml.automl: 05-02 17:26:21] {2567} INFO - iteration 406, current learner xgboost\n",
            "INFO:flaml.automl:iteration 406, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:21] {2750} INFO -  at 70.6s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "INFO:flaml.automl: at 70.6s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "[flaml.automl: 05-02 17:26:21] {2567} INFO - iteration 407, current learner xgboost\n",
            "INFO:flaml.automl:iteration 407, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:21] {2750} INFO -  at 70.6s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "INFO:flaml.automl: at 70.6s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "[flaml.automl: 05-02 17:26:21] {2567} INFO - iteration 408, current learner xgboost\n",
            "INFO:flaml.automl:iteration 408, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:21] {2750} INFO -  at 70.7s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "INFO:flaml.automl: at 70.7s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "[flaml.automl: 05-02 17:26:21] {2567} INFO - iteration 409, current learner xgboost\n",
            "INFO:flaml.automl:iteration 409, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:21] {2750} INFO -  at 70.8s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "INFO:flaml.automl: at 70.8s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "[flaml.automl: 05-02 17:26:21] {2567} INFO - iteration 410, current learner xgboost\n",
            "INFO:flaml.automl:iteration 410, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:21] {2750} INFO -  at 70.9s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "INFO:flaml.automl: at 70.9s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "[flaml.automl: 05-02 17:26:21] {2567} INFO - iteration 411, current learner xgboost\n",
            "INFO:flaml.automl:iteration 411, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:21] {2750} INFO -  at 71.0s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "INFO:flaml.automl: at 71.0s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "[flaml.automl: 05-02 17:26:21] {2567} INFO - iteration 412, current learner xgboost\n",
            "INFO:flaml.automl:iteration 412, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:21] {2750} INFO -  at 71.1s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "INFO:flaml.automl: at 71.1s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "[flaml.automl: 05-02 17:26:21] {2567} INFO - iteration 413, current learner xgboost\n",
            "INFO:flaml.automl:iteration 413, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:21] {2750} INFO -  at 71.1s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "INFO:flaml.automl: at 71.1s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "[flaml.automl: 05-02 17:26:21] {2567} INFO - iteration 414, current learner xgboost\n",
            "INFO:flaml.automl:iteration 414, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:22] {2750} INFO -  at 71.2s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "INFO:flaml.automl: at 71.2s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "[flaml.automl: 05-02 17:26:22] {2567} INFO - iteration 415, current learner xgboost\n",
            "INFO:flaml.automl:iteration 415, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:22] {2750} INFO -  at 71.3s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "INFO:flaml.automl: at 71.3s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "[flaml.automl: 05-02 17:26:22] {2567} INFO - iteration 416, current learner xgboost\n",
            "INFO:flaml.automl:iteration 416, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:22] {2750} INFO -  at 71.3s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "INFO:flaml.automl: at 71.3s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "[flaml.automl: 05-02 17:26:22] {2567} INFO - iteration 417, current learner xgboost\n",
            "INFO:flaml.automl:iteration 417, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:22] {2750} INFO -  at 71.4s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "INFO:flaml.automl: at 71.4s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "[flaml.automl: 05-02 17:26:22] {2567} INFO - iteration 418, current learner xgboost\n",
            "INFO:flaml.automl:iteration 418, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:22] {2750} INFO -  at 71.5s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "INFO:flaml.automl: at 71.5s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "[flaml.automl: 05-02 17:26:22] {2567} INFO - iteration 419, current learner xgboost\n",
            "INFO:flaml.automl:iteration 419, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:22] {2750} INFO -  at 71.6s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "INFO:flaml.automl: at 71.6s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "[flaml.automl: 05-02 17:26:22] {2567} INFO - iteration 420, current learner xgboost\n",
            "INFO:flaml.automl:iteration 420, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:22] {2750} INFO -  at 71.6s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "INFO:flaml.automl: at 71.6s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "[flaml.automl: 05-02 17:26:22] {2567} INFO - iteration 421, current learner xgboost\n",
            "INFO:flaml.automl:iteration 421, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:22] {2750} INFO -  at 71.7s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "INFO:flaml.automl: at 71.7s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "[flaml.automl: 05-02 17:26:22] {2567} INFO - iteration 422, current learner xgboost\n",
            "INFO:flaml.automl:iteration 422, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:22] {2750} INFO -  at 71.8s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "INFO:flaml.automl: at 71.8s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "[flaml.automl: 05-02 17:26:22] {2567} INFO - iteration 423, current learner xgboost\n",
            "INFO:flaml.automl:iteration 423, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:22] {2750} INFO -  at 71.9s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "INFO:flaml.automl: at 71.9s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "[flaml.automl: 05-02 17:26:22] {2567} INFO - iteration 424, current learner xgboost\n",
            "INFO:flaml.automl:iteration 424, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:22] {2750} INFO -  at 71.9s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "INFO:flaml.automl: at 71.9s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "[flaml.automl: 05-02 17:26:22] {2567} INFO - iteration 425, current learner xgboost\n",
            "INFO:flaml.automl:iteration 425, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:22] {2750} INFO -  at 72.0s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "INFO:flaml.automl: at 72.0s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "[flaml.automl: 05-02 17:26:22] {2567} INFO - iteration 426, current learner xgboost\n",
            "INFO:flaml.automl:iteration 426, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:22] {2750} INFO -  at 72.1s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "INFO:flaml.automl: at 72.1s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "[flaml.automl: 05-02 17:26:22] {2567} INFO - iteration 427, current learner xgboost\n",
            "INFO:flaml.automl:iteration 427, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:22] {2750} INFO -  at 72.2s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "INFO:flaml.automl: at 72.2s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "[flaml.automl: 05-02 17:26:22] {2567} INFO - iteration 428, current learner xgboost\n",
            "INFO:flaml.automl:iteration 428, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:23] {2750} INFO -  at 72.3s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "INFO:flaml.automl: at 72.3s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "[flaml.automl: 05-02 17:26:23] {2567} INFO - iteration 429, current learner xgboost\n",
            "INFO:flaml.automl:iteration 429, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:23] {2750} INFO -  at 72.3s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "INFO:flaml.automl: at 72.3s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "[flaml.automl: 05-02 17:26:23] {2567} INFO - iteration 430, current learner xgboost\n",
            "INFO:flaml.automl:iteration 430, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:23] {2750} INFO -  at 72.4s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "INFO:flaml.automl: at 72.4s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "[flaml.automl: 05-02 17:26:23] {2567} INFO - iteration 431, current learner xgboost\n",
            "INFO:flaml.automl:iteration 431, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:23] {2750} INFO -  at 72.5s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "INFO:flaml.automl: at 72.5s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "[flaml.automl: 05-02 17:26:23] {2567} INFO - iteration 432, current learner xgboost\n",
            "INFO:flaml.automl:iteration 432, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:23] {2750} INFO -  at 72.5s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "INFO:flaml.automl: at 72.5s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "[flaml.automl: 05-02 17:26:23] {2567} INFO - iteration 433, current learner xgboost\n",
            "INFO:flaml.automl:iteration 433, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:23] {2750} INFO -  at 72.6s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "INFO:flaml.automl: at 72.6s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "[flaml.automl: 05-02 17:26:23] {2567} INFO - iteration 434, current learner xgboost\n",
            "INFO:flaml.automl:iteration 434, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:23] {2750} INFO -  at 72.7s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "INFO:flaml.automl: at 72.7s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "[flaml.automl: 05-02 17:26:23] {2567} INFO - iteration 435, current learner xgboost\n",
            "INFO:flaml.automl:iteration 435, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:23] {2750} INFO -  at 72.8s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "INFO:flaml.automl: at 72.8s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "[flaml.automl: 05-02 17:26:23] {2567} INFO - iteration 436, current learner xgboost\n",
            "INFO:flaml.automl:iteration 436, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:23] {2750} INFO -  at 72.8s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "INFO:flaml.automl: at 72.8s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "[flaml.automl: 05-02 17:26:23] {2567} INFO - iteration 437, current learner xgboost\n",
            "INFO:flaml.automl:iteration 437, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:23] {2750} INFO -  at 72.9s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "INFO:flaml.automl: at 72.9s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "[flaml.automl: 05-02 17:26:23] {2567} INFO - iteration 438, current learner xgboost\n",
            "INFO:flaml.automl:iteration 438, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:23] {2750} INFO -  at 73.0s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "INFO:flaml.automl: at 73.0s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "[flaml.automl: 05-02 17:26:23] {2567} INFO - iteration 439, current learner xgboost\n",
            "INFO:flaml.automl:iteration 439, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:23] {2750} INFO -  at 73.1s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "INFO:flaml.automl: at 73.1s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "[flaml.automl: 05-02 17:26:23] {2567} INFO - iteration 440, current learner xgboost\n",
            "INFO:flaml.automl:iteration 440, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:23] {2750} INFO -  at 73.1s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "INFO:flaml.automl: at 73.1s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "[flaml.automl: 05-02 17:26:23] {2567} INFO - iteration 441, current learner xgboost\n",
            "INFO:flaml.automl:iteration 441, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:24] {2750} INFO -  at 73.2s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "INFO:flaml.automl: at 73.2s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "[flaml.automl: 05-02 17:26:24] {2567} INFO - iteration 442, current learner xgboost\n",
            "INFO:flaml.automl:iteration 442, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:24] {2750} INFO -  at 73.3s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "INFO:flaml.automl: at 73.3s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "[flaml.automl: 05-02 17:26:24] {2567} INFO - iteration 443, current learner xgboost\n",
            "INFO:flaml.automl:iteration 443, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:24] {2750} INFO -  at 73.4s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "INFO:flaml.automl: at 73.4s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "[flaml.automl: 05-02 17:26:24] {2567} INFO - iteration 444, current learner xgboost\n",
            "INFO:flaml.automl:iteration 444, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:24] {2750} INFO -  at 73.5s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "INFO:flaml.automl: at 73.5s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "[flaml.automl: 05-02 17:26:24] {2567} INFO - iteration 445, current learner xgboost\n",
            "INFO:flaml.automl:iteration 445, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:24] {2750} INFO -  at 73.5s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "INFO:flaml.automl: at 73.5s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "[flaml.automl: 05-02 17:26:24] {2567} INFO - iteration 446, current learner xgboost\n",
            "INFO:flaml.automl:iteration 446, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:24] {2750} INFO -  at 73.6s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "INFO:flaml.automl: at 73.6s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "[flaml.automl: 05-02 17:26:24] {2567} INFO - iteration 447, current learner xgboost\n",
            "INFO:flaml.automl:iteration 447, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:24] {2750} INFO -  at 73.7s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "INFO:flaml.automl: at 73.7s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "[flaml.automl: 05-02 17:26:24] {2567} INFO - iteration 448, current learner xgboost\n",
            "INFO:flaml.automl:iteration 448, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:24] {2750} INFO -  at 73.7s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "INFO:flaml.automl: at 73.7s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "[flaml.automl: 05-02 17:26:24] {2567} INFO - iteration 449, current learner xgboost\n",
            "INFO:flaml.automl:iteration 449, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:24] {2750} INFO -  at 73.8s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "INFO:flaml.automl: at 73.8s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "[flaml.automl: 05-02 17:26:24] {2567} INFO - iteration 450, current learner xgboost\n",
            "INFO:flaml.automl:iteration 450, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:24] {2750} INFO -  at 73.9s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "INFO:flaml.automl: at 73.9s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "[flaml.automl: 05-02 17:26:24] {2567} INFO - iteration 451, current learner xgboost\n",
            "INFO:flaml.automl:iteration 451, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:24] {2750} INFO -  at 74.0s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "INFO:flaml.automl: at 74.0s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "[flaml.automl: 05-02 17:26:24] {2567} INFO - iteration 452, current learner xgboost\n",
            "INFO:flaml.automl:iteration 452, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:24] {2750} INFO -  at 74.0s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "INFO:flaml.automl: at 74.0s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "[flaml.automl: 05-02 17:26:24] {2567} INFO - iteration 453, current learner xgboost\n",
            "INFO:flaml.automl:iteration 453, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:24] {2750} INFO -  at 74.1s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "INFO:flaml.automl: at 74.1s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "[flaml.automl: 05-02 17:26:24] {2567} INFO - iteration 454, current learner xgboost\n",
            "INFO:flaml.automl:iteration 454, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:24] {2750} INFO -  at 74.2s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "INFO:flaml.automl: at 74.2s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "[flaml.automl: 05-02 17:26:24] {2567} INFO - iteration 455, current learner xgboost\n",
            "INFO:flaml.automl:iteration 455, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:25] {2750} INFO -  at 74.2s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "INFO:flaml.automl: at 74.2s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "[flaml.automl: 05-02 17:26:25] {2567} INFO - iteration 456, current learner rf\n",
            "INFO:flaml.automl:iteration 456, current learner rf\n",
            "[flaml.automl: 05-02 17:26:25] {2750} INFO -  at 74.3s,\testimator rf's best error=0.2041,\tbest estimator xgboost's best error=0.1691\n",
            "INFO:flaml.automl: at 74.3s,\testimator rf's best error=0.2041,\tbest estimator xgboost's best error=0.1691\n",
            "[flaml.automl: 05-02 17:26:25] {2567} INFO - iteration 457, current learner xgboost\n",
            "INFO:flaml.automl:iteration 457, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:25] {2750} INFO -  at 74.4s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "INFO:flaml.automl: at 74.4s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "[flaml.automl: 05-02 17:26:25] {2567} INFO - iteration 458, current learner lrl1\n",
            "INFO:flaml.automl:iteration 458, current learner lrl1\n",
            "INFO:flaml.searcher.blendsearch:No low-cost partial config given to the search algorithm. For cost-frugal search, consider providing low-cost values for cost-related hps via 'low_cost_partial_config'. More info can be found at https://microsoft.github.io/FLAML/docs/FAQ#about-low_cost_partial_config-in-tune\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning:\n",
            "\n",
            "The max_iter was reached which means the coef_ did not converge\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning:\n",
            "\n",
            "The max_iter was reached which means the coef_ did not converge\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning:\n",
            "\n",
            "The max_iter was reached which means the coef_ did not converge\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning:\n",
            "\n",
            "The max_iter was reached which means the coef_ did not converge\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning:\n",
            "\n",
            "The max_iter was reached which means the coef_ did not converge\n",
            "\n",
            "[flaml.automl: 05-02 17:26:25] {2750} INFO -  at 74.5s,\testimator lrl1's best error=0.2431,\tbest estimator xgboost's best error=0.1691\n",
            "INFO:flaml.automl: at 74.5s,\testimator lrl1's best error=0.2431,\tbest estimator xgboost's best error=0.1691\n",
            "[flaml.automl: 05-02 17:26:25] {2567} INFO - iteration 459, current learner lrl1\n",
            "INFO:flaml.automl:iteration 459, current learner lrl1\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning:\n",
            "\n",
            "The max_iter was reached which means the coef_ did not converge\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning:\n",
            "\n",
            "The max_iter was reached which means the coef_ did not converge\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning:\n",
            "\n",
            "The max_iter was reached which means the coef_ did not converge\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning:\n",
            "\n",
            "The max_iter was reached which means the coef_ did not converge\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning:\n",
            "\n",
            "The max_iter was reached which means the coef_ did not converge\n",
            "\n",
            "[flaml.automl: 05-02 17:26:25] {2750} INFO -  at 74.6s,\testimator lrl1's best error=0.2431,\tbest estimator xgboost's best error=0.1691\n",
            "INFO:flaml.automl: at 74.6s,\testimator lrl1's best error=0.2431,\tbest estimator xgboost's best error=0.1691\n",
            "[flaml.automl: 05-02 17:26:25] {2567} INFO - iteration 460, current learner lrl1\n",
            "INFO:flaml.automl:iteration 460, current learner lrl1\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning:\n",
            "\n",
            "The max_iter was reached which means the coef_ did not converge\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning:\n",
            "\n",
            "The max_iter was reached which means the coef_ did not converge\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning:\n",
            "\n",
            "The max_iter was reached which means the coef_ did not converge\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning:\n",
            "\n",
            "The max_iter was reached which means the coef_ did not converge\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning:\n",
            "\n",
            "The max_iter was reached which means the coef_ did not converge\n",
            "\n",
            "[flaml.automl: 05-02 17:26:25] {2750} INFO -  at 74.8s,\testimator lrl1's best error=0.2426,\tbest estimator xgboost's best error=0.1691\n",
            "INFO:flaml.automl: at 74.8s,\testimator lrl1's best error=0.2426,\tbest estimator xgboost's best error=0.1691\n",
            "[flaml.automl: 05-02 17:26:25] {2567} INFO - iteration 461, current learner xgboost\n",
            "INFO:flaml.automl:iteration 461, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:25] {2750} INFO -  at 74.8s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "INFO:flaml.automl: at 74.8s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "[flaml.automl: 05-02 17:26:25] {2567} INFO - iteration 462, current learner xgboost\n",
            "INFO:flaml.automl:iteration 462, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:25] {2750} INFO -  at 74.9s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "INFO:flaml.automl: at 74.9s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "[flaml.automl: 05-02 17:26:25] {2567} INFO - iteration 463, current learner xgboost\n",
            "INFO:flaml.automl:iteration 463, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:25] {2750} INFO -  at 75.0s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "INFO:flaml.automl: at 75.0s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "[flaml.automl: 05-02 17:26:25] {2567} INFO - iteration 464, current learner xgboost\n",
            "INFO:flaml.automl:iteration 464, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:25] {2750} INFO -  at 75.0s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "INFO:flaml.automl: at 75.0s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "[flaml.automl: 05-02 17:26:25] {2567} INFO - iteration 465, current learner xgboost\n",
            "INFO:flaml.automl:iteration 465, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:25] {2750} INFO -  at 75.1s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "INFO:flaml.automl: at 75.1s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "[flaml.automl: 05-02 17:26:25] {2567} INFO - iteration 466, current learner xgboost\n",
            "INFO:flaml.automl:iteration 466, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:25] {2750} INFO -  at 75.2s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "INFO:flaml.automl: at 75.2s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "[flaml.automl: 05-02 17:26:25] {2567} INFO - iteration 467, current learner xgboost\n",
            "INFO:flaml.automl:iteration 467, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:26] {2750} INFO -  at 75.3s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "INFO:flaml.automl: at 75.3s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "[flaml.automl: 05-02 17:26:26] {2567} INFO - iteration 468, current learner rf\n",
            "INFO:flaml.automl:iteration 468, current learner rf\n",
            "[flaml.automl: 05-02 17:26:27] {2750} INFO -  at 76.6s,\testimator rf's best error=0.2041,\tbest estimator xgboost's best error=0.1691\n",
            "INFO:flaml.automl: at 76.6s,\testimator rf's best error=0.2041,\tbest estimator xgboost's best error=0.1691\n",
            "[flaml.automl: 05-02 17:26:27] {2567} INFO - iteration 469, current learner xgboost\n",
            "INFO:flaml.automl:iteration 469, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:27] {2750} INFO -  at 76.6s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "INFO:flaml.automl: at 76.6s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "[flaml.automl: 05-02 17:26:27] {2567} INFO - iteration 470, current learner lrl1\n",
            "INFO:flaml.automl:iteration 470, current learner lrl1\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning:\n",
            "\n",
            "The max_iter was reached which means the coef_ did not converge\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning:\n",
            "\n",
            "The max_iter was reached which means the coef_ did not converge\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning:\n",
            "\n",
            "The max_iter was reached which means the coef_ did not converge\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning:\n",
            "\n",
            "The max_iter was reached which means the coef_ did not converge\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning:\n",
            "\n",
            "The max_iter was reached which means the coef_ did not converge\n",
            "\n",
            "[flaml.automl: 05-02 17:26:27] {2750} INFO -  at 76.8s,\testimator lrl1's best error=0.2426,\tbest estimator xgboost's best error=0.1691\n",
            "INFO:flaml.automl: at 76.8s,\testimator lrl1's best error=0.2426,\tbest estimator xgboost's best error=0.1691\n",
            "[flaml.automl: 05-02 17:26:27] {2567} INFO - iteration 471, current learner xgboost\n",
            "INFO:flaml.automl:iteration 471, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:27] {2750} INFO -  at 76.8s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "INFO:flaml.automl: at 76.8s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "[flaml.automl: 05-02 17:26:27] {2567} INFO - iteration 472, current learner xgboost\n",
            "INFO:flaml.automl:iteration 472, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:27] {2750} INFO -  at 76.9s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "INFO:flaml.automl: at 76.9s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "[flaml.automl: 05-02 17:26:27] {2567} INFO - iteration 473, current learner xgboost\n",
            "INFO:flaml.automl:iteration 473, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:27] {2750} INFO -  at 77.0s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "INFO:flaml.automl: at 77.0s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "[flaml.automl: 05-02 17:26:27] {2567} INFO - iteration 474, current learner lrl1\n",
            "INFO:flaml.automl:iteration 474, current learner lrl1\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning:\n",
            "\n",
            "The max_iter was reached which means the coef_ did not converge\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning:\n",
            "\n",
            "The max_iter was reached which means the coef_ did not converge\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning:\n",
            "\n",
            "The max_iter was reached which means the coef_ did not converge\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning:\n",
            "\n",
            "The max_iter was reached which means the coef_ did not converge\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning:\n",
            "\n",
            "The max_iter was reached which means the coef_ did not converge\n",
            "\n",
            "[flaml.automl: 05-02 17:26:27] {2750} INFO -  at 77.1s,\testimator lrl1's best error=0.2424,\tbest estimator xgboost's best error=0.1691\n",
            "INFO:flaml.automl: at 77.1s,\testimator lrl1's best error=0.2424,\tbest estimator xgboost's best error=0.1691\n",
            "[flaml.automl: 05-02 17:26:27] {2567} INFO - iteration 475, current learner xgboost\n",
            "INFO:flaml.automl:iteration 475, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:27] {2750} INFO -  at 77.2s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "INFO:flaml.automl: at 77.2s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "[flaml.automl: 05-02 17:26:27] {2567} INFO - iteration 476, current learner xgboost\n",
            "INFO:flaml.automl:iteration 476, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:28] {2750} INFO -  at 77.3s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "INFO:flaml.automl: at 77.3s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "[flaml.automl: 05-02 17:26:28] {2567} INFO - iteration 477, current learner xgboost\n",
            "INFO:flaml.automl:iteration 477, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:28] {2750} INFO -  at 77.3s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "INFO:flaml.automl: at 77.3s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "[flaml.automl: 05-02 17:26:28] {2567} INFO - iteration 478, current learner lrl1\n",
            "INFO:flaml.automl:iteration 478, current learner lrl1\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning:\n",
            "\n",
            "The max_iter was reached which means the coef_ did not converge\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning:\n",
            "\n",
            "The max_iter was reached which means the coef_ did not converge\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning:\n",
            "\n",
            "The max_iter was reached which means the coef_ did not converge\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning:\n",
            "\n",
            "The max_iter was reached which means the coef_ did not converge\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning:\n",
            "\n",
            "The max_iter was reached which means the coef_ did not converge\n",
            "\n",
            "[flaml.automl: 05-02 17:26:28] {2750} INFO -  at 77.4s,\testimator lrl1's best error=0.2424,\tbest estimator xgboost's best error=0.1691\n",
            "INFO:flaml.automl: at 77.4s,\testimator lrl1's best error=0.2424,\tbest estimator xgboost's best error=0.1691\n",
            "[flaml.automl: 05-02 17:26:28] {2567} INFO - iteration 479, current learner xgboost\n",
            "INFO:flaml.automl:iteration 479, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:28] {2750} INFO -  at 77.5s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "INFO:flaml.automl: at 77.5s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "[flaml.automl: 05-02 17:26:28] {2567} INFO - iteration 480, current learner xgboost\n",
            "INFO:flaml.automl:iteration 480, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:28] {2750} INFO -  at 77.6s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "INFO:flaml.automl: at 77.6s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "[flaml.automl: 05-02 17:26:28] {2567} INFO - iteration 481, current learner xgboost\n",
            "INFO:flaml.automl:iteration 481, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:28] {2750} INFO -  at 77.7s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "INFO:flaml.automl: at 77.7s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "[flaml.automl: 05-02 17:26:28] {2567} INFO - iteration 482, current learner xgboost\n",
            "INFO:flaml.automl:iteration 482, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:28] {2750} INFO -  at 77.8s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "INFO:flaml.automl: at 77.8s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "[flaml.automl: 05-02 17:26:28] {2567} INFO - iteration 483, current learner xgboost\n",
            "INFO:flaml.automl:iteration 483, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:28] {2750} INFO -  at 77.8s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "INFO:flaml.automl: at 77.8s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "[flaml.automl: 05-02 17:26:28] {2567} INFO - iteration 484, current learner xgboost\n",
            "INFO:flaml.automl:iteration 484, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:28] {2750} INFO -  at 77.9s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "INFO:flaml.automl: at 77.9s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "[flaml.automl: 05-02 17:26:28] {2567} INFO - iteration 485, current learner xgboost\n",
            "INFO:flaml.automl:iteration 485, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:28] {2750} INFO -  at 78.0s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "INFO:flaml.automl: at 78.0s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "[flaml.automl: 05-02 17:26:28] {2567} INFO - iteration 486, current learner xgboost\n",
            "INFO:flaml.automl:iteration 486, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:28] {2750} INFO -  at 78.1s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "INFO:flaml.automl: at 78.1s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "[flaml.automl: 05-02 17:26:28] {2567} INFO - iteration 487, current learner xgboost\n",
            "INFO:flaml.automl:iteration 487, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:28] {2750} INFO -  at 78.1s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "INFO:flaml.automl: at 78.1s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "[flaml.automl: 05-02 17:26:28] {2567} INFO - iteration 488, current learner xgboost\n",
            "INFO:flaml.automl:iteration 488, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:29] {2750} INFO -  at 78.2s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "INFO:flaml.automl: at 78.2s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "[flaml.automl: 05-02 17:26:29] {2567} INFO - iteration 489, current learner xgboost\n",
            "INFO:flaml.automl:iteration 489, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:29] {2750} INFO -  at 78.3s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "INFO:flaml.automl: at 78.3s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "[flaml.automl: 05-02 17:26:29] {2567} INFO - iteration 490, current learner xgboost\n",
            "INFO:flaml.automl:iteration 490, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:29] {2750} INFO -  at 78.4s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "INFO:flaml.automl: at 78.4s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "[flaml.automl: 05-02 17:26:29] {2567} INFO - iteration 491, current learner xgboost\n",
            "INFO:flaml.automl:iteration 491, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:29] {2750} INFO -  at 78.4s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "INFO:flaml.automl: at 78.4s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "[flaml.automl: 05-02 17:26:29] {2567} INFO - iteration 492, current learner xgboost\n",
            "INFO:flaml.automl:iteration 492, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:29] {2750} INFO -  at 78.5s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "INFO:flaml.automl: at 78.5s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "[flaml.automl: 05-02 17:26:29] {2567} INFO - iteration 493, current learner xgboost\n",
            "INFO:flaml.automl:iteration 493, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:29] {2750} INFO -  at 78.6s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "INFO:flaml.automl: at 78.6s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "[flaml.automl: 05-02 17:26:29] {2567} INFO - iteration 494, current learner xgboost\n",
            "INFO:flaml.automl:iteration 494, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:29] {2750} INFO -  at 78.7s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "INFO:flaml.automl: at 78.7s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "[flaml.automl: 05-02 17:26:29] {2567} INFO - iteration 495, current learner xgboost\n",
            "INFO:flaml.automl:iteration 495, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:29] {2750} INFO -  at 78.8s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "INFO:flaml.automl: at 78.8s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "[flaml.automl: 05-02 17:26:29] {2567} INFO - iteration 496, current learner xgboost\n",
            "INFO:flaml.automl:iteration 496, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:29] {2750} INFO -  at 78.8s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "INFO:flaml.automl: at 78.8s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "[flaml.automl: 05-02 17:26:29] {2567} INFO - iteration 497, current learner xgboost\n",
            "INFO:flaml.automl:iteration 497, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:29] {2750} INFO -  at 78.9s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "INFO:flaml.automl: at 78.9s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "[flaml.automl: 05-02 17:26:29] {2567} INFO - iteration 498, current learner xgboost\n",
            "INFO:flaml.automl:iteration 498, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:29] {2750} INFO -  at 79.0s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "INFO:flaml.automl: at 79.0s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "[flaml.automl: 05-02 17:26:29] {2567} INFO - iteration 499, current learner xgboost\n",
            "INFO:flaml.automl:iteration 499, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:29] {2750} INFO -  at 79.1s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "INFO:flaml.automl: at 79.1s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "[flaml.automl: 05-02 17:26:29] {2567} INFO - iteration 500, current learner xgboost\n",
            "INFO:flaml.automl:iteration 500, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:29] {2750} INFO -  at 79.1s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "INFO:flaml.automl: at 79.1s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "[flaml.automl: 05-02 17:26:29] {2567} INFO - iteration 501, current learner xgboost\n",
            "INFO:flaml.automl:iteration 501, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:30] {2750} INFO -  at 79.2s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "INFO:flaml.automl: at 79.2s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "[flaml.automl: 05-02 17:26:30] {2567} INFO - iteration 502, current learner xgboost\n",
            "INFO:flaml.automl:iteration 502, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:30] {2750} INFO -  at 79.3s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "INFO:flaml.automl: at 79.3s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "[flaml.automl: 05-02 17:26:30] {2567} INFO - iteration 503, current learner xgboost\n",
            "INFO:flaml.automl:iteration 503, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:30] {2750} INFO -  at 79.4s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "INFO:flaml.automl: at 79.4s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "[flaml.automl: 05-02 17:26:30] {2567} INFO - iteration 504, current learner xgboost\n",
            "INFO:flaml.automl:iteration 504, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:30] {2750} INFO -  at 79.4s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "INFO:flaml.automl: at 79.4s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "[flaml.automl: 05-02 17:26:30] {2567} INFO - iteration 505, current learner xgboost\n",
            "INFO:flaml.automl:iteration 505, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:30] {2750} INFO -  at 79.5s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "INFO:flaml.automl: at 79.5s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "[flaml.automl: 05-02 17:26:30] {2567} INFO - iteration 506, current learner xgboost\n",
            "INFO:flaml.automl:iteration 506, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:30] {2750} INFO -  at 79.6s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "INFO:flaml.automl: at 79.6s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "[flaml.automl: 05-02 17:26:30] {2567} INFO - iteration 507, current learner xgboost\n",
            "INFO:flaml.automl:iteration 507, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:30] {2750} INFO -  at 79.7s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "INFO:flaml.automl: at 79.7s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "[flaml.automl: 05-02 17:26:30] {2567} INFO - iteration 508, current learner xgboost\n",
            "INFO:flaml.automl:iteration 508, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:30] {2750} INFO -  at 79.7s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "INFO:flaml.automl: at 79.7s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "[flaml.automl: 05-02 17:26:30] {2567} INFO - iteration 509, current learner xgboost\n",
            "INFO:flaml.automl:iteration 509, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:30] {2750} INFO -  at 79.8s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "INFO:flaml.automl: at 79.8s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "[flaml.automl: 05-02 17:26:30] {2567} INFO - iteration 510, current learner xgboost\n",
            "INFO:flaml.automl:iteration 510, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:30] {2750} INFO -  at 79.9s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "INFO:flaml.automl: at 79.9s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "[flaml.automl: 05-02 17:26:30] {2567} INFO - iteration 511, current learner xgboost\n",
            "INFO:flaml.automl:iteration 511, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:30] {2750} INFO -  at 79.9s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "INFO:flaml.automl: at 79.9s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "[flaml.automl: 05-02 17:26:30] {2567} INFO - iteration 512, current learner xgboost\n",
            "INFO:flaml.automl:iteration 512, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:30] {2750} INFO -  at 80.0s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "INFO:flaml.automl: at 80.0s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "[flaml.automl: 05-02 17:26:30] {2567} INFO - iteration 513, current learner xgboost\n",
            "INFO:flaml.automl:iteration 513, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:30] {2750} INFO -  at 80.1s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "INFO:flaml.automl: at 80.1s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "[flaml.automl: 05-02 17:26:30] {2567} INFO - iteration 514, current learner xgboost\n",
            "INFO:flaml.automl:iteration 514, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:30] {2750} INFO -  at 80.2s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "INFO:flaml.automl: at 80.2s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "[flaml.automl: 05-02 17:26:30] {2567} INFO - iteration 515, current learner xgboost\n",
            "INFO:flaml.automl:iteration 515, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:31] {2750} INFO -  at 80.2s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "INFO:flaml.automl: at 80.2s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "[flaml.automl: 05-02 17:26:31] {2567} INFO - iteration 516, current learner xgboost\n",
            "INFO:flaml.automl:iteration 516, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:31] {2750} INFO -  at 80.3s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "INFO:flaml.automl: at 80.3s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "[flaml.automl: 05-02 17:26:31] {2567} INFO - iteration 517, current learner xgboost\n",
            "INFO:flaml.automl:iteration 517, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:31] {2750} INFO -  at 80.4s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "INFO:flaml.automl: at 80.4s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "[flaml.automl: 05-02 17:26:31] {2567} INFO - iteration 518, current learner xgboost\n",
            "INFO:flaml.automl:iteration 518, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:31] {2750} INFO -  at 80.5s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "INFO:flaml.automl: at 80.5s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "[flaml.automl: 05-02 17:26:31] {2567} INFO - iteration 519, current learner xgboost\n",
            "INFO:flaml.automl:iteration 519, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:31] {2750} INFO -  at 80.6s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "INFO:flaml.automl: at 80.6s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "[flaml.automl: 05-02 17:26:31] {2567} INFO - iteration 520, current learner xgboost\n",
            "INFO:flaml.automl:iteration 520, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:31] {2750} INFO -  at 80.7s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "INFO:flaml.automl: at 80.7s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "[flaml.automl: 05-02 17:26:31] {2567} INFO - iteration 521, current learner xgboost\n",
            "INFO:flaml.automl:iteration 521, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:31] {2750} INFO -  at 80.7s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "INFO:flaml.automl: at 80.7s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "[flaml.automl: 05-02 17:26:31] {2567} INFO - iteration 522, current learner xgboost\n",
            "INFO:flaml.automl:iteration 522, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:31] {2750} INFO -  at 80.8s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "INFO:flaml.automl: at 80.8s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "[flaml.automl: 05-02 17:26:31] {2567} INFO - iteration 523, current learner extra_tree\n",
            "INFO:flaml.automl:iteration 523, current learner extra_tree\n",
            "[flaml.automl: 05-02 17:26:32] {2750} INFO -  at 82.0s,\testimator extra_tree's best error=0.2069,\tbest estimator xgboost's best error=0.1691\n",
            "INFO:flaml.automl: at 82.0s,\testimator extra_tree's best error=0.2069,\tbest estimator xgboost's best error=0.1691\n",
            "[flaml.automl: 05-02 17:26:32] {2567} INFO - iteration 524, current learner xgboost\n",
            "INFO:flaml.automl:iteration 524, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:32] {2750} INFO -  at 82.1s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "INFO:flaml.automl: at 82.1s,\testimator xgboost's best error=0.1691,\tbest estimator xgboost's best error=0.1691\n",
            "[flaml.automl: 05-02 17:26:32] {2567} INFO - iteration 525, current learner xgboost\n",
            "INFO:flaml.automl:iteration 525, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:32] {2750} INFO -  at 82.1s,\testimator xgboost's best error=0.1684,\tbest estimator xgboost's best error=0.1684\n",
            "INFO:flaml.automl: at 82.1s,\testimator xgboost's best error=0.1684,\tbest estimator xgboost's best error=0.1684\n",
            "[flaml.automl: 05-02 17:26:32] {2567} INFO - iteration 526, current learner rf\n",
            "INFO:flaml.automl:iteration 526, current learner rf\n",
            "[flaml.automl: 05-02 17:26:33] {2750} INFO -  at 82.2s,\testimator rf's best error=0.2041,\tbest estimator xgboost's best error=0.1684\n",
            "INFO:flaml.automl: at 82.2s,\testimator rf's best error=0.2041,\tbest estimator xgboost's best error=0.1684\n",
            "[flaml.automl: 05-02 17:26:33] {2567} INFO - iteration 527, current learner xgboost\n",
            "INFO:flaml.automl:iteration 527, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:33] {2750} INFO -  at 82.3s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 82.3s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:26:33] {2567} INFO - iteration 528, current learner xgboost\n",
            "INFO:flaml.automl:iteration 528, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:33] {2750} INFO -  at 82.4s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 82.4s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:26:33] {2567} INFO - iteration 529, current learner xgboost\n",
            "INFO:flaml.automl:iteration 529, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:33] {2750} INFO -  at 82.4s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 82.4s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:26:33] {2567} INFO - iteration 530, current learner xgboost\n",
            "INFO:flaml.automl:iteration 530, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:33] {2750} INFO -  at 82.5s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 82.5s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:26:33] {2567} INFO - iteration 531, current learner xgboost\n",
            "INFO:flaml.automl:iteration 531, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:33] {2750} INFO -  at 82.6s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 82.6s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:26:33] {2567} INFO - iteration 532, current learner xgboost\n",
            "INFO:flaml.automl:iteration 532, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:33] {2750} INFO -  at 82.7s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 82.7s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:26:33] {2567} INFO - iteration 533, current learner xgboost\n",
            "INFO:flaml.automl:iteration 533, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:33] {2750} INFO -  at 82.8s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 82.8s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:26:33] {2567} INFO - iteration 534, current learner xgboost\n",
            "INFO:flaml.automl:iteration 534, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:33] {2750} INFO -  at 82.9s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 82.9s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:26:33] {2567} INFO - iteration 535, current learner xgboost\n",
            "INFO:flaml.automl:iteration 535, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:33] {2750} INFO -  at 82.9s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 82.9s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:26:33] {2567} INFO - iteration 536, current learner xgboost\n",
            "INFO:flaml.automl:iteration 536, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:33] {2750} INFO -  at 83.0s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 83.0s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:26:33] {2567} INFO - iteration 537, current learner xgboost\n",
            "INFO:flaml.automl:iteration 537, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:33] {2750} INFO -  at 83.1s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 83.1s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:26:33] {2567} INFO - iteration 538, current learner xgboost\n",
            "INFO:flaml.automl:iteration 538, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:33] {2750} INFO -  at 83.1s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 83.1s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:26:33] {2567} INFO - iteration 539, current learner xgboost\n",
            "INFO:flaml.automl:iteration 539, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:34] {2750} INFO -  at 83.2s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 83.2s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:26:34] {2567} INFO - iteration 540, current learner xgboost\n",
            "INFO:flaml.automl:iteration 540, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:34] {2750} INFO -  at 83.3s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 83.3s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:26:34] {2567} INFO - iteration 541, current learner xgboost\n",
            "INFO:flaml.automl:iteration 541, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:34] {2750} INFO -  at 83.4s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 83.4s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:26:34] {2567} INFO - iteration 542, current learner xgboost\n",
            "INFO:flaml.automl:iteration 542, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:34] {2750} INFO -  at 83.5s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 83.5s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:26:34] {2567} INFO - iteration 543, current learner xgboost\n",
            "INFO:flaml.automl:iteration 543, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:34] {2750} INFO -  at 83.6s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 83.6s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:26:34] {2567} INFO - iteration 544, current learner xgboost\n",
            "INFO:flaml.automl:iteration 544, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:34] {2750} INFO -  at 83.7s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 83.7s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:26:34] {2567} INFO - iteration 545, current learner xgboost\n",
            "INFO:flaml.automl:iteration 545, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:34] {2750} INFO -  at 83.7s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 83.7s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:26:34] {2567} INFO - iteration 546, current learner xgboost\n",
            "INFO:flaml.automl:iteration 546, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:34] {2750} INFO -  at 83.8s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 83.8s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:26:34] {2567} INFO - iteration 547, current learner xgboost\n",
            "INFO:flaml.automl:iteration 547, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:34] {2750} INFO -  at 83.9s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 83.9s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:26:34] {2567} INFO - iteration 548, current learner xgboost\n",
            "INFO:flaml.automl:iteration 548, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:34] {2750} INFO -  at 84.0s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 84.0s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:26:34] {2567} INFO - iteration 549, current learner xgboost\n",
            "INFO:flaml.automl:iteration 549, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:34] {2750} INFO -  at 84.1s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 84.1s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:26:34] {2567} INFO - iteration 550, current learner xgboost\n",
            "INFO:flaml.automl:iteration 550, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:34] {2750} INFO -  at 84.1s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 84.1s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:26:34] {2567} INFO - iteration 551, current learner xgboost\n",
            "INFO:flaml.automl:iteration 551, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:35] {2750} INFO -  at 84.2s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 84.2s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:26:35] {2567} INFO - iteration 552, current learner xgboost\n",
            "INFO:flaml.automl:iteration 552, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:35] {2750} INFO -  at 84.3s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 84.3s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:26:35] {2567} INFO - iteration 553, current learner xgboost\n",
            "INFO:flaml.automl:iteration 553, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:35] {2750} INFO -  at 84.4s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 84.4s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:26:35] {2567} INFO - iteration 554, current learner xgboost\n",
            "INFO:flaml.automl:iteration 554, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:35] {2750} INFO -  at 84.4s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 84.4s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:26:35] {2567} INFO - iteration 555, current learner xgboost\n",
            "INFO:flaml.automl:iteration 555, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:35] {2750} INFO -  at 84.5s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 84.5s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:26:35] {2567} INFO - iteration 556, current learner xgboost\n",
            "INFO:flaml.automl:iteration 556, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:35] {2750} INFO -  at 84.6s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 84.6s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:26:35] {2567} INFO - iteration 557, current learner xgboost\n",
            "INFO:flaml.automl:iteration 557, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:35] {2750} INFO -  at 84.7s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 84.7s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:26:35] {2567} INFO - iteration 558, current learner xgboost\n",
            "INFO:flaml.automl:iteration 558, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:35] {2750} INFO -  at 84.8s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 84.8s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:26:35] {2567} INFO - iteration 559, current learner xgboost\n",
            "INFO:flaml.automl:iteration 559, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:35] {2750} INFO -  at 84.9s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 84.9s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:26:35] {2567} INFO - iteration 560, current learner xgboost\n",
            "INFO:flaml.automl:iteration 560, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:35] {2750} INFO -  at 85.0s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 85.0s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:26:35] {2567} INFO - iteration 561, current learner xgboost\n",
            "INFO:flaml.automl:iteration 561, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:35] {2750} INFO -  at 85.0s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 85.0s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:26:35] {2567} INFO - iteration 562, current learner xgboost\n",
            "INFO:flaml.automl:iteration 562, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:35] {2750} INFO -  at 85.1s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 85.1s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:26:35] {2567} INFO - iteration 563, current learner xgboost\n",
            "INFO:flaml.automl:iteration 563, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:35] {2750} INFO -  at 85.2s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 85.2s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:26:36] {2567} INFO - iteration 564, current learner xgboost\n",
            "INFO:flaml.automl:iteration 564, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:36] {2750} INFO -  at 85.3s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 85.3s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:26:36] {2567} INFO - iteration 565, current learner xgboost\n",
            "INFO:flaml.automl:iteration 565, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:36] {2750} INFO -  at 85.3s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 85.3s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:26:36] {2567} INFO - iteration 566, current learner xgboost\n",
            "INFO:flaml.automl:iteration 566, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:36] {2750} INFO -  at 85.4s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 85.4s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:26:36] {2567} INFO - iteration 567, current learner xgboost\n",
            "INFO:flaml.automl:iteration 567, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:36] {2750} INFO -  at 85.5s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 85.5s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:26:36] {2567} INFO - iteration 568, current learner xgboost\n",
            "INFO:flaml.automl:iteration 568, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:36] {2750} INFO -  at 85.6s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 85.6s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:26:36] {2567} INFO - iteration 569, current learner xgboost\n",
            "INFO:flaml.automl:iteration 569, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:36] {2750} INFO -  at 85.6s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 85.6s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:26:36] {2567} INFO - iteration 570, current learner xgboost\n",
            "INFO:flaml.automl:iteration 570, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:36] {2750} INFO -  at 85.7s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 85.7s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:26:36] {2567} INFO - iteration 571, current learner xgboost\n",
            "INFO:flaml.automl:iteration 571, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:36] {2750} INFO -  at 85.8s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 85.8s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:26:36] {2567} INFO - iteration 572, current learner xgboost\n",
            "INFO:flaml.automl:iteration 572, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:36] {2750} INFO -  at 85.9s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 85.9s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:26:36] {2567} INFO - iteration 573, current learner xgboost\n",
            "INFO:flaml.automl:iteration 573, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:36] {2750} INFO -  at 86.0s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 86.0s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:26:36] {2567} INFO - iteration 574, current learner xgboost\n",
            "INFO:flaml.automl:iteration 574, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:36] {2750} INFO -  at 86.0s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 86.0s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:26:36] {2567} INFO - iteration 575, current learner xgboost\n",
            "INFO:flaml.automl:iteration 575, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:36] {2750} INFO -  at 86.1s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 86.1s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:26:36] {2567} INFO - iteration 576, current learner xgboost\n",
            "INFO:flaml.automl:iteration 576, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:36] {2750} INFO -  at 86.2s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 86.2s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:26:36] {2567} INFO - iteration 577, current learner xgboost\n",
            "INFO:flaml.automl:iteration 577, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:37] {2750} INFO -  at 86.3s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 86.3s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:26:37] {2567} INFO - iteration 578, current learner xgboost\n",
            "INFO:flaml.automl:iteration 578, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:37] {2750} INFO -  at 86.3s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 86.3s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:26:37] {2567} INFO - iteration 579, current learner xgboost\n",
            "INFO:flaml.automl:iteration 579, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:37] {2750} INFO -  at 86.4s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 86.4s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:26:37] {2567} INFO - iteration 580, current learner xgboost\n",
            "INFO:flaml.automl:iteration 580, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:37] {2750} INFO -  at 86.5s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 86.5s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:26:37] {2567} INFO - iteration 581, current learner xgboost\n",
            "INFO:flaml.automl:iteration 581, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:37] {2750} INFO -  at 86.6s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 86.6s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:26:37] {2567} INFO - iteration 582, current learner xgboost\n",
            "INFO:flaml.automl:iteration 582, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:37] {2750} INFO -  at 86.7s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 86.7s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:26:37] {2567} INFO - iteration 583, current learner xgboost\n",
            "INFO:flaml.automl:iteration 583, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:37] {2750} INFO -  at 86.8s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 86.8s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:26:37] {2567} INFO - iteration 584, current learner xgboost\n",
            "INFO:flaml.automl:iteration 584, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:37] {2750} INFO -  at 86.8s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 86.8s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:26:37] {2567} INFO - iteration 585, current learner xgboost\n",
            "INFO:flaml.automl:iteration 585, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:37] {2750} INFO -  at 86.9s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 86.9s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:26:37] {2567} INFO - iteration 586, current learner xgboost\n",
            "INFO:flaml.automl:iteration 586, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:37] {2750} INFO -  at 87.0s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 87.0s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:26:37] {2567} INFO - iteration 587, current learner xgboost\n",
            "INFO:flaml.automl:iteration 587, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:37] {2750} INFO -  at 87.1s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 87.1s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:26:37] {2567} INFO - iteration 588, current learner xgboost\n",
            "INFO:flaml.automl:iteration 588, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:37] {2750} INFO -  at 87.2s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 87.2s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:26:37] {2567} INFO - iteration 589, current learner xgboost\n",
            "INFO:flaml.automl:iteration 589, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:38] {2750} INFO -  at 87.2s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 87.2s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:26:38] {2567} INFO - iteration 590, current learner xgboost\n",
            "INFO:flaml.automl:iteration 590, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:38] {2750} INFO -  at 87.3s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 87.3s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:26:38] {2567} INFO - iteration 591, current learner xgboost\n",
            "INFO:flaml.automl:iteration 591, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:38] {2750} INFO -  at 87.4s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 87.4s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:26:38] {2567} INFO - iteration 592, current learner xgboost\n",
            "INFO:flaml.automl:iteration 592, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:38] {2750} INFO -  at 87.5s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 87.5s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:26:38] {2567} INFO - iteration 593, current learner xgboost\n",
            "INFO:flaml.automl:iteration 593, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:38] {2750} INFO -  at 87.6s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 87.6s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:26:38] {2567} INFO - iteration 594, current learner xgboost\n",
            "INFO:flaml.automl:iteration 594, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:38] {2750} INFO -  at 87.6s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 87.6s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:26:38] {2567} INFO - iteration 595, current learner xgboost\n",
            "INFO:flaml.automl:iteration 595, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:38] {2750} INFO -  at 87.7s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 87.7s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:26:38] {2567} INFO - iteration 596, current learner xgboost\n",
            "INFO:flaml.automl:iteration 596, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:38] {2750} INFO -  at 87.8s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 87.8s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:26:38] {2567} INFO - iteration 597, current learner xgboost\n",
            "INFO:flaml.automl:iteration 597, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:38] {2750} INFO -  at 87.9s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 87.9s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:26:38] {2567} INFO - iteration 598, current learner xgboost\n",
            "INFO:flaml.automl:iteration 598, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:38] {2750} INFO -  at 88.0s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 88.0s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:26:38] {2567} INFO - iteration 599, current learner xgboost\n",
            "INFO:flaml.automl:iteration 599, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:38] {2750} INFO -  at 88.0s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 88.0s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:26:38] {2567} INFO - iteration 600, current learner xgboost\n",
            "INFO:flaml.automl:iteration 600, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:38] {2750} INFO -  at 88.1s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 88.1s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:26:38] {2567} INFO - iteration 601, current learner xgboost\n",
            "INFO:flaml.automl:iteration 601, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:39] {2750} INFO -  at 88.2s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 88.2s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:26:39] {2567} INFO - iteration 602, current learner xgboost\n",
            "INFO:flaml.automl:iteration 602, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:39] {2750} INFO -  at 88.3s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 88.3s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:26:39] {2567} INFO - iteration 603, current learner xgboost\n",
            "INFO:flaml.automl:iteration 603, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:39] {2750} INFO -  at 88.4s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 88.4s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:26:39] {2567} INFO - iteration 604, current learner xgboost\n",
            "INFO:flaml.automl:iteration 604, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:39] {2750} INFO -  at 88.4s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 88.4s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:26:39] {2567} INFO - iteration 605, current learner xgboost\n",
            "INFO:flaml.automl:iteration 605, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:39] {2750} INFO -  at 88.5s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 88.5s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:26:39] {2567} INFO - iteration 606, current learner xgboost\n",
            "INFO:flaml.automl:iteration 606, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:39] {2750} INFO -  at 88.6s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 88.6s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:26:39] {2567} INFO - iteration 607, current learner xgboost\n",
            "INFO:flaml.automl:iteration 607, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:39] {2750} INFO -  at 88.7s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 88.7s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:26:39] {2567} INFO - iteration 608, current learner xgboost\n",
            "INFO:flaml.automl:iteration 608, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:39] {2750} INFO -  at 88.8s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 88.8s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:26:39] {2567} INFO - iteration 609, current learner xgboost\n",
            "INFO:flaml.automl:iteration 609, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:39] {2750} INFO -  at 88.8s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 88.8s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:26:39] {2567} INFO - iteration 610, current learner xgboost\n",
            "INFO:flaml.automl:iteration 610, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:39] {2750} INFO -  at 88.9s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 88.9s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:26:39] {2567} INFO - iteration 611, current learner xgboost\n",
            "INFO:flaml.automl:iteration 611, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:39] {2750} INFO -  at 89.0s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 89.0s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:26:39] {2567} INFO - iteration 612, current learner xgboost\n",
            "INFO:flaml.automl:iteration 612, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:39] {2750} INFO -  at 89.1s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 89.1s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:26:39] {2567} INFO - iteration 613, current learner xgboost\n",
            "INFO:flaml.automl:iteration 613, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:39] {2750} INFO -  at 89.2s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 89.2s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:26:39] {2567} INFO - iteration 614, current learner xgboost\n",
            "INFO:flaml.automl:iteration 614, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:40] {2750} INFO -  at 89.2s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 89.2s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:26:40] {2567} INFO - iteration 615, current learner xgboost\n",
            "INFO:flaml.automl:iteration 615, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:40] {2750} INFO -  at 89.3s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 89.3s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:26:40] {2567} INFO - iteration 616, current learner xgboost\n",
            "INFO:flaml.automl:iteration 616, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:40] {2750} INFO -  at 89.4s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 89.4s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:26:40] {2567} INFO - iteration 617, current learner xgboost\n",
            "INFO:flaml.automl:iteration 617, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:40] {2750} INFO -  at 89.5s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 89.5s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:26:40] {2567} INFO - iteration 618, current learner xgboost\n",
            "INFO:flaml.automl:iteration 618, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:40] {2750} INFO -  at 89.6s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 89.6s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:26:40] {2567} INFO - iteration 619, current learner xgboost\n",
            "INFO:flaml.automl:iteration 619, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:40] {2750} INFO -  at 89.7s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 89.7s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:26:40] {2567} INFO - iteration 620, current learner xgboost\n",
            "INFO:flaml.automl:iteration 620, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:40] {2750} INFO -  at 89.8s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 89.8s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:26:40] {2567} INFO - iteration 621, current learner xgboost\n",
            "INFO:flaml.automl:iteration 621, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:40] {2750} INFO -  at 89.8s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 89.8s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:26:40] {2567} INFO - iteration 622, current learner xgboost\n",
            "INFO:flaml.automl:iteration 622, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:40] {2750} INFO -  at 89.9s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 89.9s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:26:40] {2567} INFO - iteration 623, current learner xgboost\n",
            "INFO:flaml.automl:iteration 623, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:40] {2750} INFO -  at 90.0s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 90.0s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:26:40] {2567} INFO - iteration 624, current learner xgboost\n",
            "INFO:flaml.automl:iteration 624, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:40] {2750} INFO -  at 90.1s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 90.1s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:26:40] {2567} INFO - iteration 625, current learner xgboost\n",
            "INFO:flaml.automl:iteration 625, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:40] {2750} INFO -  at 90.2s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 90.2s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:26:40] {2567} INFO - iteration 626, current learner xgboost\n",
            "INFO:flaml.automl:iteration 626, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:41] {2750} INFO -  at 90.2s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 90.2s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:26:41] {2567} INFO - iteration 627, current learner xgboost\n",
            "INFO:flaml.automl:iteration 627, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:41] {2750} INFO -  at 90.3s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 90.3s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:26:41] {2567} INFO - iteration 628, current learner xgboost\n",
            "INFO:flaml.automl:iteration 628, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:41] {2750} INFO -  at 90.4s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 90.4s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:26:41] {2567} INFO - iteration 629, current learner xgboost\n",
            "INFO:flaml.automl:iteration 629, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:41] {2750} INFO -  at 90.5s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 90.5s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:26:41] {2567} INFO - iteration 630, current learner xgboost\n",
            "INFO:flaml.automl:iteration 630, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:41] {2750} INFO -  at 90.6s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 90.6s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:26:41] {2567} INFO - iteration 631, current learner xgboost\n",
            "INFO:flaml.automl:iteration 631, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:41] {2750} INFO -  at 90.6s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 90.6s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:26:41] {2567} INFO - iteration 632, current learner xgboost\n",
            "INFO:flaml.automl:iteration 632, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:41] {2750} INFO -  at 90.7s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 90.7s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:26:41] {2567} INFO - iteration 633, current learner xgboost\n",
            "INFO:flaml.automl:iteration 633, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:41] {2750} INFO -  at 90.8s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 90.8s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:26:41] {2567} INFO - iteration 634, current learner xgboost\n",
            "INFO:flaml.automl:iteration 634, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:41] {2750} INFO -  at 90.9s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 90.9s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:26:41] {2567} INFO - iteration 635, current learner xgboost\n",
            "INFO:flaml.automl:iteration 635, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:41] {2750} INFO -  at 91.0s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 91.0s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:26:41] {2567} INFO - iteration 636, current learner xgboost\n",
            "INFO:flaml.automl:iteration 636, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:41] {2750} INFO -  at 91.0s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 91.0s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:26:41] {2567} INFO - iteration 637, current learner xgboost\n",
            "INFO:flaml.automl:iteration 637, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:41] {2750} INFO -  at 91.1s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 91.1s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:26:41] {2567} INFO - iteration 638, current learner xgboost\n",
            "INFO:flaml.automl:iteration 638, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:41] {2750} INFO -  at 91.2s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 91.2s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:26:41] {2567} INFO - iteration 639, current learner xgboost\n",
            "INFO:flaml.automl:iteration 639, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:42] {2750} INFO -  at 91.3s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 91.3s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:26:42] {2567} INFO - iteration 640, current learner xgboost\n",
            "INFO:flaml.automl:iteration 640, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:42] {2750} INFO -  at 91.3s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 91.3s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:26:42] {2567} INFO - iteration 641, current learner xgboost\n",
            "INFO:flaml.automl:iteration 641, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:42] {2750} INFO -  at 91.4s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 91.4s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:26:42] {2567} INFO - iteration 642, current learner xgboost\n",
            "INFO:flaml.automl:iteration 642, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:42] {2750} INFO -  at 91.5s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 91.5s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:26:42] {2567} INFO - iteration 643, current learner xgboost\n",
            "INFO:flaml.automl:iteration 643, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:42] {2750} INFO -  at 91.6s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 91.6s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:26:42] {2567} INFO - iteration 644, current learner xgboost\n",
            "INFO:flaml.automl:iteration 644, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:42] {2750} INFO -  at 91.6s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 91.6s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:26:42] {2567} INFO - iteration 645, current learner xgboost\n",
            "INFO:flaml.automl:iteration 645, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:42] {2750} INFO -  at 91.7s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 91.7s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:26:42] {2567} INFO - iteration 646, current learner xgboost\n",
            "INFO:flaml.automl:iteration 646, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:42] {2750} INFO -  at 91.8s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 91.8s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:26:42] {2567} INFO - iteration 647, current learner xgboost\n",
            "INFO:flaml.automl:iteration 647, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:42] {2750} INFO -  at 91.9s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 91.9s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:26:42] {2567} INFO - iteration 648, current learner xgboost\n",
            "INFO:flaml.automl:iteration 648, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:42] {2750} INFO -  at 91.9s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 91.9s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:26:42] {2567} INFO - iteration 649, current learner xgboost\n",
            "INFO:flaml.automl:iteration 649, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:42] {2750} INFO -  at 92.0s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 92.0s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:26:42] {2567} INFO - iteration 650, current learner xgboost\n",
            "INFO:flaml.automl:iteration 650, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:42] {2750} INFO -  at 92.1s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 92.1s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:26:42] {2567} INFO - iteration 651, current learner xgboost\n",
            "INFO:flaml.automl:iteration 651, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:43] {2750} INFO -  at 92.2s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 92.2s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:26:43] {2567} INFO - iteration 652, current learner xgboost\n",
            "INFO:flaml.automl:iteration 652, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:43] {2750} INFO -  at 92.3s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 92.3s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:26:43] {2567} INFO - iteration 653, current learner xgboost\n",
            "INFO:flaml.automl:iteration 653, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:43] {2750} INFO -  at 92.3s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 92.3s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:26:43] {2567} INFO - iteration 654, current learner xgboost\n",
            "INFO:flaml.automl:iteration 654, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:43] {2750} INFO -  at 92.4s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 92.4s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:26:43] {2567} INFO - iteration 655, current learner xgboost\n",
            "INFO:flaml.automl:iteration 655, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:43] {2750} INFO -  at 92.5s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 92.5s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:26:43] {2567} INFO - iteration 656, current learner xgboost\n",
            "INFO:flaml.automl:iteration 656, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:43] {2750} INFO -  at 92.6s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 92.6s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:26:43] {2567} INFO - iteration 657, current learner xgboost\n",
            "INFO:flaml.automl:iteration 657, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:43] {2750} INFO -  at 92.7s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 92.7s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:26:43] {2567} INFO - iteration 658, current learner rf\n",
            "INFO:flaml.automl:iteration 658, current learner rf\n",
            "[flaml.automl: 05-02 17:26:43] {2750} INFO -  at 92.8s,\testimator rf's best error=0.2041,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 92.8s,\testimator rf's best error=0.2041,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:26:43] {2567} INFO - iteration 659, current learner xgboost\n",
            "INFO:flaml.automl:iteration 659, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:43] {2750} INFO -  at 92.9s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 92.9s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:26:43] {2567} INFO - iteration 660, current learner xgboost\n",
            "INFO:flaml.automl:iteration 660, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:43] {2750} INFO -  at 92.9s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 92.9s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:26:43] {2567} INFO - iteration 661, current learner xgboost\n",
            "INFO:flaml.automl:iteration 661, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:43] {2750} INFO -  at 93.0s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 93.0s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:26:43] {2567} INFO - iteration 662, current learner xgboost\n",
            "INFO:flaml.automl:iteration 662, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:43] {2750} INFO -  at 93.1s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 93.1s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:26:43] {2567} INFO - iteration 663, current learner xgboost\n",
            "INFO:flaml.automl:iteration 663, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:43] {2750} INFO -  at 93.2s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 93.2s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:26:43] {2567} INFO - iteration 664, current learner xgboost\n",
            "INFO:flaml.automl:iteration 664, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:44] {2750} INFO -  at 93.3s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 93.3s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:26:44] {2567} INFO - iteration 665, current learner xgboost\n",
            "INFO:flaml.automl:iteration 665, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:44] {2750} INFO -  at 93.3s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 93.3s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:26:44] {2567} INFO - iteration 666, current learner xgboost\n",
            "INFO:flaml.automl:iteration 666, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:44] {2750} INFO -  at 93.4s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 93.4s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:26:44] {2567} INFO - iteration 667, current learner xgboost\n",
            "INFO:flaml.automl:iteration 667, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:44] {2750} INFO -  at 93.5s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 93.5s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:26:44] {2567} INFO - iteration 668, current learner xgboost\n",
            "INFO:flaml.automl:iteration 668, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:44] {2750} INFO -  at 93.6s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 93.6s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:26:44] {2567} INFO - iteration 669, current learner xgboost\n",
            "INFO:flaml.automl:iteration 669, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:44] {2750} INFO -  at 93.7s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 93.7s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:26:44] {2567} INFO - iteration 670, current learner xgboost\n",
            "INFO:flaml.automl:iteration 670, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:44] {2750} INFO -  at 93.7s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 93.7s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:26:44] {2567} INFO - iteration 671, current learner xgboost\n",
            "INFO:flaml.automl:iteration 671, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:44] {2750} INFO -  at 93.8s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 93.8s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:26:44] {2567} INFO - iteration 672, current learner xgboost\n",
            "INFO:flaml.automl:iteration 672, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:44] {2750} INFO -  at 93.9s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 93.9s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:26:44] {2567} INFO - iteration 673, current learner xgboost\n",
            "INFO:flaml.automl:iteration 673, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:44] {2750} INFO -  at 94.0s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 94.0s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:26:44] {2567} INFO - iteration 674, current learner xgboost\n",
            "INFO:flaml.automl:iteration 674, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:44] {2750} INFO -  at 94.0s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 94.0s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:26:44] {2567} INFO - iteration 675, current learner xgboost\n",
            "INFO:flaml.automl:iteration 675, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:44] {2750} INFO -  at 94.1s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 94.1s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:26:44] {2567} INFO - iteration 676, current learner xgboost\n",
            "INFO:flaml.automl:iteration 676, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:45] {2750} INFO -  at 94.2s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 94.2s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:26:45] {2567} INFO - iteration 677, current learner xgboost\n",
            "INFO:flaml.automl:iteration 677, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:45] {2750} INFO -  at 94.3s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 94.3s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:26:45] {2567} INFO - iteration 678, current learner xgboost\n",
            "INFO:flaml.automl:iteration 678, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:45] {2750} INFO -  at 94.4s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 94.4s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:26:45] {2567} INFO - iteration 679, current learner rf\n",
            "INFO:flaml.automl:iteration 679, current learner rf\n",
            "[flaml.automl: 05-02 17:26:46] {2750} INFO -  at 95.7s,\testimator rf's best error=0.2041,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 95.7s,\testimator rf's best error=0.2041,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:26:46] {2567} INFO - iteration 680, current learner xgboost\n",
            "INFO:flaml.automl:iteration 680, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:46] {2750} INFO -  at 95.8s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 95.8s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:26:46] {2567} INFO - iteration 681, current learner xgboost\n",
            "INFO:flaml.automl:iteration 681, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:46] {2750} INFO -  at 95.9s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 95.9s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:26:46] {2567} INFO - iteration 682, current learner xgboost\n",
            "INFO:flaml.automl:iteration 682, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:46] {2750} INFO -  at 96.0s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 96.0s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:26:46] {2567} INFO - iteration 683, current learner xgboost\n",
            "INFO:flaml.automl:iteration 683, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:46] {2750} INFO -  at 96.1s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 96.1s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:26:46] {2567} INFO - iteration 684, current learner xgboost\n",
            "INFO:flaml.automl:iteration 684, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:46] {2750} INFO -  at 96.2s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 96.2s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:26:46] {2567} INFO - iteration 685, current learner xgboost\n",
            "INFO:flaml.automl:iteration 685, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:47] {2750} INFO -  at 96.3s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 96.3s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:26:47] {2567} INFO - iteration 686, current learner xgboost\n",
            "INFO:flaml.automl:iteration 686, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:47] {2750} INFO -  at 96.3s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 96.3s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:26:47] {2567} INFO - iteration 687, current learner xgboost\n",
            "INFO:flaml.automl:iteration 687, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:47] {2750} INFO -  at 96.4s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 96.4s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:26:47] {2567} INFO - iteration 688, current learner xgboost\n",
            "INFO:flaml.automl:iteration 688, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:47] {2750} INFO -  at 96.5s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 96.5s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:26:47] {2567} INFO - iteration 689, current learner xgboost\n",
            "INFO:flaml.automl:iteration 689, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:47] {2750} INFO -  at 96.6s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 96.6s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:26:47] {2567} INFO - iteration 690, current learner xgboost\n",
            "INFO:flaml.automl:iteration 690, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:47] {2750} INFO -  at 96.7s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 96.7s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:26:47] {2567} INFO - iteration 691, current learner xgboost\n",
            "INFO:flaml.automl:iteration 691, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:47] {2750} INFO -  at 96.8s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 96.8s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:26:47] {2567} INFO - iteration 692, current learner xgboost\n",
            "INFO:flaml.automl:iteration 692, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:47] {2750} INFO -  at 96.9s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 96.9s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:26:47] {2567} INFO - iteration 693, current learner xgboost\n",
            "INFO:flaml.automl:iteration 693, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:47] {2750} INFO -  at 96.9s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 96.9s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:26:47] {2567} INFO - iteration 694, current learner xgboost\n",
            "INFO:flaml.automl:iteration 694, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:47] {2750} INFO -  at 97.0s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 97.0s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:26:47] {2567} INFO - iteration 695, current learner xgboost\n",
            "INFO:flaml.automl:iteration 695, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:47] {2750} INFO -  at 97.1s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 97.1s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:26:47] {2567} INFO - iteration 696, current learner xgboost\n",
            "INFO:flaml.automl:iteration 696, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:47] {2750} INFO -  at 97.2s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 97.2s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:26:47] {2567} INFO - iteration 697, current learner xgboost\n",
            "INFO:flaml.automl:iteration 697, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:48] {2750} INFO -  at 97.2s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 97.2s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:26:48] {2567} INFO - iteration 698, current learner xgboost\n",
            "INFO:flaml.automl:iteration 698, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:48] {2750} INFO -  at 97.3s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 97.3s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:26:48] {2567} INFO - iteration 699, current learner xgboost\n",
            "INFO:flaml.automl:iteration 699, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:48] {2750} INFO -  at 97.4s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 97.4s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:26:48] {2567} INFO - iteration 700, current learner xgboost\n",
            "INFO:flaml.automl:iteration 700, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:48] {2750} INFO -  at 97.5s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 97.5s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:26:48] {2567} INFO - iteration 701, current learner xgboost\n",
            "INFO:flaml.automl:iteration 701, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:48] {2750} INFO -  at 97.6s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 97.6s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:26:48] {2567} INFO - iteration 702, current learner xgboost\n",
            "INFO:flaml.automl:iteration 702, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:48] {2750} INFO -  at 97.7s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 97.7s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:26:48] {2567} INFO - iteration 703, current learner xgboost\n",
            "INFO:flaml.automl:iteration 703, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:48] {2750} INFO -  at 97.7s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 97.7s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:26:48] {2567} INFO - iteration 704, current learner xgboost\n",
            "INFO:flaml.automl:iteration 704, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:48] {2750} INFO -  at 97.8s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 97.8s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:26:48] {2567} INFO - iteration 705, current learner xgboost\n",
            "INFO:flaml.automl:iteration 705, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:48] {2750} INFO -  at 97.9s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 97.9s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:26:48] {2567} INFO - iteration 706, current learner xgboost\n",
            "INFO:flaml.automl:iteration 706, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:48] {2750} INFO -  at 98.0s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 98.0s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:26:48] {2567} INFO - iteration 707, current learner xgboost\n",
            "INFO:flaml.automl:iteration 707, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:48] {2750} INFO -  at 98.1s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 98.1s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:26:48] {2567} INFO - iteration 708, current learner xgboost\n",
            "INFO:flaml.automl:iteration 708, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:48] {2750} INFO -  at 98.1s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 98.1s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:26:48] {2567} INFO - iteration 709, current learner xgboost\n",
            "INFO:flaml.automl:iteration 709, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:49] {2750} INFO -  at 98.2s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 98.2s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:26:49] {2567} INFO - iteration 710, current learner xgboost\n",
            "INFO:flaml.automl:iteration 710, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:49] {2750} INFO -  at 98.3s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 98.3s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:26:49] {2567} INFO - iteration 711, current learner xgboost\n",
            "INFO:flaml.automl:iteration 711, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:49] {2750} INFO -  at 98.4s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 98.4s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:26:49] {2567} INFO - iteration 712, current learner xgboost\n",
            "INFO:flaml.automl:iteration 712, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:49] {2750} INFO -  at 98.5s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 98.5s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:26:49] {2567} INFO - iteration 713, current learner xgboost\n",
            "INFO:flaml.automl:iteration 713, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:49] {2750} INFO -  at 98.6s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 98.6s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:26:49] {2567} INFO - iteration 714, current learner xgboost\n",
            "INFO:flaml.automl:iteration 714, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:49] {2750} INFO -  at 98.6s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 98.6s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:26:49] {2567} INFO - iteration 715, current learner xgboost\n",
            "INFO:flaml.automl:iteration 715, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:49] {2750} INFO -  at 98.7s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 98.7s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:26:49] {2567} INFO - iteration 716, current learner xgboost\n",
            "INFO:flaml.automl:iteration 716, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:49] {2750} INFO -  at 98.8s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 98.8s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:26:49] {2567} INFO - iteration 717, current learner xgboost\n",
            "INFO:flaml.automl:iteration 717, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:49] {2750} INFO -  at 98.9s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 98.9s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:26:49] {2567} INFO - iteration 718, current learner xgboost\n",
            "INFO:flaml.automl:iteration 718, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:49] {2750} INFO -  at 98.9s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 98.9s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:26:49] {2567} INFO - iteration 719, current learner xgboost\n",
            "INFO:flaml.automl:iteration 719, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:49] {2750} INFO -  at 99.0s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 99.0s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:26:49] {2567} INFO - iteration 720, current learner xgboost\n",
            "INFO:flaml.automl:iteration 720, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:49] {2750} INFO -  at 99.1s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 99.1s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:26:49] {2567} INFO - iteration 721, current learner xgboost\n",
            "INFO:flaml.automl:iteration 721, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:50] {2750} INFO -  at 99.2s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 99.2s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:26:50] {2567} INFO - iteration 722, current learner xgboost\n",
            "INFO:flaml.automl:iteration 722, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:50] {2750} INFO -  at 99.3s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 99.3s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:26:50] {2567} INFO - iteration 723, current learner xgboost\n",
            "INFO:flaml.automl:iteration 723, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:50] {2750} INFO -  at 99.4s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 99.4s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:26:50] {2567} INFO - iteration 724, current learner xgboost\n",
            "INFO:flaml.automl:iteration 724, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:50] {2750} INFO -  at 99.5s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 99.5s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:26:50] {2567} INFO - iteration 725, current learner xgboost\n",
            "INFO:flaml.automl:iteration 725, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:50] {2750} INFO -  at 99.5s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 99.5s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:26:50] {2567} INFO - iteration 726, current learner xgboost\n",
            "INFO:flaml.automl:iteration 726, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:50] {2750} INFO -  at 99.6s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 99.6s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:26:50] {2567} INFO - iteration 727, current learner xgboost\n",
            "INFO:flaml.automl:iteration 727, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:50] {2750} INFO -  at 99.7s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 99.7s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:26:50] {2567} INFO - iteration 728, current learner xgboost\n",
            "INFO:flaml.automl:iteration 728, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:50] {2750} INFO -  at 99.8s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 99.8s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:26:50] {2567} INFO - iteration 729, current learner xgboost\n",
            "INFO:flaml.automl:iteration 729, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:50] {2750} INFO -  at 99.9s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 99.9s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:26:50] {2567} INFO - iteration 730, current learner xgboost\n",
            "INFO:flaml.automl:iteration 730, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:50] {2750} INFO -  at 99.9s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 99.9s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:26:50] {2567} INFO - iteration 731, current learner xgboost\n",
            "INFO:flaml.automl:iteration 731, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:50] {2750} INFO -  at 100.0s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 100.0s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:26:50] {2567} INFO - iteration 732, current learner xgboost\n",
            "INFO:flaml.automl:iteration 732, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:50] {2750} INFO -  at 100.1s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 100.1s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:26:50] {2567} INFO - iteration 733, current learner xgboost\n",
            "INFO:flaml.automl:iteration 733, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:51] {2750} INFO -  at 100.2s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 100.2s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:26:51] {2567} INFO - iteration 734, current learner xgboost\n",
            "INFO:flaml.automl:iteration 734, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:51] {2750} INFO -  at 100.3s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 100.3s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:26:51] {2567} INFO - iteration 735, current learner xgboost\n",
            "INFO:flaml.automl:iteration 735, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:51] {2750} INFO -  at 100.4s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 100.4s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:26:51] {2567} INFO - iteration 736, current learner xgboost\n",
            "INFO:flaml.automl:iteration 736, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:51] {2750} INFO -  at 100.5s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 100.5s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:26:51] {2567} INFO - iteration 737, current learner xgboost\n",
            "INFO:flaml.automl:iteration 737, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:51] {2750} INFO -  at 100.5s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 100.5s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:26:51] {2567} INFO - iteration 738, current learner xgboost\n",
            "INFO:flaml.automl:iteration 738, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:51] {2750} INFO -  at 100.6s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 100.6s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:26:51] {2567} INFO - iteration 739, current learner xgboost\n",
            "INFO:flaml.automl:iteration 739, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:51] {2750} INFO -  at 100.7s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 100.7s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:26:51] {2567} INFO - iteration 740, current learner xgboost\n",
            "INFO:flaml.automl:iteration 740, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:51] {2750} INFO -  at 100.8s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 100.8s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:26:51] {2567} INFO - iteration 741, current learner xgboost\n",
            "INFO:flaml.automl:iteration 741, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:51] {2750} INFO -  at 100.9s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 100.9s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:26:51] {2567} INFO - iteration 742, current learner xgboost\n",
            "INFO:flaml.automl:iteration 742, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:51] {2750} INFO -  at 100.9s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 100.9s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:26:51] {2567} INFO - iteration 743, current learner xgboost\n",
            "INFO:flaml.automl:iteration 743, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:51] {2750} INFO -  at 101.0s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 101.0s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:26:51] {2567} INFO - iteration 744, current learner rf\n",
            "INFO:flaml.automl:iteration 744, current learner rf\n",
            "[flaml.automl: 05-02 17:26:53] {2750} INFO -  at 102.6s,\testimator rf's best error=0.2041,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 102.6s,\testimator rf's best error=0.2041,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:26:53] {2567} INFO - iteration 745, current learner xgboost\n",
            "INFO:flaml.automl:iteration 745, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:53] {2750} INFO -  at 103.0s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 103.0s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:26:53] {2567} INFO - iteration 746, current learner xgboost\n",
            "INFO:flaml.automl:iteration 746, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:53] {2750} INFO -  at 103.1s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 103.1s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:26:53] {2567} INFO - iteration 747, current learner xgboost\n",
            "INFO:flaml.automl:iteration 747, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:54] {2750} INFO -  at 103.3s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 103.3s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:26:54] {2567} INFO - iteration 748, current learner xgboost\n",
            "INFO:flaml.automl:iteration 748, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:54] {2750} INFO -  at 103.4s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 103.4s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:26:54] {2567} INFO - iteration 749, current learner xgboost\n",
            "INFO:flaml.automl:iteration 749, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:54] {2750} INFO -  at 103.5s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 103.5s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:26:54] {2567} INFO - iteration 750, current learner xgboost\n",
            "INFO:flaml.automl:iteration 750, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:54] {2750} INFO -  at 103.6s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 103.6s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:26:54] {2567} INFO - iteration 751, current learner xgboost\n",
            "INFO:flaml.automl:iteration 751, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:54] {2750} INFO -  at 103.6s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 103.6s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:26:54] {2567} INFO - iteration 752, current learner xgboost\n",
            "INFO:flaml.automl:iteration 752, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:54] {2750} INFO -  at 103.9s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 103.9s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:26:54] {2567} INFO - iteration 753, current learner xgboost\n",
            "INFO:flaml.automl:iteration 753, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:54] {2750} INFO -  at 104.1s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 104.1s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:26:54] {2567} INFO - iteration 754, current learner xgboost\n",
            "INFO:flaml.automl:iteration 754, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:55] {2750} INFO -  at 104.5s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 104.5s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:26:55] {2567} INFO - iteration 755, current learner xgboost\n",
            "INFO:flaml.automl:iteration 755, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:55] {2750} INFO -  at 104.7s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 104.7s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:26:55] {2567} INFO - iteration 756, current learner xgboost\n",
            "INFO:flaml.automl:iteration 756, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:55] {2750} INFO -  at 104.9s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 104.9s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:26:55] {2567} INFO - iteration 757, current learner xgboost\n",
            "INFO:flaml.automl:iteration 757, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:55] {2750} INFO -  at 105.0s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 105.0s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:26:55] {2567} INFO - iteration 758, current learner xgboost\n",
            "INFO:flaml.automl:iteration 758, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:55] {2750} INFO -  at 105.1s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 105.1s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:26:55] {2567} INFO - iteration 759, current learner xgboost\n",
            "INFO:flaml.automl:iteration 759, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:56] {2750} INFO -  at 105.2s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 105.2s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:26:56] {2567} INFO - iteration 760, current learner xgboost\n",
            "INFO:flaml.automl:iteration 760, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:56] {2750} INFO -  at 105.3s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 105.3s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:26:56] {2567} INFO - iteration 761, current learner xgboost\n",
            "INFO:flaml.automl:iteration 761, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:56] {2750} INFO -  at 105.5s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 105.5s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:26:56] {2567} INFO - iteration 762, current learner xgboost\n",
            "INFO:flaml.automl:iteration 762, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:56] {2750} INFO -  at 105.8s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 105.8s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:26:56] {2567} INFO - iteration 763, current learner xgboost\n",
            "INFO:flaml.automl:iteration 763, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:56] {2750} INFO -  at 106.1s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 106.1s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:26:56] {2567} INFO - iteration 764, current learner xgboost\n",
            "INFO:flaml.automl:iteration 764, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:57] {2750} INFO -  at 106.4s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 106.4s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:26:57] {2567} INFO - iteration 765, current learner rf\n",
            "INFO:flaml.automl:iteration 765, current learner rf\n",
            "[flaml.automl: 05-02 17:26:57] {2750} INFO -  at 106.7s,\testimator rf's best error=0.2041,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 106.7s,\testimator rf's best error=0.2041,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:26:57] {2567} INFO - iteration 766, current learner xgboost\n",
            "INFO:flaml.automl:iteration 766, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:57] {2750} INFO -  at 106.8s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 106.8s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:26:57] {2567} INFO - iteration 767, current learner xgboost\n",
            "INFO:flaml.automl:iteration 767, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:57] {2750} INFO -  at 106.9s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 106.9s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:26:57] {2567} INFO - iteration 768, current learner xgboost\n",
            "INFO:flaml.automl:iteration 768, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:57] {2750} INFO -  at 106.9s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 106.9s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:26:57] {2567} INFO - iteration 769, current learner xgboost\n",
            "INFO:flaml.automl:iteration 769, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:57] {2750} INFO -  at 107.0s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 107.0s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:26:57] {2567} INFO - iteration 770, current learner xgboost\n",
            "INFO:flaml.automl:iteration 770, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:57] {2750} INFO -  at 107.1s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 107.1s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:26:57] {2567} INFO - iteration 771, current learner xgboost\n",
            "INFO:flaml.automl:iteration 771, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:57] {2750} INFO -  at 107.2s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 107.2s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:26:57] {2567} INFO - iteration 772, current learner xgboost\n",
            "INFO:flaml.automl:iteration 772, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:58] {2750} INFO -  at 107.2s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 107.2s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:26:58] {2567} INFO - iteration 773, current learner xgboost\n",
            "INFO:flaml.automl:iteration 773, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:58] {2750} INFO -  at 107.3s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 107.3s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:26:58] {2567} INFO - iteration 774, current learner xgboost\n",
            "INFO:flaml.automl:iteration 774, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:58] {2750} INFO -  at 107.4s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 107.4s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:26:58] {2567} INFO - iteration 775, current learner xgboost\n",
            "INFO:flaml.automl:iteration 775, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:58] {2750} INFO -  at 107.5s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 107.5s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:26:58] {2567} INFO - iteration 776, current learner xgboost\n",
            "INFO:flaml.automl:iteration 776, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:58] {2750} INFO -  at 107.6s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 107.6s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:26:58] {2567} INFO - iteration 777, current learner xgboost\n",
            "INFO:flaml.automl:iteration 777, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:58] {2750} INFO -  at 107.7s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 107.7s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:26:58] {2567} INFO - iteration 778, current learner xgboost\n",
            "INFO:flaml.automl:iteration 778, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:58] {2750} INFO -  at 107.7s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 107.7s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:26:58] {2567} INFO - iteration 779, current learner xgboost\n",
            "INFO:flaml.automl:iteration 779, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:58] {2750} INFO -  at 107.8s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 107.8s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:26:58] {2567} INFO - iteration 780, current learner xgboost\n",
            "INFO:flaml.automl:iteration 780, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:58] {2750} INFO -  at 107.9s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 107.9s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:26:58] {2567} INFO - iteration 781, current learner xgboost\n",
            "INFO:flaml.automl:iteration 781, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:58] {2750} INFO -  at 108.0s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 108.0s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:26:58] {2567} INFO - iteration 782, current learner xgboost\n",
            "INFO:flaml.automl:iteration 782, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:58] {2750} INFO -  at 108.1s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 108.1s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:26:58] {2567} INFO - iteration 783, current learner xgboost\n",
            "INFO:flaml.automl:iteration 783, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:58] {2750} INFO -  at 108.2s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 108.2s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:26:58] {2567} INFO - iteration 784, current learner xgboost\n",
            "INFO:flaml.automl:iteration 784, current learner xgboost\n",
            "[flaml.automl: 05-02 17:26:59] {2750} INFO -  at 108.2s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 108.2s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:26:59] {2567} INFO - iteration 785, current learner rf\n",
            "INFO:flaml.automl:iteration 785, current learner rf\n",
            "[flaml.automl: 05-02 17:27:00] {2750} INFO -  at 109.8s,\testimator rf's best error=0.2041,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 109.8s,\testimator rf's best error=0.2041,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:27:00] {2567} INFO - iteration 786, current learner xgboost\n",
            "INFO:flaml.automl:iteration 786, current learner xgboost\n",
            "[flaml.automl: 05-02 17:27:00] {2750} INFO -  at 109.8s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 109.8s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:27:00] {2567} INFO - iteration 787, current learner rf\n",
            "INFO:flaml.automl:iteration 787, current learner rf\n",
            "[flaml.automl: 05-02 17:27:00] {2750} INFO -  at 109.9s,\testimator rf's best error=0.2041,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 109.9s,\testimator rf's best error=0.2041,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:27:00] {2567} INFO - iteration 788, current learner xgboost\n",
            "INFO:flaml.automl:iteration 788, current learner xgboost\n",
            "[flaml.automl: 05-02 17:27:00] {2750} INFO -  at 110.0s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 110.0s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:27:00] {2567} INFO - iteration 789, current learner xgboost\n",
            "INFO:flaml.automl:iteration 789, current learner xgboost\n",
            "[flaml.automl: 05-02 17:27:00] {2750} INFO -  at 110.1s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 110.1s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:27:00] {2567} INFO - iteration 790, current learner xgboost\n",
            "INFO:flaml.automl:iteration 790, current learner xgboost\n",
            "[flaml.automl: 05-02 17:27:00] {2750} INFO -  at 110.2s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 110.2s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:27:00] {2567} INFO - iteration 791, current learner xgboost\n",
            "INFO:flaml.automl:iteration 791, current learner xgboost\n",
            "[flaml.automl: 05-02 17:27:01] {2750} INFO -  at 110.3s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 110.3s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:27:01] {2567} INFO - iteration 792, current learner xgboost\n",
            "INFO:flaml.automl:iteration 792, current learner xgboost\n",
            "[flaml.automl: 05-02 17:27:01] {2750} INFO -  at 110.3s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 110.3s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:27:01] {2567} INFO - iteration 793, current learner xgboost\n",
            "INFO:flaml.automl:iteration 793, current learner xgboost\n",
            "[flaml.automl: 05-02 17:27:01] {2750} INFO -  at 110.4s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 110.4s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:27:01] {2567} INFO - iteration 794, current learner xgboost\n",
            "INFO:flaml.automl:iteration 794, current learner xgboost\n",
            "[flaml.automl: 05-02 17:27:01] {2750} INFO -  at 110.5s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 110.5s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:27:01] {2567} INFO - iteration 795, current learner xgboost\n",
            "INFO:flaml.automl:iteration 795, current learner xgboost\n",
            "[flaml.automl: 05-02 17:27:01] {2750} INFO -  at 110.6s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 110.6s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:27:01] {2567} INFO - iteration 796, current learner xgboost\n",
            "INFO:flaml.automl:iteration 796, current learner xgboost\n",
            "[flaml.automl: 05-02 17:27:01] {2750} INFO -  at 110.7s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 110.7s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:27:01] {2567} INFO - iteration 797, current learner xgboost\n",
            "INFO:flaml.automl:iteration 797, current learner xgboost\n",
            "[flaml.automl: 05-02 17:27:01] {2750} INFO -  at 110.8s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 110.8s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:27:01] {2567} INFO - iteration 798, current learner xgboost\n",
            "INFO:flaml.automl:iteration 798, current learner xgboost\n",
            "[flaml.automl: 05-02 17:27:01] {2750} INFO -  at 110.9s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 110.9s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:27:01] {2567} INFO - iteration 799, current learner xgboost\n",
            "INFO:flaml.automl:iteration 799, current learner xgboost\n",
            "[flaml.automl: 05-02 17:27:01] {2750} INFO -  at 111.0s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 111.0s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:27:01] {2567} INFO - iteration 800, current learner xgboost\n",
            "INFO:flaml.automl:iteration 800, current learner xgboost\n",
            "[flaml.automl: 05-02 17:27:01] {2750} INFO -  at 111.0s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 111.0s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:27:01] {2567} INFO - iteration 801, current learner xgboost\n",
            "INFO:flaml.automl:iteration 801, current learner xgboost\n",
            "[flaml.automl: 05-02 17:27:01] {2750} INFO -  at 111.2s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 111.2s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:27:02] {2567} INFO - iteration 802, current learner xgboost\n",
            "INFO:flaml.automl:iteration 802, current learner xgboost\n",
            "[flaml.automl: 05-02 17:27:02] {2750} INFO -  at 111.3s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 111.3s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:27:02] {2567} INFO - iteration 803, current learner xgboost\n",
            "INFO:flaml.automl:iteration 803, current learner xgboost\n",
            "[flaml.automl: 05-02 17:27:02] {2750} INFO -  at 111.4s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 111.4s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:27:02] {2567} INFO - iteration 804, current learner xgboost\n",
            "INFO:flaml.automl:iteration 804, current learner xgboost\n",
            "[flaml.automl: 05-02 17:27:02] {2750} INFO -  at 111.5s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 111.5s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:27:02] {2567} INFO - iteration 805, current learner xgboost\n",
            "INFO:flaml.automl:iteration 805, current learner xgboost\n",
            "[flaml.automl: 05-02 17:27:02] {2750} INFO -  at 111.6s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 111.6s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:27:02] {2567} INFO - iteration 806, current learner xgboost\n",
            "INFO:flaml.automl:iteration 806, current learner xgboost\n",
            "[flaml.automl: 05-02 17:27:02] {2750} INFO -  at 111.7s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 111.7s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:27:02] {2567} INFO - iteration 807, current learner xgboost\n",
            "INFO:flaml.automl:iteration 807, current learner xgboost\n",
            "[flaml.automl: 05-02 17:27:02] {2750} INFO -  at 111.8s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 111.8s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:27:02] {2567} INFO - iteration 808, current learner xgboost\n",
            "INFO:flaml.automl:iteration 808, current learner xgboost\n",
            "[flaml.automl: 05-02 17:27:02] {2750} INFO -  at 111.9s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 111.9s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:27:02] {2567} INFO - iteration 809, current learner xgboost\n",
            "INFO:flaml.automl:iteration 809, current learner xgboost\n",
            "[flaml.automl: 05-02 17:27:02] {2750} INFO -  at 112.0s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 112.0s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:27:02] {2567} INFO - iteration 810, current learner xgboost\n",
            "INFO:flaml.automl:iteration 810, current learner xgboost\n",
            "[flaml.automl: 05-02 17:27:02] {2750} INFO -  at 112.1s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 112.1s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:27:02] {2567} INFO - iteration 811, current learner xgboost\n",
            "INFO:flaml.automl:iteration 811, current learner xgboost\n",
            "[flaml.automl: 05-02 17:27:03] {2750} INFO -  at 112.2s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 112.2s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:27:03] {2567} INFO - iteration 812, current learner xgboost\n",
            "INFO:flaml.automl:iteration 812, current learner xgboost\n",
            "[flaml.automl: 05-02 17:27:03] {2750} INFO -  at 112.3s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 112.3s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:27:03] {2567} INFO - iteration 813, current learner xgboost\n",
            "INFO:flaml.automl:iteration 813, current learner xgboost\n",
            "[flaml.automl: 05-02 17:27:03] {2750} INFO -  at 112.4s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 112.4s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:27:03] {2567} INFO - iteration 814, current learner xgboost\n",
            "INFO:flaml.automl:iteration 814, current learner xgboost\n",
            "[flaml.automl: 05-02 17:27:03] {2750} INFO -  at 112.5s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 112.5s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:27:03] {2567} INFO - iteration 815, current learner xgboost\n",
            "INFO:flaml.automl:iteration 815, current learner xgboost\n",
            "[flaml.automl: 05-02 17:27:03] {2750} INFO -  at 112.6s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 112.6s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:27:03] {2567} INFO - iteration 816, current learner xgboost\n",
            "INFO:flaml.automl:iteration 816, current learner xgboost\n",
            "[flaml.automl: 05-02 17:27:03] {2750} INFO -  at 112.7s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 112.7s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:27:03] {2567} INFO - iteration 817, current learner xgboost\n",
            "INFO:flaml.automl:iteration 817, current learner xgboost\n",
            "[flaml.automl: 05-02 17:27:03] {2750} INFO -  at 112.8s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 112.8s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:27:03] {2567} INFO - iteration 818, current learner xgboost\n",
            "INFO:flaml.automl:iteration 818, current learner xgboost\n",
            "[flaml.automl: 05-02 17:27:03] {2750} INFO -  at 112.9s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 112.9s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:27:03] {2567} INFO - iteration 819, current learner xgboost\n",
            "INFO:flaml.automl:iteration 819, current learner xgboost\n",
            "[flaml.automl: 05-02 17:27:03] {2750} INFO -  at 113.0s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 113.0s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:27:03] {2567} INFO - iteration 820, current learner xgboost\n",
            "INFO:flaml.automl:iteration 820, current learner xgboost\n",
            "[flaml.automl: 05-02 17:27:03] {2750} INFO -  at 113.1s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 113.1s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:27:03] {2567} INFO - iteration 821, current learner xgboost\n",
            "INFO:flaml.automl:iteration 821, current learner xgboost\n",
            "[flaml.automl: 05-02 17:27:04] {2750} INFO -  at 113.2s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 113.2s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:27:04] {2567} INFO - iteration 822, current learner xgboost\n",
            "INFO:flaml.automl:iteration 822, current learner xgboost\n",
            "[flaml.automl: 05-02 17:27:04] {2750} INFO -  at 113.3s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 113.3s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:27:04] {2567} INFO - iteration 823, current learner xgboost\n",
            "INFO:flaml.automl:iteration 823, current learner xgboost\n",
            "[flaml.automl: 05-02 17:27:04] {2750} INFO -  at 113.4s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 113.4s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:27:04] {2567} INFO - iteration 824, current learner xgboost\n",
            "INFO:flaml.automl:iteration 824, current learner xgboost\n",
            "[flaml.automl: 05-02 17:27:04] {2750} INFO -  at 113.5s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 113.5s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:27:04] {2567} INFO - iteration 825, current learner xgboost\n",
            "INFO:flaml.automl:iteration 825, current learner xgboost\n",
            "[flaml.automl: 05-02 17:27:04] {2750} INFO -  at 113.6s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 113.6s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:27:04] {2567} INFO - iteration 826, current learner xgboost\n",
            "INFO:flaml.automl:iteration 826, current learner xgboost\n",
            "[flaml.automl: 05-02 17:27:04] {2750} INFO -  at 113.7s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 113.7s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:27:04] {2567} INFO - iteration 827, current learner xgboost\n",
            "INFO:flaml.automl:iteration 827, current learner xgboost\n",
            "[flaml.automl: 05-02 17:27:04] {2750} INFO -  at 113.8s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 113.8s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:27:04] {2567} INFO - iteration 828, current learner xgboost\n",
            "INFO:flaml.automl:iteration 828, current learner xgboost\n",
            "[flaml.automl: 05-02 17:27:04] {2750} INFO -  at 113.9s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 113.9s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:27:04] {2567} INFO - iteration 829, current learner xgboost\n",
            "INFO:flaml.automl:iteration 829, current learner xgboost\n",
            "[flaml.automl: 05-02 17:27:04] {2750} INFO -  at 114.0s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 114.0s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:27:04] {2567} INFO - iteration 830, current learner xgboost\n",
            "INFO:flaml.automl:iteration 830, current learner xgboost\n",
            "[flaml.automl: 05-02 17:27:04] {2750} INFO -  at 114.1s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 114.1s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:27:04] {2567} INFO - iteration 831, current learner xgboost\n",
            "INFO:flaml.automl:iteration 831, current learner xgboost\n",
            "[flaml.automl: 05-02 17:27:05] {2750} INFO -  at 114.2s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 114.2s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:27:05] {2567} INFO - iteration 832, current learner xgboost\n",
            "INFO:flaml.automl:iteration 832, current learner xgboost\n",
            "[flaml.automl: 05-02 17:27:05] {2750} INFO -  at 114.3s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 114.3s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:27:05] {2567} INFO - iteration 833, current learner xgboost\n",
            "INFO:flaml.automl:iteration 833, current learner xgboost\n",
            "[flaml.automl: 05-02 17:27:05] {2750} INFO -  at 114.4s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 114.4s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:27:05] {2567} INFO - iteration 834, current learner xgboost\n",
            "INFO:flaml.automl:iteration 834, current learner xgboost\n",
            "[flaml.automl: 05-02 17:27:05] {2750} INFO -  at 114.5s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 114.5s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:27:05] {2567} INFO - iteration 835, current learner xgboost\n",
            "INFO:flaml.automl:iteration 835, current learner xgboost\n",
            "[flaml.automl: 05-02 17:27:05] {2750} INFO -  at 114.7s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 114.7s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:27:05] {2567} INFO - iteration 836, current learner xgboost\n",
            "INFO:flaml.automl:iteration 836, current learner xgboost\n",
            "[flaml.automl: 05-02 17:27:05] {2750} INFO -  at 114.8s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 114.8s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:27:05] {2567} INFO - iteration 837, current learner xgboost\n",
            "INFO:flaml.automl:iteration 837, current learner xgboost\n",
            "[flaml.automl: 05-02 17:27:05] {2750} INFO -  at 115.0s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 115.0s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:27:05] {2567} INFO - iteration 838, current learner xgboost\n",
            "INFO:flaml.automl:iteration 838, current learner xgboost\n",
            "[flaml.automl: 05-02 17:27:05] {2750} INFO -  at 115.1s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 115.1s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:27:05] {2567} INFO - iteration 839, current learner xgboost\n",
            "INFO:flaml.automl:iteration 839, current learner xgboost\n",
            "[flaml.automl: 05-02 17:27:06] {2750} INFO -  at 115.2s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 115.2s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:27:06] {2567} INFO - iteration 840, current learner xgboost\n",
            "INFO:flaml.automl:iteration 840, current learner xgboost\n",
            "[flaml.automl: 05-02 17:27:06] {2750} INFO -  at 115.3s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 115.3s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:27:06] {2567} INFO - iteration 841, current learner xgboost\n",
            "INFO:flaml.automl:iteration 841, current learner xgboost\n",
            "[flaml.automl: 05-02 17:27:06] {2750} INFO -  at 115.4s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 115.4s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:27:06] {2567} INFO - iteration 842, current learner xgboost\n",
            "INFO:flaml.automl:iteration 842, current learner xgboost\n",
            "[flaml.automl: 05-02 17:27:06] {2750} INFO -  at 115.5s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 115.5s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:27:06] {2567} INFO - iteration 843, current learner xgboost\n",
            "INFO:flaml.automl:iteration 843, current learner xgboost\n",
            "[flaml.automl: 05-02 17:27:06] {2750} INFO -  at 115.6s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 115.6s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:27:06] {2567} INFO - iteration 844, current learner xgboost\n",
            "INFO:flaml.automl:iteration 844, current learner xgboost\n",
            "[flaml.automl: 05-02 17:27:06] {2750} INFO -  at 115.7s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 115.7s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:27:06] {2567} INFO - iteration 845, current learner xgboost\n",
            "INFO:flaml.automl:iteration 845, current learner xgboost\n",
            "[flaml.automl: 05-02 17:27:06] {2750} INFO -  at 115.8s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 115.8s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:27:06] {2567} INFO - iteration 846, current learner xgboost\n",
            "INFO:flaml.automl:iteration 846, current learner xgboost\n",
            "[flaml.automl: 05-02 17:27:06] {2750} INFO -  at 115.9s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 115.9s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:27:06] {2567} INFO - iteration 847, current learner xgboost\n",
            "INFO:flaml.automl:iteration 847, current learner xgboost\n",
            "[flaml.automl: 05-02 17:27:06] {2750} INFO -  at 116.0s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 116.0s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:27:06] {2567} INFO - iteration 848, current learner xgboost\n",
            "INFO:flaml.automl:iteration 848, current learner xgboost\n",
            "[flaml.automl: 05-02 17:27:06] {2750} INFO -  at 116.1s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 116.1s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:27:06] {2567} INFO - iteration 849, current learner xgboost\n",
            "INFO:flaml.automl:iteration 849, current learner xgboost\n",
            "[flaml.automl: 05-02 17:27:07] {2750} INFO -  at 116.2s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 116.2s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:27:07] {2567} INFO - iteration 850, current learner xgboost\n",
            "INFO:flaml.automl:iteration 850, current learner xgboost\n",
            "[flaml.automl: 05-02 17:27:07] {2750} INFO -  at 116.3s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 116.3s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:27:07] {2567} INFO - iteration 851, current learner xgboost\n",
            "INFO:flaml.automl:iteration 851, current learner xgboost\n",
            "[flaml.automl: 05-02 17:27:07] {2750} INFO -  at 116.5s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 116.5s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:27:07] {2567} INFO - iteration 852, current learner xgboost\n",
            "INFO:flaml.automl:iteration 852, current learner xgboost\n",
            "[flaml.automl: 05-02 17:27:07] {2750} INFO -  at 116.6s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 116.6s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:27:07] {2567} INFO - iteration 853, current learner xgboost\n",
            "INFO:flaml.automl:iteration 853, current learner xgboost\n",
            "[flaml.automl: 05-02 17:27:07] {2750} INFO -  at 116.8s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 116.8s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:27:07] {2567} INFO - iteration 854, current learner xgboost\n",
            "INFO:flaml.automl:iteration 854, current learner xgboost\n",
            "[flaml.automl: 05-02 17:27:07] {2750} INFO -  at 117.0s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 117.0s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:27:07] {2567} INFO - iteration 855, current learner xgboost\n",
            "INFO:flaml.automl:iteration 855, current learner xgboost\n",
            "[flaml.automl: 05-02 17:27:07] {2750} INFO -  at 117.1s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 117.1s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:27:07] {2567} INFO - iteration 856, current learner xgboost\n",
            "INFO:flaml.automl:iteration 856, current learner xgboost\n",
            "[flaml.automl: 05-02 17:27:08] {2750} INFO -  at 117.2s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 117.2s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:27:08] {2567} INFO - iteration 857, current learner xgboost\n",
            "INFO:flaml.automl:iteration 857, current learner xgboost\n",
            "[flaml.automl: 05-02 17:27:08] {2750} INFO -  at 117.4s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 117.4s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:27:08] {2567} INFO - iteration 858, current learner xgboost\n",
            "INFO:flaml.automl:iteration 858, current learner xgboost\n",
            "[flaml.automl: 05-02 17:27:08] {2750} INFO -  at 117.6s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 117.6s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:27:08] {2567} INFO - iteration 859, current learner extra_tree\n",
            "INFO:flaml.automl:iteration 859, current learner extra_tree\n",
            "[flaml.automl: 05-02 17:27:09] {2750} INFO -  at 119.1s,\testimator extra_tree's best error=0.1895,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 119.1s,\testimator extra_tree's best error=0.1895,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:27:09] {2567} INFO - iteration 860, current learner extra_tree\n",
            "INFO:flaml.automl:iteration 860, current learner extra_tree\n",
            "[flaml.automl: 05-02 17:27:11] {2750} INFO -  at 120.4s,\testimator extra_tree's best error=0.1772,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 120.4s,\testimator extra_tree's best error=0.1772,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:27:11] {2567} INFO - iteration 861, current learner extra_tree\n",
            "INFO:flaml.automl:iteration 861, current learner extra_tree\n",
            "[flaml.automl: 05-02 17:27:12] {2750} INFO -  at 121.9s,\testimator extra_tree's best error=0.1772,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 121.9s,\testimator extra_tree's best error=0.1772,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:27:12] {2567} INFO - iteration 862, current learner xgboost\n",
            "INFO:flaml.automl:iteration 862, current learner xgboost\n",
            "[flaml.automl: 05-02 17:27:12] {2750} INFO -  at 122.0s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 122.0s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:27:12] {2567} INFO - iteration 863, current learner extra_tree\n",
            "INFO:flaml.automl:iteration 863, current learner extra_tree\n",
            "[flaml.automl: 05-02 17:27:14] {2750} INFO -  at 123.5s,\testimator extra_tree's best error=0.1657,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 123.5s,\testimator extra_tree's best error=0.1657,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:27:14] {2567} INFO - iteration 864, current learner extra_tree\n",
            "INFO:flaml.automl:iteration 864, current learner extra_tree\n",
            "[flaml.automl: 05-02 17:27:15] {2750} INFO -  at 125.0s,\testimator extra_tree's best error=0.1657,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 125.0s,\testimator extra_tree's best error=0.1657,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:27:15] {2567} INFO - iteration 865, current learner extra_tree\n",
            "INFO:flaml.automl:iteration 865, current learner extra_tree\n",
            "[flaml.automl: 05-02 17:27:17] {2750} INFO -  at 126.4s,\testimator extra_tree's best error=0.1657,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 126.4s,\testimator extra_tree's best error=0.1657,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:27:17] {2567} INFO - iteration 866, current learner extra_tree\n",
            "INFO:flaml.automl:iteration 866, current learner extra_tree\n",
            "[flaml.automl: 05-02 17:27:18] {2750} INFO -  at 127.7s,\testimator extra_tree's best error=0.1657,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 127.7s,\testimator extra_tree's best error=0.1657,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:27:18] {2567} INFO - iteration 867, current learner extra_tree\n",
            "INFO:flaml.automl:iteration 867, current learner extra_tree\n",
            "[flaml.automl: 05-02 17:27:19] {2750} INFO -  at 129.0s,\testimator extra_tree's best error=0.1657,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 129.0s,\testimator extra_tree's best error=0.1657,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:27:19] {2567} INFO - iteration 868, current learner extra_tree\n",
            "INFO:flaml.automl:iteration 868, current learner extra_tree\n",
            "[flaml.automl: 05-02 17:27:21] {2750} INFO -  at 130.7s,\testimator extra_tree's best error=0.1657,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 130.7s,\testimator extra_tree's best error=0.1657,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:27:21] {2567} INFO - iteration 869, current learner extra_tree\n",
            "INFO:flaml.automl:iteration 869, current learner extra_tree\n",
            "[flaml.automl: 05-02 17:27:23] {2750} INFO -  at 132.2s,\testimator extra_tree's best error=0.1657,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 132.2s,\testimator extra_tree's best error=0.1657,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:27:23] {2567} INFO - iteration 870, current learner extra_tree\n",
            "INFO:flaml.automl:iteration 870, current learner extra_tree\n",
            "[flaml.automl: 05-02 17:27:24] {2750} INFO -  at 133.7s,\testimator extra_tree's best error=0.1657,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 133.7s,\testimator extra_tree's best error=0.1657,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:27:24] {2567} INFO - iteration 871, current learner extra_tree\n",
            "INFO:flaml.automl:iteration 871, current learner extra_tree\n",
            "[flaml.automl: 05-02 17:27:25] {2750} INFO -  at 135.0s,\testimator extra_tree's best error=0.1657,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 135.0s,\testimator extra_tree's best error=0.1657,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:27:25] {2567} INFO - iteration 872, current learner xgboost\n",
            "INFO:flaml.automl:iteration 872, current learner xgboost\n",
            "[flaml.automl: 05-02 17:27:25] {2750} INFO -  at 135.1s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 135.1s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:27:25] {2567} INFO - iteration 873, current learner extra_tree\n",
            "INFO:flaml.automl:iteration 873, current learner extra_tree\n",
            "[flaml.automl: 05-02 17:27:27] {2750} INFO -  at 136.7s,\testimator extra_tree's best error=0.1657,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 136.7s,\testimator extra_tree's best error=0.1657,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:27:27] {2567} INFO - iteration 874, current learner xgboost\n",
            "INFO:flaml.automl:iteration 874, current learner xgboost\n",
            "[flaml.automl: 05-02 17:27:27] {2750} INFO -  at 136.7s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 136.7s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:27:27] {2567} INFO - iteration 875, current learner xgboost\n",
            "INFO:flaml.automl:iteration 875, current learner xgboost\n",
            "[flaml.automl: 05-02 17:27:27] {2750} INFO -  at 136.8s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 136.8s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:27:27] {2567} INFO - iteration 876, current learner extra_tree\n",
            "INFO:flaml.automl:iteration 876, current learner extra_tree\n",
            "[flaml.automl: 05-02 17:27:28] {2750} INFO -  at 138.1s,\testimator extra_tree's best error=0.1657,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 138.1s,\testimator extra_tree's best error=0.1657,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:27:28] {2567} INFO - iteration 877, current learner xgboost\n",
            "INFO:flaml.automl:iteration 877, current learner xgboost\n",
            "[flaml.automl: 05-02 17:27:29] {2750} INFO -  at 138.2s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 138.2s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:27:29] {2567} INFO - iteration 878, current learner extra_tree\n",
            "INFO:flaml.automl:iteration 878, current learner extra_tree\n",
            "[flaml.automl: 05-02 17:27:30] {2750} INFO -  at 139.5s,\testimator extra_tree's best error=0.1657,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 139.5s,\testimator extra_tree's best error=0.1657,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:27:30] {2567} INFO - iteration 879, current learner xgboost\n",
            "INFO:flaml.automl:iteration 879, current learner xgboost\n",
            "[flaml.automl: 05-02 17:27:30] {2750} INFO -  at 139.6s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 139.6s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:27:30] {2567} INFO - iteration 880, current learner xgboost\n",
            "INFO:flaml.automl:iteration 880, current learner xgboost\n",
            "[flaml.automl: 05-02 17:27:30] {2750} INFO -  at 139.7s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 139.7s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:27:30] {2567} INFO - iteration 881, current learner xgboost\n",
            "INFO:flaml.automl:iteration 881, current learner xgboost\n",
            "[flaml.automl: 05-02 17:27:30] {2750} INFO -  at 139.8s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "INFO:flaml.automl: at 139.8s,\testimator xgboost's best error=0.1655,\tbest estimator xgboost's best error=0.1655\n",
            "[flaml.automl: 05-02 17:27:30] {2567} INFO - iteration 882, current learner extra_tree\n",
            "INFO:flaml.automl:iteration 882, current learner extra_tree\n",
            "[flaml.automl: 05-02 17:27:32] {2750} INFO -  at 141.3s,\testimator extra_tree's best error=0.1588,\tbest estimator extra_tree's best error=0.1588\n",
            "INFO:flaml.automl: at 141.3s,\testimator extra_tree's best error=0.1588,\tbest estimator extra_tree's best error=0.1588\n",
            "[flaml.automl: 05-02 17:27:32] {2567} INFO - iteration 883, current learner extra_tree\n",
            "INFO:flaml.automl:iteration 883, current learner extra_tree\n",
            "[flaml.automl: 05-02 17:27:33] {2750} INFO -  at 142.6s,\testimator extra_tree's best error=0.1588,\tbest estimator extra_tree's best error=0.1588\n",
            "INFO:flaml.automl: at 142.6s,\testimator extra_tree's best error=0.1588,\tbest estimator extra_tree's best error=0.1588\n",
            "[flaml.automl: 05-02 17:27:33] {2567} INFO - iteration 884, current learner extra_tree\n",
            "INFO:flaml.automl:iteration 884, current learner extra_tree\n",
            "[flaml.automl: 05-02 17:27:34] {2750} INFO -  at 144.1s,\testimator extra_tree's best error=0.1588,\tbest estimator extra_tree's best error=0.1588\n",
            "INFO:flaml.automl: at 144.1s,\testimator extra_tree's best error=0.1588,\tbest estimator extra_tree's best error=0.1588\n",
            "[flaml.automl: 05-02 17:27:34] {2567} INFO - iteration 885, current learner extra_tree\n",
            "INFO:flaml.automl:iteration 885, current learner extra_tree\n",
            "[flaml.automl: 05-02 17:27:36] {2750} INFO -  at 145.3s,\testimator extra_tree's best error=0.1588,\tbest estimator extra_tree's best error=0.1588\n",
            "INFO:flaml.automl: at 145.3s,\testimator extra_tree's best error=0.1588,\tbest estimator extra_tree's best error=0.1588\n",
            "[flaml.automl: 05-02 17:27:36] {2567} INFO - iteration 886, current learner extra_tree\n",
            "INFO:flaml.automl:iteration 886, current learner extra_tree\n",
            "[flaml.automl: 05-02 17:27:37] {2750} INFO -  at 146.7s,\testimator extra_tree's best error=0.1588,\tbest estimator extra_tree's best error=0.1588\n",
            "INFO:flaml.automl: at 146.7s,\testimator extra_tree's best error=0.1588,\tbest estimator extra_tree's best error=0.1588\n",
            "[flaml.automl: 05-02 17:27:37] {2567} INFO - iteration 887, current learner extra_tree\n",
            "INFO:flaml.automl:iteration 887, current learner extra_tree\n",
            "[flaml.automl: 05-02 17:27:39] {2750} INFO -  at 148.3s,\testimator extra_tree's best error=0.1588,\tbest estimator extra_tree's best error=0.1588\n",
            "INFO:flaml.automl: at 148.3s,\testimator extra_tree's best error=0.1588,\tbest estimator extra_tree's best error=0.1588\n",
            "[flaml.automl: 05-02 17:27:39] {2567} INFO - iteration 888, current learner extra_tree\n",
            "INFO:flaml.automl:iteration 888, current learner extra_tree\n",
            "[flaml.automl: 05-02 17:27:40] {2750} INFO -  at 149.6s,\testimator extra_tree's best error=0.1588,\tbest estimator extra_tree's best error=0.1588\n",
            "INFO:flaml.automl: at 149.6s,\testimator extra_tree's best error=0.1588,\tbest estimator extra_tree's best error=0.1588\n",
            "[flaml.automl: 05-02 17:27:40] {2567} INFO - iteration 889, current learner extra_tree\n",
            "INFO:flaml.automl:iteration 889, current learner extra_tree\n",
            "[flaml.automl: 05-02 17:27:41] {2750} INFO -  at 150.9s,\testimator extra_tree's best error=0.1588,\tbest estimator extra_tree's best error=0.1588\n",
            "INFO:flaml.automl: at 150.9s,\testimator extra_tree's best error=0.1588,\tbest estimator extra_tree's best error=0.1588\n",
            "[flaml.automl: 05-02 17:27:41] {2567} INFO - iteration 890, current learner extra_tree\n",
            "INFO:flaml.automl:iteration 890, current learner extra_tree\n",
            "[flaml.automl: 05-02 17:27:43] {2750} INFO -  at 152.4s,\testimator extra_tree's best error=0.1588,\tbest estimator extra_tree's best error=0.1588\n",
            "INFO:flaml.automl: at 152.4s,\testimator extra_tree's best error=0.1588,\tbest estimator extra_tree's best error=0.1588\n",
            "[flaml.automl: 05-02 17:27:43] {2567} INFO - iteration 891, current learner xgboost\n",
            "INFO:flaml.automl:iteration 891, current learner xgboost\n",
            "[flaml.automl: 05-02 17:27:43] {2750} INFO -  at 152.4s,\testimator xgboost's best error=0.1655,\tbest estimator extra_tree's best error=0.1588\n",
            "INFO:flaml.automl: at 152.4s,\testimator xgboost's best error=0.1655,\tbest estimator extra_tree's best error=0.1588\n",
            "[flaml.automl: 05-02 17:27:43] {2567} INFO - iteration 892, current learner extra_tree\n",
            "INFO:flaml.automl:iteration 892, current learner extra_tree\n",
            "[flaml.automl: 05-02 17:27:44] {2750} INFO -  at 153.9s,\testimator extra_tree's best error=0.1588,\tbest estimator extra_tree's best error=0.1588\n",
            "INFO:flaml.automl: at 153.9s,\testimator extra_tree's best error=0.1588,\tbest estimator extra_tree's best error=0.1588\n",
            "[flaml.automl: 05-02 17:27:44] {2567} INFO - iteration 893, current learner extra_tree\n",
            "INFO:flaml.automl:iteration 893, current learner extra_tree\n",
            "[flaml.automl: 05-02 17:27:46] {2750} INFO -  at 155.4s,\testimator extra_tree's best error=0.1588,\tbest estimator extra_tree's best error=0.1588\n",
            "INFO:flaml.automl: at 155.4s,\testimator extra_tree's best error=0.1588,\tbest estimator extra_tree's best error=0.1588\n",
            "[flaml.automl: 05-02 17:27:46] {2567} INFO - iteration 894, current learner extra_tree\n",
            "INFO:flaml.automl:iteration 894, current learner extra_tree\n",
            "[flaml.automl: 05-02 17:27:47] {2750} INFO -  at 156.6s,\testimator extra_tree's best error=0.1588,\tbest estimator extra_tree's best error=0.1588\n",
            "INFO:flaml.automl: at 156.6s,\testimator extra_tree's best error=0.1588,\tbest estimator extra_tree's best error=0.1588\n",
            "[flaml.automl: 05-02 17:27:47] {2567} INFO - iteration 895, current learner extra_tree\n",
            "INFO:flaml.automl:iteration 895, current learner extra_tree\n",
            "[flaml.automl: 05-02 17:27:48] {2750} INFO -  at 157.9s,\testimator extra_tree's best error=0.1588,\tbest estimator extra_tree's best error=0.1588\n",
            "INFO:flaml.automl: at 157.9s,\testimator extra_tree's best error=0.1588,\tbest estimator extra_tree's best error=0.1588\n",
            "[flaml.automl: 05-02 17:27:48] {2567} INFO - iteration 896, current learner extra_tree\n",
            "INFO:flaml.automl:iteration 896, current learner extra_tree\n",
            "[flaml.automl: 05-02 17:27:50] {2750} INFO -  at 159.6s,\testimator extra_tree's best error=0.1588,\tbest estimator extra_tree's best error=0.1588\n",
            "INFO:flaml.automl: at 159.6s,\testimator extra_tree's best error=0.1588,\tbest estimator extra_tree's best error=0.1588\n",
            "[flaml.automl: 05-02 17:27:50] {2567} INFO - iteration 897, current learner extra_tree\n",
            "INFO:flaml.automl:iteration 897, current learner extra_tree\n",
            "[flaml.automl: 05-02 17:27:51] {2750} INFO -  at 160.9s,\testimator extra_tree's best error=0.1588,\tbest estimator extra_tree's best error=0.1588\n",
            "INFO:flaml.automl: at 160.9s,\testimator extra_tree's best error=0.1588,\tbest estimator extra_tree's best error=0.1588\n",
            "[flaml.automl: 05-02 17:27:51] {2567} INFO - iteration 898, current learner extra_tree\n",
            "INFO:flaml.automl:iteration 898, current learner extra_tree\n",
            "[flaml.automl: 05-02 17:27:53] {2750} INFO -  at 162.2s,\testimator extra_tree's best error=0.1588,\tbest estimator extra_tree's best error=0.1588\n",
            "INFO:flaml.automl: at 162.2s,\testimator extra_tree's best error=0.1588,\tbest estimator extra_tree's best error=0.1588\n",
            "[flaml.automl: 05-02 17:27:53] {2567} INFO - iteration 899, current learner extra_tree\n",
            "INFO:flaml.automl:iteration 899, current learner extra_tree\n",
            "[flaml.automl: 05-02 17:27:54] {2750} INFO -  at 164.0s,\testimator extra_tree's best error=0.1588,\tbest estimator extra_tree's best error=0.1588\n",
            "INFO:flaml.automl: at 164.0s,\testimator extra_tree's best error=0.1588,\tbest estimator extra_tree's best error=0.1588\n",
            "[flaml.automl: 05-02 17:27:54] {2567} INFO - iteration 900, current learner extra_tree\n",
            "INFO:flaml.automl:iteration 900, current learner extra_tree\n",
            "[flaml.automl: 05-02 17:27:56] {2750} INFO -  at 165.5s,\testimator extra_tree's best error=0.1588,\tbest estimator extra_tree's best error=0.1588\n",
            "INFO:flaml.automl: at 165.5s,\testimator extra_tree's best error=0.1588,\tbest estimator extra_tree's best error=0.1588\n",
            "[flaml.automl: 05-02 17:27:56] {2567} INFO - iteration 901, current learner extra_tree\n",
            "INFO:flaml.automl:iteration 901, current learner extra_tree\n",
            "[flaml.automl: 05-02 17:27:57] {2750} INFO -  at 166.7s,\testimator extra_tree's best error=0.1588,\tbest estimator extra_tree's best error=0.1588\n",
            "INFO:flaml.automl: at 166.7s,\testimator extra_tree's best error=0.1588,\tbest estimator extra_tree's best error=0.1588\n",
            "[flaml.automl: 05-02 17:27:57] {2567} INFO - iteration 902, current learner extra_tree\n",
            "INFO:flaml.automl:iteration 902, current learner extra_tree\n",
            "[flaml.automl: 05-02 17:27:58] {2750} INFO -  at 168.0s,\testimator extra_tree's best error=0.1588,\tbest estimator extra_tree's best error=0.1588\n",
            "INFO:flaml.automl: at 168.0s,\testimator extra_tree's best error=0.1588,\tbest estimator extra_tree's best error=0.1588\n",
            "[flaml.automl: 05-02 17:27:58] {2567} INFO - iteration 903, current learner extra_tree\n",
            "INFO:flaml.automl:iteration 903, current learner extra_tree\n",
            "[flaml.automl: 05-02 17:28:00] {2750} INFO -  at 169.3s,\testimator extra_tree's best error=0.1588,\tbest estimator extra_tree's best error=0.1588\n",
            "INFO:flaml.automl: at 169.3s,\testimator extra_tree's best error=0.1588,\tbest estimator extra_tree's best error=0.1588\n",
            "[flaml.automl: 05-02 17:28:00] {2567} INFO - iteration 904, current learner extra_tree\n",
            "INFO:flaml.automl:iteration 904, current learner extra_tree\n",
            "[flaml.automl: 05-02 17:28:01] {2750} INFO -  at 170.5s,\testimator extra_tree's best error=0.1588,\tbest estimator extra_tree's best error=0.1588\n",
            "INFO:flaml.automl: at 170.5s,\testimator extra_tree's best error=0.1588,\tbest estimator extra_tree's best error=0.1588\n",
            "[flaml.automl: 05-02 17:28:01] {2567} INFO - iteration 905, current learner extra_tree\n",
            "INFO:flaml.automl:iteration 905, current learner extra_tree\n",
            "[flaml.automl: 05-02 17:28:02] {2750} INFO -  at 171.8s,\testimator extra_tree's best error=0.1588,\tbest estimator extra_tree's best error=0.1588\n",
            "INFO:flaml.automl: at 171.8s,\testimator extra_tree's best error=0.1588,\tbest estimator extra_tree's best error=0.1588\n",
            "[flaml.automl: 05-02 17:28:02] {2567} INFO - iteration 906, current learner xgboost\n",
            "INFO:flaml.automl:iteration 906, current learner xgboost\n",
            "[flaml.automl: 05-02 17:28:02] {2750} INFO -  at 171.9s,\testimator xgboost's best error=0.1655,\tbest estimator extra_tree's best error=0.1588\n",
            "INFO:flaml.automl: at 171.9s,\testimator xgboost's best error=0.1655,\tbest estimator extra_tree's best error=0.1588\n",
            "[flaml.automl: 05-02 17:28:02] {2567} INFO - iteration 907, current learner extra_tree\n",
            "INFO:flaml.automl:iteration 907, current learner extra_tree\n",
            "[flaml.automl: 05-02 17:28:04] {2750} INFO -  at 173.5s,\testimator extra_tree's best error=0.1588,\tbest estimator extra_tree's best error=0.1588\n",
            "INFO:flaml.automl: at 173.5s,\testimator extra_tree's best error=0.1588,\tbest estimator extra_tree's best error=0.1588\n",
            "[flaml.automl: 05-02 17:28:04] {2567} INFO - iteration 908, current learner extra_tree\n",
            "INFO:flaml.automl:iteration 908, current learner extra_tree\n",
            "[flaml.automl: 05-02 17:28:05] {2750} INFO -  at 174.8s,\testimator extra_tree's best error=0.1588,\tbest estimator extra_tree's best error=0.1588\n",
            "INFO:flaml.automl: at 174.8s,\testimator extra_tree's best error=0.1588,\tbest estimator extra_tree's best error=0.1588\n",
            "[flaml.automl: 05-02 17:28:05] {2567} INFO - iteration 909, current learner extra_tree\n",
            "INFO:flaml.automl:iteration 909, current learner extra_tree\n",
            "[flaml.automl: 05-02 17:28:06] {2750} INFO -  at 176.1s,\testimator extra_tree's best error=0.1588,\tbest estimator extra_tree's best error=0.1588\n",
            "INFO:flaml.automl: at 176.1s,\testimator extra_tree's best error=0.1588,\tbest estimator extra_tree's best error=0.1588\n",
            "[flaml.automl: 05-02 17:28:06] {2567} INFO - iteration 910, current learner extra_tree\n",
            "INFO:flaml.automl:iteration 910, current learner extra_tree\n",
            "[flaml.automl: 05-02 17:28:08] {2750} INFO -  at 177.4s,\testimator extra_tree's best error=0.1588,\tbest estimator extra_tree's best error=0.1588\n",
            "INFO:flaml.automl: at 177.4s,\testimator extra_tree's best error=0.1588,\tbest estimator extra_tree's best error=0.1588\n",
            "[flaml.automl: 05-02 17:28:08] {2567} INFO - iteration 911, current learner xgboost\n",
            "INFO:flaml.automl:iteration 911, current learner xgboost\n",
            "[flaml.automl: 05-02 17:28:08] {2750} INFO -  at 177.4s,\testimator xgboost's best error=0.1655,\tbest estimator extra_tree's best error=0.1588\n",
            "INFO:flaml.automl: at 177.4s,\testimator xgboost's best error=0.1655,\tbest estimator extra_tree's best error=0.1588\n",
            "[flaml.automl: 05-02 17:28:08] {2567} INFO - iteration 912, current learner extra_tree\n",
            "INFO:flaml.automl:iteration 912, current learner extra_tree\n",
            "[flaml.automl: 05-02 17:28:09] {2750} INFO -  at 178.7s,\testimator extra_tree's best error=0.1588,\tbest estimator extra_tree's best error=0.1588\n",
            "INFO:flaml.automl: at 178.7s,\testimator extra_tree's best error=0.1588,\tbest estimator extra_tree's best error=0.1588\n",
            "[flaml.automl: 05-02 17:28:09] {2567} INFO - iteration 913, current learner xgboost\n",
            "INFO:flaml.automl:iteration 913, current learner xgboost\n",
            "[flaml.automl: 05-02 17:28:09] {2750} INFO -  at 178.8s,\testimator xgboost's best error=0.1655,\tbest estimator extra_tree's best error=0.1588\n",
            "INFO:flaml.automl: at 178.8s,\testimator xgboost's best error=0.1655,\tbest estimator extra_tree's best error=0.1588\n",
            "[flaml.automl: 05-02 17:28:09] {2567} INFO - iteration 914, current learner extra_tree\n",
            "INFO:flaml.automl:iteration 914, current learner extra_tree\n",
            "[flaml.automl: 05-02 17:28:11] {2750} INFO -  at 180.4s,\testimator extra_tree's best error=0.1588,\tbest estimator extra_tree's best error=0.1588\n",
            "INFO:flaml.automl: at 180.4s,\testimator extra_tree's best error=0.1588,\tbest estimator extra_tree's best error=0.1588\n",
            "[flaml.automl: 05-02 17:28:11] {2567} INFO - iteration 915, current learner xgboost\n",
            "INFO:flaml.automl:iteration 915, current learner xgboost\n",
            "[flaml.automl: 05-02 17:28:11] {2750} INFO -  at 180.4s,\testimator xgboost's best error=0.1655,\tbest estimator extra_tree's best error=0.1588\n",
            "INFO:flaml.automl: at 180.4s,\testimator xgboost's best error=0.1655,\tbest estimator extra_tree's best error=0.1588\n",
            "[flaml.automl: 05-02 17:28:11] {2567} INFO - iteration 916, current learner extra_tree\n",
            "INFO:flaml.automl:iteration 916, current learner extra_tree\n",
            "[flaml.automl: 05-02 17:28:12] {2750} INFO -  at 181.7s,\testimator extra_tree's best error=0.1588,\tbest estimator extra_tree's best error=0.1588\n",
            "INFO:flaml.automl: at 181.7s,\testimator extra_tree's best error=0.1588,\tbest estimator extra_tree's best error=0.1588\n",
            "[flaml.automl: 05-02 17:28:12] {2567} INFO - iteration 917, current learner extra_tree\n",
            "INFO:flaml.automl:iteration 917, current learner extra_tree\n",
            "[flaml.automl: 05-02 17:28:14] {2750} INFO -  at 183.2s,\testimator extra_tree's best error=0.1588,\tbest estimator extra_tree's best error=0.1588\n",
            "INFO:flaml.automl: at 183.2s,\testimator extra_tree's best error=0.1588,\tbest estimator extra_tree's best error=0.1588\n",
            "[flaml.automl: 05-02 17:28:14] {2567} INFO - iteration 918, current learner extra_tree\n",
            "INFO:flaml.automl:iteration 918, current learner extra_tree\n",
            "[flaml.automl: 05-02 17:28:15] {2750} INFO -  at 184.8s,\testimator extra_tree's best error=0.1588,\tbest estimator extra_tree's best error=0.1588\n",
            "INFO:flaml.automl: at 184.8s,\testimator extra_tree's best error=0.1588,\tbest estimator extra_tree's best error=0.1588\n",
            "[flaml.automl: 05-02 17:28:15] {2567} INFO - iteration 919, current learner extra_tree\n",
            "INFO:flaml.automl:iteration 919, current learner extra_tree\n",
            "[flaml.automl: 05-02 17:28:16] {2750} INFO -  at 186.0s,\testimator extra_tree's best error=0.1588,\tbest estimator extra_tree's best error=0.1588\n",
            "INFO:flaml.automl: at 186.0s,\testimator extra_tree's best error=0.1588,\tbest estimator extra_tree's best error=0.1588\n",
            "[flaml.automl: 05-02 17:28:16] {2567} INFO - iteration 920, current learner extra_tree\n",
            "INFO:flaml.automl:iteration 920, current learner extra_tree\n",
            "[flaml.automl: 05-02 17:28:18] {2750} INFO -  at 187.3s,\testimator extra_tree's best error=0.1588,\tbest estimator extra_tree's best error=0.1588\n",
            "INFO:flaml.automl: at 187.3s,\testimator extra_tree's best error=0.1588,\tbest estimator extra_tree's best error=0.1588\n",
            "[flaml.automl: 05-02 17:28:18] {2567} INFO - iteration 921, current learner extra_tree\n",
            "INFO:flaml.automl:iteration 921, current learner extra_tree\n",
            "[flaml.automl: 05-02 17:28:19] {2750} INFO -  at 188.8s,\testimator extra_tree's best error=0.1588,\tbest estimator extra_tree's best error=0.1588\n",
            "INFO:flaml.automl: at 188.8s,\testimator extra_tree's best error=0.1588,\tbest estimator extra_tree's best error=0.1588\n",
            "[flaml.automl: 05-02 17:28:19] {2567} INFO - iteration 922, current learner extra_tree\n",
            "INFO:flaml.automl:iteration 922, current learner extra_tree\n",
            "[flaml.automl: 05-02 17:28:20] {2750} INFO -  at 190.0s,\testimator extra_tree's best error=0.1588,\tbest estimator extra_tree's best error=0.1588\n",
            "INFO:flaml.automl: at 190.0s,\testimator extra_tree's best error=0.1588,\tbest estimator extra_tree's best error=0.1588\n",
            "[flaml.automl: 05-02 17:28:20] {2567} INFO - iteration 923, current learner extra_tree\n",
            "INFO:flaml.automl:iteration 923, current learner extra_tree\n",
            "[flaml.automl: 05-02 17:28:22] {2750} INFO -  at 191.5s,\testimator extra_tree's best error=0.1588,\tbest estimator extra_tree's best error=0.1588\n",
            "INFO:flaml.automl: at 191.5s,\testimator extra_tree's best error=0.1588,\tbest estimator extra_tree's best error=0.1588\n",
            "[flaml.automl: 05-02 17:28:22] {2567} INFO - iteration 924, current learner xgboost\n",
            "INFO:flaml.automl:iteration 924, current learner xgboost\n",
            "[flaml.automl: 05-02 17:28:22] {2750} INFO -  at 191.6s,\testimator xgboost's best error=0.1655,\tbest estimator extra_tree's best error=0.1588\n",
            "INFO:flaml.automl: at 191.6s,\testimator xgboost's best error=0.1655,\tbest estimator extra_tree's best error=0.1588\n",
            "[flaml.automl: 05-02 17:28:22] {2567} INFO - iteration 925, current learner extra_tree\n",
            "INFO:flaml.automl:iteration 925, current learner extra_tree\n",
            "[flaml.automl: 05-02 17:28:23] {2750} INFO -  at 192.9s,\testimator extra_tree's best error=0.1588,\tbest estimator extra_tree's best error=0.1588\n",
            "INFO:flaml.automl: at 192.9s,\testimator extra_tree's best error=0.1588,\tbest estimator extra_tree's best error=0.1588\n",
            "[flaml.automl: 05-02 17:28:23] {2567} INFO - iteration 926, current learner xgboost\n",
            "INFO:flaml.automl:iteration 926, current learner xgboost\n",
            "[flaml.automl: 05-02 17:28:23] {2750} INFO -  at 193.0s,\testimator xgboost's best error=0.1655,\tbest estimator extra_tree's best error=0.1588\n",
            "INFO:flaml.automl: at 193.0s,\testimator xgboost's best error=0.1655,\tbest estimator extra_tree's best error=0.1588\n",
            "[flaml.automl: 05-02 17:28:23] {2567} INFO - iteration 927, current learner extra_tree\n",
            "INFO:flaml.automl:iteration 927, current learner extra_tree\n",
            "[flaml.automl: 05-02 17:28:25] {2750} INFO -  at 194.3s,\testimator extra_tree's best error=0.1588,\tbest estimator extra_tree's best error=0.1588\n",
            "INFO:flaml.automl: at 194.3s,\testimator extra_tree's best error=0.1588,\tbest estimator extra_tree's best error=0.1588\n",
            "[flaml.automl: 05-02 17:28:25] {2567} INFO - iteration 928, current learner extra_tree\n",
            "INFO:flaml.automl:iteration 928, current learner extra_tree\n",
            "[flaml.automl: 05-02 17:28:26] {2750} INFO -  at 195.6s,\testimator extra_tree's best error=0.1588,\tbest estimator extra_tree's best error=0.1588\n",
            "INFO:flaml.automl: at 195.6s,\testimator extra_tree's best error=0.1588,\tbest estimator extra_tree's best error=0.1588\n",
            "[flaml.automl: 05-02 17:28:26] {2567} INFO - iteration 929, current learner extra_tree\n",
            "INFO:flaml.automl:iteration 929, current learner extra_tree\n",
            "[flaml.automl: 05-02 17:28:27] {2750} INFO -  at 197.1s,\testimator extra_tree's best error=0.1588,\tbest estimator extra_tree's best error=0.1588\n",
            "INFO:flaml.automl: at 197.1s,\testimator extra_tree's best error=0.1588,\tbest estimator extra_tree's best error=0.1588\n",
            "[flaml.automl: 05-02 17:28:27] {2567} INFO - iteration 930, current learner extra_tree\n",
            "INFO:flaml.automl:iteration 930, current learner extra_tree\n",
            "[flaml.automl: 05-02 17:28:29] {2750} INFO -  at 198.3s,\testimator extra_tree's best error=0.1588,\tbest estimator extra_tree's best error=0.1588\n",
            "INFO:flaml.automl: at 198.3s,\testimator extra_tree's best error=0.1588,\tbest estimator extra_tree's best error=0.1588\n",
            "[flaml.automl: 05-02 17:28:29] {2567} INFO - iteration 931, current learner extra_tree\n",
            "INFO:flaml.automl:iteration 931, current learner extra_tree\n",
            "[flaml.automl: 05-02 17:28:30] {2750} INFO -  at 199.7s,\testimator extra_tree's best error=0.1588,\tbest estimator extra_tree's best error=0.1588\n",
            "INFO:flaml.automl: at 199.7s,\testimator extra_tree's best error=0.1588,\tbest estimator extra_tree's best error=0.1588\n",
            "[flaml.automl: 05-02 17:28:30] {2567} INFO - iteration 932, current learner xgboost\n",
            "INFO:flaml.automl:iteration 932, current learner xgboost\n",
            "[flaml.automl: 05-02 17:28:30] {2750} INFO -  at 199.8s,\testimator xgboost's best error=0.1655,\tbest estimator extra_tree's best error=0.1588\n",
            "INFO:flaml.automl: at 199.8s,\testimator xgboost's best error=0.1655,\tbest estimator extra_tree's best error=0.1588\n",
            "[flaml.automl: 05-02 17:28:30] {2567} INFO - iteration 933, current learner xgboost\n",
            "INFO:flaml.automl:iteration 933, current learner xgboost\n",
            "[flaml.automl: 05-02 17:28:30] {2750} INFO -  at 199.9s,\testimator xgboost's best error=0.1655,\tbest estimator extra_tree's best error=0.1588\n",
            "INFO:flaml.automl: at 199.9s,\testimator xgboost's best error=0.1655,\tbest estimator extra_tree's best error=0.1588\n",
            "[flaml.automl: 05-02 17:28:30] {2567} INFO - iteration 934, current learner xgboost\n",
            "INFO:flaml.automl:iteration 934, current learner xgboost\n",
            "[flaml.automl: 05-02 17:28:30] {2750} INFO -  at 200.0s,\testimator xgboost's best error=0.1655,\tbest estimator extra_tree's best error=0.1588\n",
            "INFO:flaml.automl: at 200.0s,\testimator xgboost's best error=0.1655,\tbest estimator extra_tree's best error=0.1588\n",
            "[flaml.automl: 05-02 17:28:31] {2976} INFO - retrain extra_tree for 0.3s\n",
            "INFO:flaml.automl:retrain extra_tree for 0.3s\n",
            "[flaml.automl: 05-02 17:28:31] {2981} INFO - retrained model: ExtraTreesClassifier(criterion='entropy', max_features=1.0, max_leaf_nodes=4,\n",
            "                     n_estimators=6, n_jobs=-1)\n",
            "INFO:flaml.automl:retrained model: ExtraTreesClassifier(criterion='entropy', max_features=1.0, max_leaf_nodes=4,\n",
            "                     n_estimators=6, n_jobs=-1)\n",
            "[flaml.automl: 05-02 17:28:31] {2310} INFO - fit succeeded\n",
            "INFO:flaml.automl:fit succeeded\n",
            "[flaml.automl: 05-02 17:28:31] {2312} INFO - Time taken to find the best model: 141.27475953102112\n",
            "INFO:flaml.automl:Time taken to find the best model: 141.27475953102112\n",
            "[flaml.automl: 05-02 17:28:31] {2326} WARNING - Time taken to find the best model is 71% of the provided time budget and not all estimators' hyperparameter search converged. Consider increasing the time budget.\n",
            "WARNING:flaml.automl:Time taken to find the best model is 71% of the provided time budget and not all estimators' hyperparameter search converged. Consider increasing the time budget.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "automl.model.estimator"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7530c0ba-0f0e-4b48-b708-eb2c84aaa014",
        "id": "XX1yFU-wlt9R"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ExtraTreesClassifier(criterion='entropy', max_features=1.0, max_leaf_nodes=4,\n",
              "                     n_estimators=6, n_jobs=-1)"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Ypred=automl.predict(Xtest)"
      ],
      "metadata": {
        "id": "mcUwpWjflt9R"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy_score(Ytest, Ypred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "01354dab-7598-419f-a90c-a53618aaf9cf",
        "id": "gNS9hp7clt9S"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7183098591549296"
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pd.DataFrame(classification_report(Ytest, Ypred, output_dict=True))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 174
        },
        "id": "Q2eZbBs8l1ey",
        "outputId": "fa91010a-675f-441a-b264-0dfa0f40de7f"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                   0          1  accuracy  macro avg  weighted avg\n",
              "precision   0.709677   0.725000   0.71831   0.717339      0.717878\n",
              "recall      0.666667   0.763158   0.71831   0.714912      0.718310\n",
              "f1-score    0.687500   0.743590   0.71831   0.715545      0.717520\n",
              "support    33.000000  38.000000   0.71831  71.000000     71.000000"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c67e6663-26da-4bd1-98f7-aeb8493624de\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>macro avg</th>\n",
              "      <th>weighted avg</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>precision</th>\n",
              "      <td>0.709677</td>\n",
              "      <td>0.725000</td>\n",
              "      <td>0.71831</td>\n",
              "      <td>0.717339</td>\n",
              "      <td>0.717878</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>recall</th>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.763158</td>\n",
              "      <td>0.71831</td>\n",
              "      <td>0.714912</td>\n",
              "      <td>0.718310</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>f1-score</th>\n",
              "      <td>0.687500</td>\n",
              "      <td>0.743590</td>\n",
              "      <td>0.71831</td>\n",
              "      <td>0.715545</td>\n",
              "      <td>0.717520</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>support</th>\n",
              "      <td>33.000000</td>\n",
              "      <td>38.000000</td>\n",
              "      <td>0.71831</td>\n",
              "      <td>71.000000</td>\n",
              "      <td>71.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c67e6663-26da-4bd1-98f7-aeb8493624de')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c67e6663-26da-4bd1-98f7-aeb8493624de button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c67e6663-26da-4bd1-98f7-aeb8493624de');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Oversampling"
      ],
      "metadata": {
        "id": "SQgRlRUl5J7a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Oversampling**"
      ],
      "metadata": {
        "id": "UXSpYS_-noM-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset=[trainx,ytrain]\n",
        "df_train= pd.concat(dataset, axis=1)"
      ],
      "metadata": {
        "id": "nfQWT8RiWVPm"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train"
      ],
      "metadata": {
        "id": "FkQPXPl9WmQS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "outputId": "11874879-838e-453c-9474-9fd13e90dd8e"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      gender  Residence_type  work_type  smoking_status  ever_married   age  \\\n",
              "0          1               1          2               1             1  67.0   \n",
              "1          0               0          3               2             1  61.0   \n",
              "2          1               0          2               2             1  80.0   \n",
              "3          0               1          2               3             1  49.0   \n",
              "4          0               0          3               2             1  79.0   \n",
              "...      ...             ...        ...             ...           ...   ...   \n",
              "5105       0               1          2               2             1  80.0   \n",
              "5106       0               1          3               2             1  81.0   \n",
              "5107       0               0          3               2             1  35.0   \n",
              "5108       1               0          2               1             1  51.0   \n",
              "5109       0               1          0               0             1  44.0   \n",
              "\n",
              "      hypertension  heart_disease  avg_glucose_level  stroke  \n",
              "0                0              1             228.69       1  \n",
              "1                0              0             202.21       1  \n",
              "2                0              1             105.92       1  \n",
              "3                0              0             171.23       1  \n",
              "4                1              0             174.12       1  \n",
              "...            ...            ...                ...     ...  \n",
              "5105             1              0              83.75       0  \n",
              "5106             0              0             125.20       0  \n",
              "5107             0              0              82.99       0  \n",
              "5108             0              0             166.29       0  \n",
              "5109             0              0              85.28       0  \n",
              "\n",
              "[5110 rows x 10 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8737fbc2-2814-48b8-999e-4b1361ad62d1\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>gender</th>\n",
              "      <th>Residence_type</th>\n",
              "      <th>work_type</th>\n",
              "      <th>smoking_status</th>\n",
              "      <th>ever_married</th>\n",
              "      <th>age</th>\n",
              "      <th>hypertension</th>\n",
              "      <th>heart_disease</th>\n",
              "      <th>avg_glucose_level</th>\n",
              "      <th>stroke</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>67.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>228.69</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>61.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>202.21</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>80.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>105.92</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>49.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>171.23</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>79.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>174.12</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5105</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>80.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>83.75</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5106</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>81.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>125.20</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5107</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>35.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>82.99</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5108</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>51.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>166.29</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5109</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>44.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>85.28</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5110 rows × 10 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8737fbc2-2814-48b8-999e-4b1361ad62d1')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-8737fbc2-2814-48b8-999e-4b1361ad62d1 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-8737fbc2-2814-48b8-999e-4b1361ad62d1');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_train['stroke'].value_counts()"
      ],
      "metadata": {
        "id": "XG8dwgEobXTB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "92d3acf7-932d-4916-a1c2-8e4400e7654b"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    4861\n",
              "1     249\n",
              "Name: stroke, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.utils import resample\n",
        "#create two different dataframe of majority and minority class \n",
        "df_majority = df_train[(df_train['stroke']==0)] \n",
        "df_minority = df_train[(df_train['stroke']==1)] \n",
        "# upsample minority class\n",
        "df_minority_upsampled = resample(df_minority, \n",
        "                                 replace=True,    # sample with replacement\n",
        "                                 n_samples= 4861, # to match majority class\n",
        "                                 random_state=42)  # reproducible results\n",
        "# Combine majority class with upsampled minority class\n",
        "df_upsampled = pd.concat([df_minority_upsampled, df_majority])"
      ],
      "metadata": {
        "id": "3SV-Q0tUVZvE"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_upsampled"
      ],
      "metadata": {
        "id": "FNaVow5WWz8_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "outputId": "c44ca4de-6814-4446-c978-b4e6ae06a9e7"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      gender  Residence_type  work_type  smoking_status  ever_married   age  \\\n",
              "102        0               0          2               1             1  74.0   \n",
              "179        1               1          2               0             1  81.0   \n",
              "92         0               1          3               2             0  57.0   \n",
              "14         0               1          2               2             1  79.0   \n",
              "106        0               0          2               1             1  50.0   \n",
              "...      ...             ...        ...             ...           ...   ...   \n",
              "5105       0               1          2               2             1  80.0   \n",
              "5106       0               1          3               2             1  81.0   \n",
              "5107       0               0          3               2             1  35.0   \n",
              "5108       1               0          2               1             1  51.0   \n",
              "5109       0               1          0               0             1  44.0   \n",
              "\n",
              "      hypertension  heart_disease  avg_glucose_level  stroke  \n",
              "102              0              0             231.61       1  \n",
              "179              0              0             213.22       1  \n",
              "92               0              0              68.02       1  \n",
              "14               0              1             214.09       1  \n",
              "106              1              0              73.18       1  \n",
              "...            ...            ...                ...     ...  \n",
              "5105             1              0              83.75       0  \n",
              "5106             0              0             125.20       0  \n",
              "5107             0              0              82.99       0  \n",
              "5108             0              0             166.29       0  \n",
              "5109             0              0              85.28       0  \n",
              "\n",
              "[9722 rows x 10 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-499c4e03-e470-41a9-9edf-d21b325b01af\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>gender</th>\n",
              "      <th>Residence_type</th>\n",
              "      <th>work_type</th>\n",
              "      <th>smoking_status</th>\n",
              "      <th>ever_married</th>\n",
              "      <th>age</th>\n",
              "      <th>hypertension</th>\n",
              "      <th>heart_disease</th>\n",
              "      <th>avg_glucose_level</th>\n",
              "      <th>stroke</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>102</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>74.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>231.61</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>179</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>81.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>213.22</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>92</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>57.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>68.02</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>79.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>214.09</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>106</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>50.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>73.18</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5105</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>80.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>83.75</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5106</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>81.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>125.20</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5107</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>35.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>82.99</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5108</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>51.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>166.29</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5109</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>44.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>85.28</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>9722 rows × 10 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-499c4e03-e470-41a9-9edf-d21b325b01af')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-499c4e03-e470-41a9-9edf-d21b325b01af button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-499c4e03-e470-41a9-9edf-d21b325b01af');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sns.countplot(x ='stroke', data = df_upsampled)\n",
        "#data is balanced"
      ],
      "metadata": {
        "id": "Ql1_6ipeZqQI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "outputId": "5779bafc-78e2-4199-96ac-d28243396bd6"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f03769fea10>"
            ]
          },
          "metadata": {},
          "execution_count": 90
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_upsampled.iloc[:,:9]"
      ],
      "metadata": {
        "id": "1LPUNhHtb57q",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "outputId": "6c741e48-7169-4b59-f80e-b0db763e7ede"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      gender  Residence_type  work_type  smoking_status  ever_married   age  \\\n",
              "102        0               0          2               1             1  74.0   \n",
              "179        1               1          2               0             1  81.0   \n",
              "92         0               1          3               2             0  57.0   \n",
              "14         0               1          2               2             1  79.0   \n",
              "106        0               0          2               1             1  50.0   \n",
              "...      ...             ...        ...             ...           ...   ...   \n",
              "5105       0               1          2               2             1  80.0   \n",
              "5106       0               1          3               2             1  81.0   \n",
              "5107       0               0          3               2             1  35.0   \n",
              "5108       1               0          2               1             1  51.0   \n",
              "5109       0               1          0               0             1  44.0   \n",
              "\n",
              "      hypertension  heart_disease  avg_glucose_level  \n",
              "102              0              0             231.61  \n",
              "179              0              0             213.22  \n",
              "92               0              0              68.02  \n",
              "14               0              1             214.09  \n",
              "106              1              0              73.18  \n",
              "...            ...            ...                ...  \n",
              "5105             1              0              83.75  \n",
              "5106             0              0             125.20  \n",
              "5107             0              0              82.99  \n",
              "5108             0              0             166.29  \n",
              "5109             0              0              85.28  \n",
              "\n",
              "[9722 rows x 9 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-531c60d7-51f3-4038-b4e0-0244747c809f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>gender</th>\n",
              "      <th>Residence_type</th>\n",
              "      <th>work_type</th>\n",
              "      <th>smoking_status</th>\n",
              "      <th>ever_married</th>\n",
              "      <th>age</th>\n",
              "      <th>hypertension</th>\n",
              "      <th>heart_disease</th>\n",
              "      <th>avg_glucose_level</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>102</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>74.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>231.61</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>179</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>81.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>213.22</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>92</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>57.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>68.02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>79.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>214.09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>106</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>50.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>73.18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5105</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>80.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>83.75</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5106</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>81.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>125.20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5107</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>35.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>82.99</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5108</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>51.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>166.29</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5109</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>44.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>85.28</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>9722 rows × 9 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-531c60d7-51f3-4038-b4e0-0244747c809f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-531c60d7-51f3-4038-b4e0-0244747c809f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-531c60d7-51f3-4038-b4e0-0244747c809f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, Y_train, Y_test = train_test_split(df_upsampled.iloc[:,:9], df_upsampled['stroke'], test_size=0.2, random_state=50)"
      ],
      "metadata": {
        "id": "2-P6DwElbog_"
      },
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import svm"
      ],
      "metadata": {
        "id": "4Q31ppXycbXD"
      },
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clf = svm.SVC(kernel='linear')"
      ],
      "metadata": {
        "id": "-2ukzqH9czdh"
      },
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clf.fit(X_train,Y_train)"
      ],
      "metadata": {
        "id": "nxihYarvc1YJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 310
        },
        "outputId": "fff7415f-af22-44a1-ac35-c0b39c33cdde"
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-95-35aeecabe685>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearnex/svm/svc.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m     47\u001b[0m             \u001b[0;34m'onedal'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_onedal_fit\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m             \u001b[0;34m'sklearn'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0msklearn_SVC\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m         }, X, y, sample_weight)\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearnex/_device_offload.py\u001b[0m in \u001b[0;36mdispatch\u001b[0;34m(obj, method_name, branches, *args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"sklearn.{method_name}: {get_patch_message(backend, q)}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mbackend\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'onedal'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mbranches\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mhostargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mhostkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mqueue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mbackend\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'sklearn'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbranches\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mhostargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mhostkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearnex/svm/svc.py\u001b[0m in \u001b[0;36m_onedal_fit\u001b[0;34m(self, X, y, sample_weight, queue)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_onedal_estimator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0monedal_SVC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0monedal_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_onedal_estimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mqueue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mqueue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclass_weight\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'balanced'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/onedal/svm/svm.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, queue)\u001b[0m\n\u001b[1;32m    392\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mqueue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 394\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassification\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mqueue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    395\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mqueue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/onedal/svm/svm.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, sample_weight, module, queue)\u001b[0m\n\u001b[1;32m    208\u001b[0m         \u001b[0mpolicy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_policy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mqueue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m         \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_onedal_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 210\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpolicy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mto_table\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sparse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred=clf.predict(X_test)"
      ],
      "metadata": {
        "id": "DuCZNEq1c5XU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.DataFrame(classification_report(Y_test, pred, output_dict=True))"
      ],
      "metadata": {
        "id": "pgTCW9SjdxG-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "neigh = KNeighborsClassifier(n_neighbors=3)\n",
        "neigh.fit(X_train, Y_train)"
      ],
      "metadata": {
        "id": "pbRgX-zu9KZQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Y_pred=neigh.predict(X_test)"
      ],
      "metadata": {
        "id": "6m8F4oUo9zeT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.DataFrame(classification_report(Y_test, Y_pred, output_dict=True))"
      ],
      "metadata": {
        "id": "7A6wGp_A-CKt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from flaml import AutoML\n",
        "automl = AutoML()\n",
        "automl.fit(X_train, Y_train, task=\"classification\",estimator_list=[ \"xgboost\", \"rf\",'extra_tree','lrl1'],time_budget=250)"
      ],
      "metadata": {
        "id": "5Y-c7DWOpciE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "automl.model.estimator"
      ],
      "metadata": {
        "id": "OEQW-AYlpkHr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred=automl.predict(X_test)"
      ],
      "metadata": {
        "id": "5hQXu9alrxhy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy_score(Y_test, y_pred)"
      ],
      "metadata": {
        "id": "-b3uP1bir0j_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Pipeline"
      ],
      "metadata": {
        "id": "dGFx4myPxcXH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.utils import resample\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn import set_config\n",
        "from xgboost import XGBClassifier\n",
        "steps = [\n",
        "    (\"preprocessing\", LabelEncoder()),\n",
        "    (\"Classifier\", XGBClassifier(colsample_bylevel=0.7142801381920149, colsample_bytree=1.0,\n",
        "              grow_policy='lossguide', learning_rate=0.004338606755663443,\n",
        "              max_depth=0, max_leaves=477, min_child_weight=0.14197509384544463,\n",
        "              n_estimators=92, n_jobs=-1, reg_alpha=0.0010576618664776879,\n",
        "              reg_lambda=0.0020617210165454563, subsample=0.9192957817587406,\n",
        "              tree_method='hist', use_label_encoder=False, verbosity=0))\n",
        "]\n",
        "pipe = Pipeline(steps)"
      ],
      "metadata": {
        "id": "HXNjSY6ixbr-"
      },
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "set_config(display=\"diagram\")\n",
        "pipe"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 259
        },
        "id": "uhefABnC1VC1",
        "outputId": "0539f54f-bde8-4646-b396-eb4d5a9566d2"
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(steps=[('preprocessing', LabelEncoder()),\n",
              "                ('Classifier',\n",
              "                 XGBClassifier(colsample_bylevel=0.7142801381920149,\n",
              "                               colsample_bytree=1.0, grow_policy='lossguide',\n",
              "                               learning_rate=0.004338606755663443, max_depth=0,\n",
              "                               max_leaves=477,\n",
              "                               min_child_weight=0.14197509384544463,\n",
              "                               n_estimators=92, n_jobs=-1,\n",
              "                               reg_alpha=0.0010576618664776879,\n",
              "                               reg_lambda=0.0020617210165454563,\n",
              "                               subsample=0.9192957817587406, tree_method='hist',\n",
              "                               use_label_encoder=False, verbosity=0))])"
            ],
            "text/html": [
              "<style>#sk-c5a1fce9-05b8-4af0-afd4-0e7d20679be0 {color: black;background-color: white;}#sk-c5a1fce9-05b8-4af0-afd4-0e7d20679be0 pre{padding: 0;}#sk-c5a1fce9-05b8-4af0-afd4-0e7d20679be0 div.sk-toggleable {background-color: white;}#sk-c5a1fce9-05b8-4af0-afd4-0e7d20679be0 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-c5a1fce9-05b8-4af0-afd4-0e7d20679be0 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-c5a1fce9-05b8-4af0-afd4-0e7d20679be0 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-c5a1fce9-05b8-4af0-afd4-0e7d20679be0 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-c5a1fce9-05b8-4af0-afd4-0e7d20679be0 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-c5a1fce9-05b8-4af0-afd4-0e7d20679be0 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-c5a1fce9-05b8-4af0-afd4-0e7d20679be0 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-c5a1fce9-05b8-4af0-afd4-0e7d20679be0 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-c5a1fce9-05b8-4af0-afd4-0e7d20679be0 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-c5a1fce9-05b8-4af0-afd4-0e7d20679be0 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-c5a1fce9-05b8-4af0-afd4-0e7d20679be0 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-c5a1fce9-05b8-4af0-afd4-0e7d20679be0 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-c5a1fce9-05b8-4af0-afd4-0e7d20679be0 div.sk-estimator:hover {background-color: #d4ebff;}#sk-c5a1fce9-05b8-4af0-afd4-0e7d20679be0 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-c5a1fce9-05b8-4af0-afd4-0e7d20679be0 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-c5a1fce9-05b8-4af0-afd4-0e7d20679be0 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 2em;bottom: 0;left: 50%;}#sk-c5a1fce9-05b8-4af0-afd4-0e7d20679be0 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;}#sk-c5a1fce9-05b8-4af0-afd4-0e7d20679be0 div.sk-item {z-index: 1;}#sk-c5a1fce9-05b8-4af0-afd4-0e7d20679be0 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;}#sk-c5a1fce9-05b8-4af0-afd4-0e7d20679be0 div.sk-parallel::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 2em;bottom: 0;left: 50%;}#sk-c5a1fce9-05b8-4af0-afd4-0e7d20679be0 div.sk-parallel-item {display: flex;flex-direction: column;position: relative;background-color: white;}#sk-c5a1fce9-05b8-4af0-afd4-0e7d20679be0 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-c5a1fce9-05b8-4af0-afd4-0e7d20679be0 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-c5a1fce9-05b8-4af0-afd4-0e7d20679be0 div.sk-parallel-item:only-child::after {width: 0;}#sk-c5a1fce9-05b8-4af0-afd4-0e7d20679be0 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;position: relative;}#sk-c5a1fce9-05b8-4af0-afd4-0e7d20679be0 div.sk-label label {font-family: monospace;font-weight: bold;background-color: white;display: inline-block;line-height: 1.2em;}#sk-c5a1fce9-05b8-4af0-afd4-0e7d20679be0 div.sk-label-container {position: relative;z-index: 2;text-align: center;}#sk-c5a1fce9-05b8-4af0-afd4-0e7d20679be0 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-c5a1fce9-05b8-4af0-afd4-0e7d20679be0 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-c5a1fce9-05b8-4af0-afd4-0e7d20679be0\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;preprocessing&#x27;, LabelEncoder()),\n",
              "                (&#x27;Classifier&#x27;,\n",
              "                 XGBClassifier(colsample_bylevel=0.7142801381920149,\n",
              "                               colsample_bytree=1.0, grow_policy=&#x27;lossguide&#x27;,\n",
              "                               learning_rate=0.004338606755663443, max_depth=0,\n",
              "                               max_leaves=477,\n",
              "                               min_child_weight=0.14197509384544463,\n",
              "                               n_estimators=92, n_jobs=-1,\n",
              "                               reg_alpha=0.0010576618664776879,\n",
              "                               reg_lambda=0.0020617210165454563,\n",
              "                               subsample=0.9192957817587406, tree_method=&#x27;hist&#x27;,\n",
              "                               use_label_encoder=False, verbosity=0))])</pre><b>Please rerun this cell to show the HTML repr or trust the notebook.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"6b683c2b-9ca3-4674-8b88-ca06489f6952\" type=\"checkbox\" ><label for=\"6b683c2b-9ca3-4674-8b88-ca06489f6952\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;preprocessing&#x27;, LabelEncoder()),\n",
              "                (&#x27;Classifier&#x27;,\n",
              "                 XGBClassifier(colsample_bylevel=0.7142801381920149,\n",
              "                               colsample_bytree=1.0, grow_policy=&#x27;lossguide&#x27;,\n",
              "                               learning_rate=0.004338606755663443, max_depth=0,\n",
              "                               max_leaves=477,\n",
              "                               min_child_weight=0.14197509384544463,\n",
              "                               n_estimators=92, n_jobs=-1,\n",
              "                               reg_alpha=0.0010576618664776879,\n",
              "                               reg_lambda=0.0020617210165454563,\n",
              "                               subsample=0.9192957817587406, tree_method=&#x27;hist&#x27;,\n",
              "                               use_label_encoder=False, verbosity=0))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"e2a073ba-d293-40bd-95a7-6beed33bc89b\" type=\"checkbox\" ><label for=\"e2a073ba-d293-40bd-95a7-6beed33bc89b\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LabelEncoder</label><div class=\"sk-toggleable__content\"><pre>LabelEncoder()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"0bbfbe48-d580-4a35-95b2-d17acc103d61\" type=\"checkbox\" ><label for=\"0bbfbe48-d580-4a35-95b2-d17acc103d61\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(colsample_bylevel=0.7142801381920149, colsample_bytree=1.0,\n",
              "              grow_policy=&#x27;lossguide&#x27;, learning_rate=0.004338606755663443,\n",
              "              max_depth=0, max_leaves=477, min_child_weight=0.14197509384544463,\n",
              "              n_estimators=92, n_jobs=-1, reg_alpha=0.0010576618664776879,\n",
              "              reg_lambda=0.0020617210165454563, subsample=0.9192957817587406,\n",
              "              tree_method=&#x27;hist&#x27;, use_label_encoder=False, verbosity=0)</pre></div></div></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# multi-criteria model"
      ],
      "metadata": {
        "id": "uADqiiBZ2qf1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df1 = pd.concat([x_train,y_train],axis=1)"
      ],
      "metadata": {
        "id": "xihdUgdt6JUx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1"
      ],
      "metadata": {
        "id": "z4oZx8mb6SK_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bag1 = df1.sample(frac=0.8, replace=True, random_state = 3)\n",
        "lgb_clf1 = lgb.LGBMClassifier(n_estimators=500, max_depth = 9)\n",
        "lgb_clf1.fit(bag1.iloc[:, :-1], bag1.iloc[:, -1])\n",
        "y_pred1 = lgb_clf1.predict(x_test)"
      ],
      "metadata": {
        "id": "ijFnadIQ4MF9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bag2 = df1.sample(frac=0.8, replace=True, random_state = 4)\n",
        "lgb_clf2 = lgb.LGBMClassifier(n_estimators=500, max_depth = 10)\n",
        "lgb_clf2.fit(bag2.iloc[:, :-1], bag2.iloc[:, -1])\n",
        "y_pred2 = lgb_clf2.predict(x_test)"
      ],
      "metadata": {
        "id": "PwQtTIFp4PS-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bag3= df1.sample(frac=0.8, replace=True, random_state = 5)\n",
        "lgb_clf3 = lgb.LGBMClassifier(n_estimators=500, max_depth = 11)\n",
        "lgb_clf3.fit(bag3.iloc[:, :-1], bag3.iloc[:, -1])\n",
        "y_pred3 = lgb_clf3.predict(x_test)"
      ],
      "metadata": {
        "id": "HA9qy87F4RlR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bag4= df1.sample(frac=0.8, replace=True, random_state = 6)\n",
        "lgb_clf4 = lgb.LGBMClassifier(n_estimators=500, max_depth = 12)\n",
        "lgb_clf4.fit(bag4.iloc[:, :-1], bag4.iloc[:, -1])\n",
        "y_pred4 = lgb_clf4.predict(x_test)"
      ],
      "metadata": {
        "id": "ziiOqBpk4Tqb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bag5= df1.sample(frac=0.8, replace=True, random_state = 7)\n",
        "lgb_clf5 = lgb.LGBMClassifier(n_estimators=500, max_depth = 13)\n",
        "lgb_clf5.fit(bag5.iloc[:, :-1], bag5.iloc[:, -1])\n",
        "y_pred5 = lgb_clf5.predict(x_test)"
      ],
      "metadata": {
        "id": "IJUf1SVU4UJa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bag6= df1.sample(frac=0.8, replace=True, random_state = 8)\n",
        "lgb_clf6 = lgb.LGBMClassifier(n_estimators=500, max_depth = 14)\n",
        "lgb_clf6.fit(bag6.iloc[:, :-1], bag6.iloc[:, -1])\n",
        "y_pred6 = lgb_clf6.predict(x_test)"
      ],
      "metadata": {
        "id": "jW5v-1W14V0b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bag7= df1.sample(frac=0.8, replace=True, random_state=9)\n",
        "lgb_clf7 = lgb.LGBMClassifier(n_estimators=500, max_depth = 15)\n",
        "lgb_clf7.fit(bag7.iloc[:, :-1], bag7.iloc[:, -1])\n",
        "y_pred7 = lgb_clf7.predict(x_test)"
      ],
      "metadata": {
        "id": "rjxZEmZ_4XKN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bag8= df1.sample(frac=0.8, replace=True, random_state=10)\n",
        "lgb_clf8 = lgb.LGBMClassifier(n_estimators=500, max_depth = 16)\n",
        "lgb_clf8.fit(bag8.iloc[:, :-1], bag8.iloc[:, -1])\n",
        "y_pred8 = lgb_clf8.predict(x_test)"
      ],
      "metadata": {
        "id": "Es5WctCq4Y0J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bag9= df1.sample(frac=0.8, replace=True, random_state=11)\n",
        "lgb_clf9 = lgb.LGBMClassifier(n_estimators=500, max_depth = 17)\n",
        "lgb_clf9.fit(bag9.iloc[:, :-1], bag9.iloc[:, -1])\n",
        "y_pred9 = lgb_clf9.predict(x_test)"
      ],
      "metadata": {
        "id": "UY8_XsDl4bd1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bag10= df1.sample(frac=0.8, replace=True, random_state=12)\n",
        "lgb_clf10 = lgb.LGBMClassifier(n_estimators=500, max_depth = 18)\n",
        "lgb_clf10.fit(bag10.iloc[:, :-1], bag10.iloc[:, -1])\n",
        "y_pred10 = lgb_clf10.predict(x_test)"
      ],
      "metadata": {
        "id": "k_OtvyBh4c69"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred1_s = pd.Series(y_pred1)\n",
        "y_pred2_s = pd.Series(y_pred2)\n",
        "y_pred3_s = pd.Series(y_pred3)\n",
        "y_pred4_s = pd.Series(y_pred4)\n",
        "y_pred5_s = pd.Series(y_pred5)\n",
        "y_pred6_s = pd.Series(y_pred6)\n",
        "y_pred7_s = pd.Series(y_pred7)\n",
        "y_pred8_s = pd.Series(y_pred8)\n",
        "y_pred9_s = pd.Series(y_pred9)\n",
        "y_pred10_s = pd.Series(y_pred10)"
      ],
      "metadata": {
        "id": "KLLRlJqd4gZS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_f = pd.concat([y_pred1_s,y_pred2_s,y_pred3_s,y_pred4_s,y_pred5_s,y_pred6_s,y_pred7_s,y_pred8_s,y_pred9_s,y_pred10_s], axis=1)"
      ],
      "metadata": {
        "id": "0A1U3rX44jON"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_f"
      ],
      "metadata": {
        "id": "xjwF3yIR7LvC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = []\n",
        "y_pred_f = np.array(y_pred_f)\n",
        "\n",
        "for i in range(len(y_pred_f)):\n",
        "  count_0 = 0\n",
        "  count_1 = 0\n",
        "\n",
        "  for j in range(len(y_pred_f[0])):\n",
        "    if (y_pred_f[i][j]):\n",
        "      count_1 += 1\n",
        "    else:\n",
        "      count_0 += 1\n",
        "  \n",
        "  if (count_1 > count_0):\n",
        "    y_pred.append(1)\n",
        "  else:\n",
        "    y_pred.append(0)"
      ],
      "metadata": {
        "id": "wVEQjj4s7QgD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(accuracy_score(y_test, y_pred))"
      ],
      "metadata": {
        "id": "TovqJDGeOrJc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}